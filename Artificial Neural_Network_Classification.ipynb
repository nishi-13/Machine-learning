{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Copy of CO III  Neural_Network_Classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nishi-13/Machine-learning/blob/main/Artificial%20Neural_Network_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhPEM4IUoDKA"
      },
      "source": [
        "# Joint Online Faculty Development programme on Deep Learning (Parallel Architecture) Aug 23 â€“ Sep 3 , 2021\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZpJe0cAaoG98"
      },
      "source": [
        "# Tutorial 3: Neural Network Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dIT7QrK2PwdM"
      },
      "source": [
        "Dataset: [Pima Indian Diabetes Dataset](https://data.world/data-society/pima-indians-diabetes-database#)\n",
        "\n",
        "This dataset is originally from the National Institute of Diabetes and Digestive and Kidney Diseases. The objective is to predict based on diagnostic measurements whether a patient has diabetes.\n",
        "\n",
        "Several constraints were placed on the selection of these instances from a larger database. In particular, all patients here are females at least 21 years old of Pima Indian heritage.\n",
        "\n",
        "Attributes of PIMA dataset:\n",
        "\n",
        "**Pregnancies**: Number of times pregnant\n",
        "\n",
        "**Glucose**: Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n",
        "\n",
        "**BloodPressure**: Diastolic blood pressure (mm Hg)\n",
        "\n",
        "**SkinThickness**: Triceps skin fold thickness (mm)\n",
        "\n",
        "**Insulin**: 2-Hour serum insulin (mu U/ml)\n",
        "\n",
        "**BMI**: Body mass index (weight in kg/(height in m)^2)\n",
        "\n",
        "**DiabetesPedigreeFunction**: Diabetes pedigree function\n",
        "\n",
        "**Age**: Age (years)\n",
        "\n",
        "**Outcome**: Class variable (0 or 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FIAgs3sTY712"
      },
      "source": [
        "**1. Mount the Google Drive**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CrZg_G5MQ4L5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e92e537-5256-4f68-95ff-da3bc70a23e3"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CqAhYoWHZAwg"
      },
      "source": [
        "**2. Move to the place where data resides**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TjgG_3CiP4eQ",
        "outputId": "e5505075-7fd1-42d2-a24e-b0385d669090"
      },
      "source": [
        "%cd /content/drive/MyDrive"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "S-KhHH_xATY8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09fde5e5-e85a-45ad-d669-19bcf53cd58e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 16397397439574137648366277021999.jpg\n",
            " 16397397748753720546659151768852.jpg\n",
            "'alexa skill'\n",
            "'alexa skill department .gsheet'\n",
            "'Ashutosh chouhan  (1).pdf'\n",
            "'Ashutoshchouhan(CO-14)ADA(assignment).pdf'\n",
            "'Ashutosh chouhan (CO-14).docx'\n",
            "'Ashutosh chouhan Cybersecurity_Foundation_Student_Certificate.pdf'\n",
            "'Ashutosh chouhan .pdf'\n",
            "'ashutosh chouhan resume (1).pdf'\n",
            "'ashutosh chouhan resume.pdf'\n",
            "'Assignment - Alexa Skill Set.docx'\n",
            " Classroom\n",
            "'Colab Notebooks'\n",
            "'CSIT-1st yr.xlsx'\n",
            " CSO\n",
            "'CSO practical file '\n",
            " custom_trainvalacc.png\n",
            " custom_trainvalloss.png\n",
            "'Cyber security lab analysis.gdoc'\n",
            "'DBMS Experiment List.gdoc'\n",
            " diabetes.csv\n",
            "'DS Practical .pdf'\n",
            "'G18- design and impelementation of exam software_CO04 CO14 CO26 CO54.docx'\n",
            "'Getting started.pdf'\n",
            " IMG_20210520_113852.jpg\n",
            " IMG_20210601_164205.jpg\n",
            " IMG-20210724-WA0003.jpg\n",
            " IMG_20210929_152745.jpg\n",
            " IMG_20210929_153059.jpg\n",
            "'IP DNS Subnet Mask.pptx'\n",
            "'IWT +LINUX  Assignments and Lab work'\n",
            "'Linux _Lab-CS505 File Format (1).gdoc'\n",
            "'Linux _Lab-CS505 File Format (2).gdoc'\n",
            "'Linux _Lab-CS505 File Format (3).gdoc'\n",
            "'Linux _Lab-CS505 File Format.gdoc'\n",
            "'OOPM PPT ASHUTOSH CHOUHAN (CO-14) .pdf'\n",
            "'Operating System Tutorial Ashutosh chouhan CO-14.docx'\n",
            " Parent_AFD_2290935_27122020154054192.pdf\n",
            "'response sheet of C0-304(MST-I).gsheet'\n",
            " Screenshot_20180528-195428.png\n",
            " Screenshot_2021-05-29-11-53-51-395_com.google.android.youtube.jpg\n",
            " Screenshot_2021-05-29-14-21-32-384_com.google.android.youtube.jpg\n",
            " Screenshot_2021-08-06-11-42-00-478_com.google.android.apps.meetings.jpg\n",
            " Screenshot_2021-08-06-12-11-40-785_com.google.android.apps.meetings.jpg\n",
            " Screenshot_2021-08-31-14-41-22-606_com.google.android.apps.meetings.jpg\n",
            " Screenshot_2021-10-05-16-34-11-315_com.google.android.apps.meetings.jpg\n",
            " Student_AFD_2290935_2712202015405452.pdf\n",
            "'Summer Training Jan June 2021(CSIT Dept.).pdf'\n",
            "'TOC_Practical_assessment_format (1).gdoc'\n",
            " TOC_Practical_assessment_format.gdoc\n",
            " Unit5.gslides\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKvfswsOZLUB"
      },
      "source": [
        "**3. Read the dataset from CSV file**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "32nNonRSSaQq",
        "outputId": "09094a7d-d24e-4622-d2bd-25e360b891bf"
      },
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv('diabetes.csv')\n",
        "data.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
              "0            6      148             72             35        0  33.6   \n",
              "1            1       85             66             29        0  26.6   \n",
              "2            8      183             64              0        0  23.3   \n",
              "3            1       89             66             23       94  28.1   \n",
              "4            0      137             40             35      168  43.1   \n",
              "5            5      116             74              0        0  25.6   \n",
              "6            3       78             50             32       88  31.0   \n",
              "7           10      115              0              0        0  35.3   \n",
              "8            2      197             70             45      543  30.5   \n",
              "9            8      125             96              0        0   0.0   \n",
              "\n",
              "   DiabetesPedigreeFunction  Age  Outcome  \n",
              "0                     0.627   50        1  \n",
              "1                     0.351   31        0  \n",
              "2                     0.672   32        1  \n",
              "3                     0.167   21        0  \n",
              "4                     2.288   33        1  \n",
              "5                     0.201   30        0  \n",
              "6                     0.248   26        1  \n",
              "7                     0.134   29        0  \n",
              "8                     0.158   53        1  \n",
              "9                     0.232   54        1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f81dde18-d184-47de-9763-d8c0fae7dfd9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pregnancies</th>\n",
              "      <th>Glucose</th>\n",
              "      <th>BloodPressure</th>\n",
              "      <th>SkinThickness</th>\n",
              "      <th>Insulin</th>\n",
              "      <th>BMI</th>\n",
              "      <th>DiabetesPedigreeFunction</th>\n",
              "      <th>Age</th>\n",
              "      <th>Outcome</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>148</td>\n",
              "      <td>72</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>33.6</td>\n",
              "      <td>0.627</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>66</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.351</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>183</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.672</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>94</td>\n",
              "      <td>28.1</td>\n",
              "      <td>0.167</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>137</td>\n",
              "      <td>40</td>\n",
              "      <td>35</td>\n",
              "      <td>168</td>\n",
              "      <td>43.1</td>\n",
              "      <td>2.288</td>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>116</td>\n",
              "      <td>74</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>25.6</td>\n",
              "      <td>0.201</td>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>3</td>\n",
              "      <td>78</td>\n",
              "      <td>50</td>\n",
              "      <td>32</td>\n",
              "      <td>88</td>\n",
              "      <td>31.0</td>\n",
              "      <td>0.248</td>\n",
              "      <td>26</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>10</td>\n",
              "      <td>115</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>35.3</td>\n",
              "      <td>0.134</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2</td>\n",
              "      <td>197</td>\n",
              "      <td>70</td>\n",
              "      <td>45</td>\n",
              "      <td>543</td>\n",
              "      <td>30.5</td>\n",
              "      <td>0.158</td>\n",
              "      <td>53</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>8</td>\n",
              "      <td>125</td>\n",
              "      <td>96</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.232</td>\n",
              "      <td>54</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f81dde18-d184-47de-9763-d8c0fae7dfd9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f81dde18-d184-47de-9763-d8c0fae7dfd9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f81dde18-d184-47de-9763-d8c0fae7dfd9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZrslDLESShr7",
        "outputId": "6e79fa4a-db56-4153-fe1e-c555e427b1e3"
      },
      "source": [
        "data.columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',\n",
              "       'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BLElehZ-Skgq",
        "outputId": "e0f0508d-d5c6-4d8c-91b6-b3d378d236ef"
      },
      "source": [
        "data.values"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  6.   , 148.   ,  72.   , ...,   0.627,  50.   ,   1.   ],\n",
              "       [  1.   ,  85.   ,  66.   , ...,   0.351,  31.   ,   0.   ],\n",
              "       [  8.   , 183.   ,  64.   , ...,   0.672,  32.   ,   1.   ],\n",
              "       ...,\n",
              "       [  5.   , 121.   ,  72.   , ...,   0.245,  30.   ,   0.   ],\n",
              "       [  1.   , 126.   ,  60.   , ...,   0.349,  47.   ,   1.   ],\n",
              "       [  1.   ,  93.   ,  70.   , ...,   0.315,  23.   ,   0.   ]])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2HnZxGc4ZQlf"
      },
      "source": [
        "**4. Store the data into input feature and label variables**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IPfA5BF0Sm4R",
        "outputId": "af64dd11-1d4a-4dc1-8be3-7a477c34ee76"
      },
      "source": [
        "dataset= data.values\n",
        "X = dataset[:,0:8]\n",
        "Y = dataset[:,8]\n",
        "print(X)\n",
        "print(Y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[  6.    148.     72.    ...  33.6     0.627  50.   ]\n",
            " [  1.     85.     66.    ...  26.6     0.351  31.   ]\n",
            " [  8.    183.     64.    ...  23.3     0.672  32.   ]\n",
            " ...\n",
            " [  5.    121.     72.    ...  26.2     0.245  30.   ]\n",
            " [  1.    126.     60.    ...  30.1     0.349  47.   ]\n",
            " [  1.     93.     70.    ...  30.4     0.315  23.   ]]\n",
            "[1. 0. 1. 0. 1. 0. 1. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 1.\n",
            " 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0.\n",
            " 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0.\n",
            " 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0.\n",
            " 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0.\n",
            " 1. 0. 0. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0.\n",
            " 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0.\n",
            " 1. 1. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 1. 1.\n",
            " 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0.\n",
            " 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0.\n",
            " 1. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1.\n",
            " 0. 0. 0. 1. 1. 1. 0. 0. 1. 0. 1. 0. 1. 1. 0. 1. 0. 0. 1. 0. 1. 1. 0. 0.\n",
            " 1. 0. 1. 0. 0. 1. 0. 1. 0. 1. 1. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0.\n",
            " 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1.\n",
            " 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0.\n",
            " 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 1. 1. 0. 1. 0. 1. 0. 1. 0.\n",
            " 1. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0.\n",
            " 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1.\n",
            " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
            " 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.\n",
            " 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
            " 0. 1. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 0.\n",
            " 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 1.\n",
            " 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0.\n",
            " 0. 0. 0. 1. 1. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1.\n",
            " 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1.\n",
            " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1.\n",
            " 0. 0. 1. 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OdPZerNUZV4Q"
      },
      "source": [
        "**5. Data Normalization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pM4g3T1fWri-",
        "outputId": "cc8e1a29-7bb6-414b-c4a9-62e6918c8799"
      },
      "source": [
        "from sklearn import preprocessing\n",
        "min_max_scaler = preprocessing.MinMaxScaler()\n",
        "X_scale = min_max_scaler.fit_transform(X)\n",
        "X_scale"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.35294118, 0.74371859, 0.59016393, ..., 0.50074516, 0.23441503,\n",
              "        0.48333333],\n",
              "       [0.05882353, 0.42713568, 0.54098361, ..., 0.39642325, 0.11656704,\n",
              "        0.16666667],\n",
              "       [0.47058824, 0.91959799, 0.52459016, ..., 0.34724292, 0.25362938,\n",
              "        0.18333333],\n",
              "       ...,\n",
              "       [0.29411765, 0.6080402 , 0.59016393, ..., 0.390462  , 0.07130658,\n",
              "        0.15      ],\n",
              "       [0.05882353, 0.63316583, 0.49180328, ..., 0.4485842 , 0.11571307,\n",
              "        0.43333333],\n",
              "       [0.05882353, 0.46733668, 0.57377049, ..., 0.45305514, 0.10119556,\n",
              "        0.03333333]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n1B5x8C0ZY-e"
      },
      "source": [
        "**6. One-hot vector conversion**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IWPUAnA-XNd8",
        "outputId": "439d856b-1e8c-495c-9878-03523f8e6db6"
      },
      "source": [
        "from keras.utils import np_utils\n",
        "encoded_y = np_utils.to_categorical(Y)\n",
        "encoded_y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       ...,\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IeJWmMxjZbgo"
      },
      "source": [
        "**7. Split the dataset into training, testing and validation set**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3BqXnV1FXYIV",
        "outputId": "907c2353-d956-4f46-9320-de9eb7d401b3"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_training, X_testing, Y_training, Y_testing = train_test_split(X_scale, encoded_y, test_size=0.4, random_state=10)\n",
        "X_training, X_valid, Y_training, Y_valid = train_test_split(X_training, Y_training, test_size=0.4, random_state=10)\n",
        "print(len(X_training))\n",
        "print(len(X_testing))\n",
        "print(len(X_valid))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "276\n",
            "308\n",
            "184\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EH9IZizVZfKB"
      },
      "source": [
        "**8. Model Creation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hNfmvbMOXeku",
        "outputId": "0ad8e43f-3bd1-4f87-d1dc-14680fd7800b"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "# Creating the model\n",
        "model = Sequential()\n",
        "model.add(Dense(12, input_shape=(8,), activation='relu'))\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dense(10, activation='relu'))\n",
        "model.add(Dense(2, activation='softmax'))\n",
        "model.summary()   #gives a summary of the model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 12)                108       \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 8)                 104       \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 10)                90        \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 2)                 22        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 324\n",
            "Trainable params: 324\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYxZHI_EZiEF"
      },
      "source": [
        "**9. Model Compile**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "plF2qlxwXiIY"
      },
      "source": [
        "from tensorflow.keras import optimizers\n",
        "opt=optimizers.Adam(learning_rate=0.001)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8VrUFVQZkNd"
      },
      "source": [
        "**10. Model Training**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "if you have 1000 training examples, and your batch size is  500, then it will take 2 iterations to complete 1 epoch."
      ],
      "metadata": {
        "id": "08Ul5lN90_Sp"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xhDZ8yPhXrs0",
        "outputId": "de48d56c-021f-4c64-fff6-2242548fa701"
      },
      "source": [
        "hist = model.fit(X_training, Y_training,batch_size=16,  epochs=1000, validation_data=(X_valid,Y_valid))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "18/18 [==============================] - 1s 15ms/step - loss: 0.6753 - accuracy: 0.6413 - val_loss: 0.6657 - val_accuracy: 0.6304\n",
            "Epoch 2/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6602 - accuracy: 0.6594 - val_loss: 0.6561 - val_accuracy: 0.6359\n",
            "Epoch 3/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6509 - accuracy: 0.6594 - val_loss: 0.6523 - val_accuracy: 0.6359\n",
            "Epoch 4/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6474 - accuracy: 0.6594 - val_loss: 0.6491 - val_accuracy: 0.6359\n",
            "Epoch 5/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6436 - accuracy: 0.6594 - val_loss: 0.6463 - val_accuracy: 0.6359\n",
            "Epoch 6/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6400 - accuracy: 0.6594 - val_loss: 0.6425 - val_accuracy: 0.6359\n",
            "Epoch 7/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6372 - accuracy: 0.6594 - val_loss: 0.6399 - val_accuracy: 0.6359\n",
            "Epoch 8/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6333 - accuracy: 0.6594 - val_loss: 0.6366 - val_accuracy: 0.6359\n",
            "Epoch 9/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6291 - accuracy: 0.6630 - val_loss: 0.6324 - val_accuracy: 0.6304\n",
            "Epoch 10/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6245 - accuracy: 0.6667 - val_loss: 0.6275 - val_accuracy: 0.6359\n",
            "Epoch 11/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6190 - accuracy: 0.6667 - val_loss: 0.6238 - val_accuracy: 0.6413\n",
            "Epoch 12/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6135 - accuracy: 0.6667 - val_loss: 0.6191 - val_accuracy: 0.6522\n",
            "Epoch 13/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6083 - accuracy: 0.6739 - val_loss: 0.6127 - val_accuracy: 0.6739\n",
            "Epoch 14/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6034 - accuracy: 0.6703 - val_loss: 0.6111 - val_accuracy: 0.6739\n",
            "Epoch 15/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5951 - accuracy: 0.6848 - val_loss: 0.6007 - val_accuracy: 0.6902\n",
            "Epoch 16/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5892 - accuracy: 0.7065 - val_loss: 0.5916 - val_accuracy: 0.6685\n",
            "Epoch 17/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5820 - accuracy: 0.6957 - val_loss: 0.5883 - val_accuracy: 0.6739\n",
            "Epoch 18/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5737 - accuracy: 0.7029 - val_loss: 0.5799 - val_accuracy: 0.6685\n",
            "Epoch 19/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5658 - accuracy: 0.7174 - val_loss: 0.5722 - val_accuracy: 0.6957\n",
            "Epoch 20/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5611 - accuracy: 0.7210 - val_loss: 0.5693 - val_accuracy: 0.7011\n",
            "Epoch 21/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5558 - accuracy: 0.7138 - val_loss: 0.5654 - val_accuracy: 0.7011\n",
            "Epoch 22/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5589 - accuracy: 0.7029 - val_loss: 0.5658 - val_accuracy: 0.7065\n",
            "Epoch 23/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5463 - accuracy: 0.7174 - val_loss: 0.5592 - val_accuracy: 0.7065\n",
            "Epoch 24/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5470 - accuracy: 0.7138 - val_loss: 0.5579 - val_accuracy: 0.7120\n",
            "Epoch 25/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5395 - accuracy: 0.7138 - val_loss: 0.5596 - val_accuracy: 0.7120\n",
            "Epoch 26/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5367 - accuracy: 0.7283 - val_loss: 0.5571 - val_accuracy: 0.7120\n",
            "Epoch 27/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5314 - accuracy: 0.7101 - val_loss: 0.5523 - val_accuracy: 0.7065\n",
            "Epoch 28/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5286 - accuracy: 0.7138 - val_loss: 0.5523 - val_accuracy: 0.7228\n",
            "Epoch 29/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5258 - accuracy: 0.7210 - val_loss: 0.5484 - val_accuracy: 0.7174\n",
            "Epoch 30/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5259 - accuracy: 0.7391 - val_loss: 0.5458 - val_accuracy: 0.7120\n",
            "Epoch 31/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5216 - accuracy: 0.7246 - val_loss: 0.5469 - val_accuracy: 0.7228\n",
            "Epoch 32/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5160 - accuracy: 0.7283 - val_loss: 0.5420 - val_accuracy: 0.7228\n",
            "Epoch 33/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5176 - accuracy: 0.7174 - val_loss: 0.5440 - val_accuracy: 0.7228\n",
            "Epoch 34/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5130 - accuracy: 0.7319 - val_loss: 0.5392 - val_accuracy: 0.7283\n",
            "Epoch 35/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5112 - accuracy: 0.7283 - val_loss: 0.5432 - val_accuracy: 0.7337\n",
            "Epoch 36/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5107 - accuracy: 0.7246 - val_loss: 0.5398 - val_accuracy: 0.7228\n",
            "Epoch 37/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5059 - accuracy: 0.7355 - val_loss: 0.5358 - val_accuracy: 0.7283\n",
            "Epoch 38/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5126 - accuracy: 0.7319 - val_loss: 0.5398 - val_accuracy: 0.7283\n",
            "Epoch 39/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5012 - accuracy: 0.7355 - val_loss: 0.5311 - val_accuracy: 0.7283\n",
            "Epoch 40/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5009 - accuracy: 0.7391 - val_loss: 0.5299 - val_accuracy: 0.7283\n",
            "Epoch 41/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4957 - accuracy: 0.7464 - val_loss: 0.5273 - val_accuracy: 0.7391\n",
            "Epoch 42/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4912 - accuracy: 0.7464 - val_loss: 0.5295 - val_accuracy: 0.7337\n",
            "Epoch 43/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4906 - accuracy: 0.7428 - val_loss: 0.5311 - val_accuracy: 0.7283\n",
            "Epoch 44/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4873 - accuracy: 0.7536 - val_loss: 0.5212 - val_accuracy: 0.7391\n",
            "Epoch 45/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4868 - accuracy: 0.7572 - val_loss: 0.5249 - val_accuracy: 0.7446\n",
            "Epoch 46/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4827 - accuracy: 0.7536 - val_loss: 0.5195 - val_accuracy: 0.7446\n",
            "Epoch 47/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4790 - accuracy: 0.7645 - val_loss: 0.5224 - val_accuracy: 0.7446\n",
            "Epoch 48/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4813 - accuracy: 0.7536 - val_loss: 0.5239 - val_accuracy: 0.7446\n",
            "Epoch 49/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4752 - accuracy: 0.7536 - val_loss: 0.5194 - val_accuracy: 0.7554\n",
            "Epoch 50/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4765 - accuracy: 0.7500 - val_loss: 0.5160 - val_accuracy: 0.7500\n",
            "Epoch 51/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4720 - accuracy: 0.7609 - val_loss: 0.5135 - val_accuracy: 0.7500\n",
            "Epoch 52/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4684 - accuracy: 0.7609 - val_loss: 0.5156 - val_accuracy: 0.7554\n",
            "Epoch 53/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4735 - accuracy: 0.7536 - val_loss: 0.5164 - val_accuracy: 0.7554\n",
            "Epoch 54/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4658 - accuracy: 0.7645 - val_loss: 0.5097 - val_accuracy: 0.7500\n",
            "Epoch 55/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4700 - accuracy: 0.7572 - val_loss: 0.5092 - val_accuracy: 0.7554\n",
            "Epoch 56/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4627 - accuracy: 0.7609 - val_loss: 0.5082 - val_accuracy: 0.7609\n",
            "Epoch 57/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4594 - accuracy: 0.7754 - val_loss: 0.5087 - val_accuracy: 0.7609\n",
            "Epoch 58/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4576 - accuracy: 0.7681 - val_loss: 0.5060 - val_accuracy: 0.7609\n",
            "Epoch 59/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4565 - accuracy: 0.7717 - val_loss: 0.5053 - val_accuracy: 0.7609\n",
            "Epoch 60/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4575 - accuracy: 0.7681 - val_loss: 0.5038 - val_accuracy: 0.7446\n",
            "Epoch 61/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4553 - accuracy: 0.7717 - val_loss: 0.5024 - val_accuracy: 0.7446\n",
            "Epoch 62/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4504 - accuracy: 0.7681 - val_loss: 0.5066 - val_accuracy: 0.7609\n",
            "Epoch 63/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4517 - accuracy: 0.7754 - val_loss: 0.5084 - val_accuracy: 0.7609\n",
            "Epoch 64/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4562 - accuracy: 0.7717 - val_loss: 0.5039 - val_accuracy: 0.7663\n",
            "Epoch 65/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4520 - accuracy: 0.7826 - val_loss: 0.5100 - val_accuracy: 0.7717\n",
            "Epoch 66/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4429 - accuracy: 0.7681 - val_loss: 0.4991 - val_accuracy: 0.7500\n",
            "Epoch 67/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4444 - accuracy: 0.7790 - val_loss: 0.4996 - val_accuracy: 0.7554\n",
            "Epoch 68/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4422 - accuracy: 0.7826 - val_loss: 0.5045 - val_accuracy: 0.7717\n",
            "Epoch 69/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4394 - accuracy: 0.7826 - val_loss: 0.4970 - val_accuracy: 0.7554\n",
            "Epoch 70/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4385 - accuracy: 0.7899 - val_loss: 0.4995 - val_accuracy: 0.7609\n",
            "Epoch 71/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4365 - accuracy: 0.7826 - val_loss: 0.4984 - val_accuracy: 0.7554\n",
            "Epoch 72/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4401 - accuracy: 0.7754 - val_loss: 0.4987 - val_accuracy: 0.7554\n",
            "Epoch 73/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4366 - accuracy: 0.7935 - val_loss: 0.4997 - val_accuracy: 0.7609\n",
            "Epoch 74/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4320 - accuracy: 0.7935 - val_loss: 0.4960 - val_accuracy: 0.7554\n",
            "Epoch 75/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4327 - accuracy: 0.7754 - val_loss: 0.4997 - val_accuracy: 0.7609\n",
            "Epoch 76/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4335 - accuracy: 0.7862 - val_loss: 0.4967 - val_accuracy: 0.7500\n",
            "Epoch 77/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4274 - accuracy: 0.7899 - val_loss: 0.4974 - val_accuracy: 0.7609\n",
            "Epoch 78/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4264 - accuracy: 0.7971 - val_loss: 0.5027 - val_accuracy: 0.7500\n",
            "Epoch 79/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4254 - accuracy: 0.7935 - val_loss: 0.4930 - val_accuracy: 0.7609\n",
            "Epoch 80/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4262 - accuracy: 0.7935 - val_loss: 0.4932 - val_accuracy: 0.7609\n",
            "Epoch 81/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4270 - accuracy: 0.7862 - val_loss: 0.4932 - val_accuracy: 0.7554\n",
            "Epoch 82/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4277 - accuracy: 0.7899 - val_loss: 0.4926 - val_accuracy: 0.7609\n",
            "Epoch 83/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4198 - accuracy: 0.8043 - val_loss: 0.4980 - val_accuracy: 0.7554\n",
            "Epoch 84/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4181 - accuracy: 0.7935 - val_loss: 0.4884 - val_accuracy: 0.7663\n",
            "Epoch 85/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4234 - accuracy: 0.7935 - val_loss: 0.4923 - val_accuracy: 0.7554\n",
            "Epoch 86/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4193 - accuracy: 0.7899 - val_loss: 0.4950 - val_accuracy: 0.7554\n",
            "Epoch 87/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4148 - accuracy: 0.7899 - val_loss: 0.4910 - val_accuracy: 0.7663\n",
            "Epoch 88/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4147 - accuracy: 0.7862 - val_loss: 0.4909 - val_accuracy: 0.7663\n",
            "Epoch 89/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4128 - accuracy: 0.7971 - val_loss: 0.4895 - val_accuracy: 0.7609\n",
            "Epoch 90/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4118 - accuracy: 0.7862 - val_loss: 0.4907 - val_accuracy: 0.7609\n",
            "Epoch 91/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4115 - accuracy: 0.8007 - val_loss: 0.4869 - val_accuracy: 0.7609\n",
            "Epoch 92/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4100 - accuracy: 0.8007 - val_loss: 0.4902 - val_accuracy: 0.7609\n",
            "Epoch 93/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4091 - accuracy: 0.8043 - val_loss: 0.4905 - val_accuracy: 0.7609\n",
            "Epoch 94/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4088 - accuracy: 0.7971 - val_loss: 0.4914 - val_accuracy: 0.7609\n",
            "Epoch 95/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4085 - accuracy: 0.8152 - val_loss: 0.4961 - val_accuracy: 0.7609\n",
            "Epoch 96/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4105 - accuracy: 0.7899 - val_loss: 0.4999 - val_accuracy: 0.7609\n",
            "Epoch 97/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4039 - accuracy: 0.8043 - val_loss: 0.4923 - val_accuracy: 0.7663\n",
            "Epoch 98/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4053 - accuracy: 0.8043 - val_loss: 0.5003 - val_accuracy: 0.7554\n",
            "Epoch 99/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4029 - accuracy: 0.7971 - val_loss: 0.4935 - val_accuracy: 0.7663\n",
            "Epoch 100/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4027 - accuracy: 0.8080 - val_loss: 0.4962 - val_accuracy: 0.7663\n",
            "Epoch 101/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3994 - accuracy: 0.8152 - val_loss: 0.4946 - val_accuracy: 0.7663\n",
            "Epoch 102/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3996 - accuracy: 0.8152 - val_loss: 0.4980 - val_accuracy: 0.7609\n",
            "Epoch 103/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4006 - accuracy: 0.8080 - val_loss: 0.4978 - val_accuracy: 0.7609\n",
            "Epoch 104/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4009 - accuracy: 0.8116 - val_loss: 0.4969 - val_accuracy: 0.7609\n",
            "Epoch 105/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3963 - accuracy: 0.8043 - val_loss: 0.4999 - val_accuracy: 0.7663\n",
            "Epoch 106/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3967 - accuracy: 0.8116 - val_loss: 0.5004 - val_accuracy: 0.7609\n",
            "Epoch 107/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3955 - accuracy: 0.8080 - val_loss: 0.5050 - val_accuracy: 0.7609\n",
            "Epoch 108/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3943 - accuracy: 0.8152 - val_loss: 0.5012 - val_accuracy: 0.7663\n",
            "Epoch 109/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3979 - accuracy: 0.8116 - val_loss: 0.5025 - val_accuracy: 0.7609\n",
            "Epoch 110/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3946 - accuracy: 0.8116 - val_loss: 0.5051 - val_accuracy: 0.7609\n",
            "Epoch 111/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3937 - accuracy: 0.7971 - val_loss: 0.4971 - val_accuracy: 0.7717\n",
            "Epoch 112/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3941 - accuracy: 0.8116 - val_loss: 0.5049 - val_accuracy: 0.7609\n",
            "Epoch 113/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3911 - accuracy: 0.8116 - val_loss: 0.5069 - val_accuracy: 0.7609\n",
            "Epoch 114/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3892 - accuracy: 0.8116 - val_loss: 0.5047 - val_accuracy: 0.7609\n",
            "Epoch 115/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3885 - accuracy: 0.8188 - val_loss: 0.5045 - val_accuracy: 0.7609\n",
            "Epoch 116/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3882 - accuracy: 0.8152 - val_loss: 0.5115 - val_accuracy: 0.7609\n",
            "Epoch 117/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3907 - accuracy: 0.8188 - val_loss: 0.5055 - val_accuracy: 0.7663\n",
            "Epoch 118/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3864 - accuracy: 0.8188 - val_loss: 0.5113 - val_accuracy: 0.7609\n",
            "Epoch 119/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3879 - accuracy: 0.8080 - val_loss: 0.5129 - val_accuracy: 0.7609\n",
            "Epoch 120/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3884 - accuracy: 0.8225 - val_loss: 0.5118 - val_accuracy: 0.7663\n",
            "Epoch 121/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3881 - accuracy: 0.8297 - val_loss: 0.5107 - val_accuracy: 0.7609\n",
            "Epoch 122/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3843 - accuracy: 0.8225 - val_loss: 0.5152 - val_accuracy: 0.7609\n",
            "Epoch 123/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3838 - accuracy: 0.8152 - val_loss: 0.5154 - val_accuracy: 0.7609\n",
            "Epoch 124/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3847 - accuracy: 0.8152 - val_loss: 0.5139 - val_accuracy: 0.7609\n",
            "Epoch 125/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3862 - accuracy: 0.8333 - val_loss: 0.5178 - val_accuracy: 0.7663\n",
            "Epoch 126/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3815 - accuracy: 0.8152 - val_loss: 0.5254 - val_accuracy: 0.7663\n",
            "Epoch 127/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3804 - accuracy: 0.8261 - val_loss: 0.5213 - val_accuracy: 0.7663\n",
            "Epoch 128/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3783 - accuracy: 0.8188 - val_loss: 0.5312 - val_accuracy: 0.7609\n",
            "Epoch 129/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3796 - accuracy: 0.8225 - val_loss: 0.5229 - val_accuracy: 0.7609\n",
            "Epoch 130/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3816 - accuracy: 0.8261 - val_loss: 0.5255 - val_accuracy: 0.7554\n",
            "Epoch 131/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3767 - accuracy: 0.8261 - val_loss: 0.5230 - val_accuracy: 0.7663\n",
            "Epoch 132/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3781 - accuracy: 0.8188 - val_loss: 0.5263 - val_accuracy: 0.7663\n",
            "Epoch 133/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3768 - accuracy: 0.8225 - val_loss: 0.5241 - val_accuracy: 0.7663\n",
            "Epoch 134/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3783 - accuracy: 0.8116 - val_loss: 0.5293 - val_accuracy: 0.7609\n",
            "Epoch 135/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3792 - accuracy: 0.8116 - val_loss: 0.5258 - val_accuracy: 0.7609\n",
            "Epoch 136/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3883 - accuracy: 0.8152 - val_loss: 0.5266 - val_accuracy: 0.7609\n",
            "Epoch 137/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3798 - accuracy: 0.8370 - val_loss: 0.5277 - val_accuracy: 0.7609\n",
            "Epoch 138/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3765 - accuracy: 0.8225 - val_loss: 0.5324 - val_accuracy: 0.7554\n",
            "Epoch 139/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3757 - accuracy: 0.8297 - val_loss: 0.5292 - val_accuracy: 0.7609\n",
            "Epoch 140/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3735 - accuracy: 0.8333 - val_loss: 0.5250 - val_accuracy: 0.7391\n",
            "Epoch 141/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3718 - accuracy: 0.8188 - val_loss: 0.5411 - val_accuracy: 0.7500\n",
            "Epoch 142/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3805 - accuracy: 0.8261 - val_loss: 0.5395 - val_accuracy: 0.7446\n",
            "Epoch 143/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3754 - accuracy: 0.8188 - val_loss: 0.5353 - val_accuracy: 0.7500\n",
            "Epoch 144/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3758 - accuracy: 0.8333 - val_loss: 0.5306 - val_accuracy: 0.7609\n",
            "Epoch 145/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3710 - accuracy: 0.8333 - val_loss: 0.5374 - val_accuracy: 0.7500\n",
            "Epoch 146/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3721 - accuracy: 0.8225 - val_loss: 0.5331 - val_accuracy: 0.7609\n",
            "Epoch 147/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3702 - accuracy: 0.8370 - val_loss: 0.5350 - val_accuracy: 0.7554\n",
            "Epoch 148/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3726 - accuracy: 0.8370 - val_loss: 0.5367 - val_accuracy: 0.7554\n",
            "Epoch 149/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3692 - accuracy: 0.8406 - val_loss: 0.5497 - val_accuracy: 0.7391\n",
            "Epoch 150/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3755 - accuracy: 0.8297 - val_loss: 0.5392 - val_accuracy: 0.7446\n",
            "Epoch 151/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3681 - accuracy: 0.8370 - val_loss: 0.5407 - val_accuracy: 0.7554\n",
            "Epoch 152/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3681 - accuracy: 0.8297 - val_loss: 0.5325 - val_accuracy: 0.7554\n",
            "Epoch 153/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3663 - accuracy: 0.8370 - val_loss: 0.5425 - val_accuracy: 0.7446\n",
            "Epoch 154/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3684 - accuracy: 0.8261 - val_loss: 0.5422 - val_accuracy: 0.7554\n",
            "Epoch 155/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3681 - accuracy: 0.8261 - val_loss: 0.5517 - val_accuracy: 0.7446\n",
            "Epoch 156/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3691 - accuracy: 0.8297 - val_loss: 0.5357 - val_accuracy: 0.7391\n",
            "Epoch 157/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3686 - accuracy: 0.8406 - val_loss: 0.5427 - val_accuracy: 0.7554\n",
            "Epoch 158/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3647 - accuracy: 0.8333 - val_loss: 0.5348 - val_accuracy: 0.7554\n",
            "Epoch 159/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3653 - accuracy: 0.8333 - val_loss: 0.5534 - val_accuracy: 0.7391\n",
            "Epoch 160/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3659 - accuracy: 0.8370 - val_loss: 0.5432 - val_accuracy: 0.7391\n",
            "Epoch 161/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3666 - accuracy: 0.8478 - val_loss: 0.5495 - val_accuracy: 0.7500\n",
            "Epoch 162/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3705 - accuracy: 0.8333 - val_loss: 0.5536 - val_accuracy: 0.7391\n",
            "Epoch 163/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3624 - accuracy: 0.8261 - val_loss: 0.5469 - val_accuracy: 0.7446\n",
            "Epoch 164/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3621 - accuracy: 0.8370 - val_loss: 0.5547 - val_accuracy: 0.7446\n",
            "Epoch 165/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3635 - accuracy: 0.8406 - val_loss: 0.5488 - val_accuracy: 0.7391\n",
            "Epoch 166/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3637 - accuracy: 0.8406 - val_loss: 0.5515 - val_accuracy: 0.7337\n",
            "Epoch 167/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3628 - accuracy: 0.8442 - val_loss: 0.5520 - val_accuracy: 0.7391\n",
            "Epoch 168/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3584 - accuracy: 0.8333 - val_loss: 0.5597 - val_accuracy: 0.7391\n",
            "Epoch 169/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3594 - accuracy: 0.8370 - val_loss: 0.5475 - val_accuracy: 0.7337\n",
            "Epoch 170/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3633 - accuracy: 0.8442 - val_loss: 0.5507 - val_accuracy: 0.7337\n",
            "Epoch 171/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3701 - accuracy: 0.8152 - val_loss: 0.5528 - val_accuracy: 0.7337\n",
            "Epoch 172/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3759 - accuracy: 0.8225 - val_loss: 0.5582 - val_accuracy: 0.7391\n",
            "Epoch 173/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3588 - accuracy: 0.8406 - val_loss: 0.5596 - val_accuracy: 0.7391\n",
            "Epoch 174/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3580 - accuracy: 0.8406 - val_loss: 0.5548 - val_accuracy: 0.7337\n",
            "Epoch 175/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3598 - accuracy: 0.8442 - val_loss: 0.5630 - val_accuracy: 0.7391\n",
            "Epoch 176/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3588 - accuracy: 0.8333 - val_loss: 0.5560 - val_accuracy: 0.7337\n",
            "Epoch 177/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3576 - accuracy: 0.8333 - val_loss: 0.5522 - val_accuracy: 0.7283\n",
            "Epoch 178/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3575 - accuracy: 0.8406 - val_loss: 0.5545 - val_accuracy: 0.7283\n",
            "Epoch 179/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3563 - accuracy: 0.8478 - val_loss: 0.5631 - val_accuracy: 0.7391\n",
            "Epoch 180/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3561 - accuracy: 0.8406 - val_loss: 0.5592 - val_accuracy: 0.7337\n",
            "Epoch 181/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3592 - accuracy: 0.8333 - val_loss: 0.5549 - val_accuracy: 0.7283\n",
            "Epoch 182/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3607 - accuracy: 0.8333 - val_loss: 0.5592 - val_accuracy: 0.7283\n",
            "Epoch 183/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3695 - accuracy: 0.8297 - val_loss: 0.5730 - val_accuracy: 0.7337\n",
            "Epoch 184/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3595 - accuracy: 0.8370 - val_loss: 0.5525 - val_accuracy: 0.7337\n",
            "Epoch 185/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3594 - accuracy: 0.8333 - val_loss: 0.5620 - val_accuracy: 0.7337\n",
            "Epoch 186/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3550 - accuracy: 0.8406 - val_loss: 0.5618 - val_accuracy: 0.7337\n",
            "Epoch 187/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3561 - accuracy: 0.8406 - val_loss: 0.5736 - val_accuracy: 0.7337\n",
            "Epoch 188/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3564 - accuracy: 0.8225 - val_loss: 0.5516 - val_accuracy: 0.7391\n",
            "Epoch 189/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3650 - accuracy: 0.8370 - val_loss: 0.5608 - val_accuracy: 0.7283\n",
            "Epoch 190/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3573 - accuracy: 0.8442 - val_loss: 0.5613 - val_accuracy: 0.7283\n",
            "Epoch 191/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3544 - accuracy: 0.8370 - val_loss: 0.5566 - val_accuracy: 0.7283\n",
            "Epoch 192/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3516 - accuracy: 0.8478 - val_loss: 0.5648 - val_accuracy: 0.7283\n",
            "Epoch 193/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3486 - accuracy: 0.8442 - val_loss: 0.5746 - val_accuracy: 0.7283\n",
            "Epoch 194/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3514 - accuracy: 0.8442 - val_loss: 0.5691 - val_accuracy: 0.7283\n",
            "Epoch 195/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3518 - accuracy: 0.8370 - val_loss: 0.5652 - val_accuracy: 0.7228\n",
            "Epoch 196/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3501 - accuracy: 0.8406 - val_loss: 0.5676 - val_accuracy: 0.7228\n",
            "Epoch 197/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3537 - accuracy: 0.8333 - val_loss: 0.5783 - val_accuracy: 0.7337\n",
            "Epoch 198/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3608 - accuracy: 0.8370 - val_loss: 0.5711 - val_accuracy: 0.7337\n",
            "Epoch 199/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3528 - accuracy: 0.8406 - val_loss: 0.5726 - val_accuracy: 0.7337\n",
            "Epoch 200/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3566 - accuracy: 0.8478 - val_loss: 0.5660 - val_accuracy: 0.7174\n",
            "Epoch 201/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3495 - accuracy: 0.8406 - val_loss: 0.5709 - val_accuracy: 0.7283\n",
            "Epoch 202/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3623 - accuracy: 0.8370 - val_loss: 0.5636 - val_accuracy: 0.7228\n",
            "Epoch 203/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3580 - accuracy: 0.8370 - val_loss: 0.5711 - val_accuracy: 0.7228\n",
            "Epoch 204/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3479 - accuracy: 0.8406 - val_loss: 0.5639 - val_accuracy: 0.7283\n",
            "Epoch 205/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3508 - accuracy: 0.8370 - val_loss: 0.5764 - val_accuracy: 0.7228\n",
            "Epoch 206/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3557 - accuracy: 0.8370 - val_loss: 0.5840 - val_accuracy: 0.7228\n",
            "Epoch 207/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3444 - accuracy: 0.8370 - val_loss: 0.5706 - val_accuracy: 0.7228\n",
            "Epoch 208/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3459 - accuracy: 0.8333 - val_loss: 0.5710 - val_accuracy: 0.7228\n",
            "Epoch 209/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3443 - accuracy: 0.8297 - val_loss: 0.5818 - val_accuracy: 0.7228\n",
            "Epoch 210/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3462 - accuracy: 0.8370 - val_loss: 0.5775 - val_accuracy: 0.7337\n",
            "Epoch 211/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3449 - accuracy: 0.8406 - val_loss: 0.5848 - val_accuracy: 0.7283\n",
            "Epoch 212/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3463 - accuracy: 0.8333 - val_loss: 0.5694 - val_accuracy: 0.7283\n",
            "Epoch 213/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3477 - accuracy: 0.8442 - val_loss: 0.5821 - val_accuracy: 0.7120\n",
            "Epoch 214/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3418 - accuracy: 0.8406 - val_loss: 0.5707 - val_accuracy: 0.7228\n",
            "Epoch 215/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3443 - accuracy: 0.8333 - val_loss: 0.5692 - val_accuracy: 0.7283\n",
            "Epoch 216/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3468 - accuracy: 0.8370 - val_loss: 0.5727 - val_accuracy: 0.7228\n",
            "Epoch 217/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3425 - accuracy: 0.8406 - val_loss: 0.5750 - val_accuracy: 0.7174\n",
            "Epoch 218/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3429 - accuracy: 0.8370 - val_loss: 0.5739 - val_accuracy: 0.7174\n",
            "Epoch 219/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3429 - accuracy: 0.8297 - val_loss: 0.5847 - val_accuracy: 0.7174\n",
            "Epoch 220/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3421 - accuracy: 0.8370 - val_loss: 0.5865 - val_accuracy: 0.7120\n",
            "Epoch 221/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3413 - accuracy: 0.8406 - val_loss: 0.5878 - val_accuracy: 0.7174\n",
            "Epoch 222/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3442 - accuracy: 0.8406 - val_loss: 0.5728 - val_accuracy: 0.7120\n",
            "Epoch 223/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3412 - accuracy: 0.8442 - val_loss: 0.5857 - val_accuracy: 0.7174\n",
            "Epoch 224/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3384 - accuracy: 0.8406 - val_loss: 0.5773 - val_accuracy: 0.7228\n",
            "Epoch 225/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3394 - accuracy: 0.8370 - val_loss: 0.5861 - val_accuracy: 0.7174\n",
            "Epoch 226/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3403 - accuracy: 0.8370 - val_loss: 0.5784 - val_accuracy: 0.7120\n",
            "Epoch 227/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3495 - accuracy: 0.8333 - val_loss: 0.5847 - val_accuracy: 0.7120\n",
            "Epoch 228/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3492 - accuracy: 0.8188 - val_loss: 0.5872 - val_accuracy: 0.7120\n",
            "Epoch 229/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3389 - accuracy: 0.8370 - val_loss: 0.5667 - val_accuracy: 0.7337\n",
            "Epoch 230/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3503 - accuracy: 0.8442 - val_loss: 0.5726 - val_accuracy: 0.7174\n",
            "Epoch 231/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3453 - accuracy: 0.8333 - val_loss: 0.5772 - val_accuracy: 0.7174\n",
            "Epoch 232/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3406 - accuracy: 0.8297 - val_loss: 0.5852 - val_accuracy: 0.7120\n",
            "Epoch 233/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3423 - accuracy: 0.8442 - val_loss: 0.5784 - val_accuracy: 0.7174\n",
            "Epoch 234/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3382 - accuracy: 0.8333 - val_loss: 0.5893 - val_accuracy: 0.7174\n",
            "Epoch 235/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3427 - accuracy: 0.8442 - val_loss: 0.5786 - val_accuracy: 0.7174\n",
            "Epoch 236/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3374 - accuracy: 0.8442 - val_loss: 0.5823 - val_accuracy: 0.7174\n",
            "Epoch 237/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3412 - accuracy: 0.8406 - val_loss: 0.6006 - val_accuracy: 0.7283\n",
            "Epoch 238/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3370 - accuracy: 0.8406 - val_loss: 0.5871 - val_accuracy: 0.7174\n",
            "Epoch 239/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3395 - accuracy: 0.8514 - val_loss: 0.5806 - val_accuracy: 0.7120\n",
            "Epoch 240/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3402 - accuracy: 0.8370 - val_loss: 0.5850 - val_accuracy: 0.7120\n",
            "Epoch 241/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3337 - accuracy: 0.8442 - val_loss: 0.6032 - val_accuracy: 0.7228\n",
            "Epoch 242/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3392 - accuracy: 0.8370 - val_loss: 0.5861 - val_accuracy: 0.7120\n",
            "Epoch 243/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3336 - accuracy: 0.8333 - val_loss: 0.5915 - val_accuracy: 0.7120\n",
            "Epoch 244/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3362 - accuracy: 0.8514 - val_loss: 0.5900 - val_accuracy: 0.7120\n",
            "Epoch 245/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3344 - accuracy: 0.8297 - val_loss: 0.5964 - val_accuracy: 0.7174\n",
            "Epoch 246/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3350 - accuracy: 0.8406 - val_loss: 0.5937 - val_accuracy: 0.7120\n",
            "Epoch 247/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3319 - accuracy: 0.8370 - val_loss: 0.5966 - val_accuracy: 0.7174\n",
            "Epoch 248/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3350 - accuracy: 0.8333 - val_loss: 0.5988 - val_accuracy: 0.7120\n",
            "Epoch 249/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3458 - accuracy: 0.8297 - val_loss: 0.5873 - val_accuracy: 0.7065\n",
            "Epoch 250/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3404 - accuracy: 0.8406 - val_loss: 0.5918 - val_accuracy: 0.7174\n",
            "Epoch 251/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3436 - accuracy: 0.8370 - val_loss: 0.5959 - val_accuracy: 0.7120\n",
            "Epoch 252/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3353 - accuracy: 0.8478 - val_loss: 0.5972 - val_accuracy: 0.7065\n",
            "Epoch 253/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3337 - accuracy: 0.8406 - val_loss: 0.6063 - val_accuracy: 0.7120\n",
            "Epoch 254/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3354 - accuracy: 0.8514 - val_loss: 0.5860 - val_accuracy: 0.7065\n",
            "Epoch 255/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3444 - accuracy: 0.8297 - val_loss: 0.6057 - val_accuracy: 0.7228\n",
            "Epoch 256/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3364 - accuracy: 0.8478 - val_loss: 0.5876 - val_accuracy: 0.7065\n",
            "Epoch 257/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3294 - accuracy: 0.8442 - val_loss: 0.5897 - val_accuracy: 0.7174\n",
            "Epoch 258/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3317 - accuracy: 0.8370 - val_loss: 0.5976 - val_accuracy: 0.7174\n",
            "Epoch 259/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3283 - accuracy: 0.8478 - val_loss: 0.5886 - val_accuracy: 0.7065\n",
            "Epoch 260/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3317 - accuracy: 0.8478 - val_loss: 0.5925 - val_accuracy: 0.7174\n",
            "Epoch 261/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3317 - accuracy: 0.8551 - val_loss: 0.5972 - val_accuracy: 0.7065\n",
            "Epoch 262/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3299 - accuracy: 0.8406 - val_loss: 0.5956 - val_accuracy: 0.7174\n",
            "Epoch 263/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3355 - accuracy: 0.8333 - val_loss: 0.5883 - val_accuracy: 0.7283\n",
            "Epoch 264/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3263 - accuracy: 0.8406 - val_loss: 0.6028 - val_accuracy: 0.7174\n",
            "Epoch 265/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3282 - accuracy: 0.8442 - val_loss: 0.5957 - val_accuracy: 0.7120\n",
            "Epoch 266/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3263 - accuracy: 0.8514 - val_loss: 0.6017 - val_accuracy: 0.7120\n",
            "Epoch 267/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3312 - accuracy: 0.8370 - val_loss: 0.6059 - val_accuracy: 0.7228\n",
            "Epoch 268/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3268 - accuracy: 0.8478 - val_loss: 0.6045 - val_accuracy: 0.7174\n",
            "Epoch 269/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3275 - accuracy: 0.8406 - val_loss: 0.5985 - val_accuracy: 0.7120\n",
            "Epoch 270/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3259 - accuracy: 0.8478 - val_loss: 0.6033 - val_accuracy: 0.7174\n",
            "Epoch 271/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3260 - accuracy: 0.8478 - val_loss: 0.6061 - val_accuracy: 0.7120\n",
            "Epoch 272/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3292 - accuracy: 0.8406 - val_loss: 0.5989 - val_accuracy: 0.7120\n",
            "Epoch 273/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3263 - accuracy: 0.8442 - val_loss: 0.6117 - val_accuracy: 0.7174\n",
            "Epoch 274/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3322 - accuracy: 0.8333 - val_loss: 0.6113 - val_accuracy: 0.7174\n",
            "Epoch 275/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3280 - accuracy: 0.8514 - val_loss: 0.6062 - val_accuracy: 0.7174\n",
            "Epoch 276/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3249 - accuracy: 0.8514 - val_loss: 0.6110 - val_accuracy: 0.7174\n",
            "Epoch 277/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3246 - accuracy: 0.8551 - val_loss: 0.6082 - val_accuracy: 0.7120\n",
            "Epoch 278/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3243 - accuracy: 0.8442 - val_loss: 0.6048 - val_accuracy: 0.7174\n",
            "Epoch 279/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3294 - accuracy: 0.8551 - val_loss: 0.6048 - val_accuracy: 0.7228\n",
            "Epoch 280/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3218 - accuracy: 0.8478 - val_loss: 0.5921 - val_accuracy: 0.7283\n",
            "Epoch 281/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3284 - accuracy: 0.8333 - val_loss: 0.6241 - val_accuracy: 0.7337\n",
            "Epoch 282/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3391 - accuracy: 0.8370 - val_loss: 0.5905 - val_accuracy: 0.7391\n",
            "Epoch 283/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3343 - accuracy: 0.8333 - val_loss: 0.6049 - val_accuracy: 0.7120\n",
            "Epoch 284/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3466 - accuracy: 0.8261 - val_loss: 0.5853 - val_accuracy: 0.7446\n",
            "Epoch 285/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3247 - accuracy: 0.8406 - val_loss: 0.6095 - val_accuracy: 0.7174\n",
            "Epoch 286/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3244 - accuracy: 0.8406 - val_loss: 0.5970 - val_accuracy: 0.7120\n",
            "Epoch 287/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3264 - accuracy: 0.8478 - val_loss: 0.6033 - val_accuracy: 0.7174\n",
            "Epoch 288/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3418 - accuracy: 0.8333 - val_loss: 0.6100 - val_accuracy: 0.7174\n",
            "Epoch 289/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3490 - accuracy: 0.8225 - val_loss: 0.5919 - val_accuracy: 0.7228\n",
            "Epoch 290/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3236 - accuracy: 0.8442 - val_loss: 0.5948 - val_accuracy: 0.7174\n",
            "Epoch 291/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3231 - accuracy: 0.8514 - val_loss: 0.6088 - val_accuracy: 0.7120\n",
            "Epoch 292/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3191 - accuracy: 0.8551 - val_loss: 0.5981 - val_accuracy: 0.7120\n",
            "Epoch 293/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3218 - accuracy: 0.8442 - val_loss: 0.6043 - val_accuracy: 0.7174\n",
            "Epoch 294/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3193 - accuracy: 0.8478 - val_loss: 0.6081 - val_accuracy: 0.7120\n",
            "Epoch 295/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3196 - accuracy: 0.8478 - val_loss: 0.6079 - val_accuracy: 0.7174\n",
            "Epoch 296/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3205 - accuracy: 0.8478 - val_loss: 0.6155 - val_accuracy: 0.7174\n",
            "Epoch 297/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3191 - accuracy: 0.8551 - val_loss: 0.6074 - val_accuracy: 0.7120\n",
            "Epoch 298/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3188 - accuracy: 0.8478 - val_loss: 0.6054 - val_accuracy: 0.7174\n",
            "Epoch 299/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3199 - accuracy: 0.8478 - val_loss: 0.6189 - val_accuracy: 0.7174\n",
            "Epoch 300/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3295 - accuracy: 0.8587 - val_loss: 0.6143 - val_accuracy: 0.7228\n",
            "Epoch 301/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3414 - accuracy: 0.8333 - val_loss: 0.6067 - val_accuracy: 0.7174\n",
            "Epoch 302/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3292 - accuracy: 0.8406 - val_loss: 0.5978 - val_accuracy: 0.7283\n",
            "Epoch 303/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3174 - accuracy: 0.8478 - val_loss: 0.6169 - val_accuracy: 0.7174\n",
            "Epoch 304/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3256 - accuracy: 0.8442 - val_loss: 0.6025 - val_accuracy: 0.7228\n",
            "Epoch 305/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3197 - accuracy: 0.8551 - val_loss: 0.6067 - val_accuracy: 0.7174\n",
            "Epoch 306/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3168 - accuracy: 0.8514 - val_loss: 0.6123 - val_accuracy: 0.7174\n",
            "Epoch 307/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3180 - accuracy: 0.8442 - val_loss: 0.6054 - val_accuracy: 0.7174\n",
            "Epoch 308/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3235 - accuracy: 0.8406 - val_loss: 0.6115 - val_accuracy: 0.7120\n",
            "Epoch 309/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3156 - accuracy: 0.8623 - val_loss: 0.6057 - val_accuracy: 0.7228\n",
            "Epoch 310/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3158 - accuracy: 0.8587 - val_loss: 0.6133 - val_accuracy: 0.7120\n",
            "Epoch 311/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3160 - accuracy: 0.8587 - val_loss: 0.6217 - val_accuracy: 0.7120\n",
            "Epoch 312/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3207 - accuracy: 0.8514 - val_loss: 0.6079 - val_accuracy: 0.7174\n",
            "Epoch 313/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3146 - accuracy: 0.8587 - val_loss: 0.6207 - val_accuracy: 0.7120\n",
            "Epoch 314/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3178 - accuracy: 0.8587 - val_loss: 0.6017 - val_accuracy: 0.7283\n",
            "Epoch 315/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3173 - accuracy: 0.8587 - val_loss: 0.6172 - val_accuracy: 0.7174\n",
            "Epoch 316/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3171 - accuracy: 0.8514 - val_loss: 0.6096 - val_accuracy: 0.7228\n",
            "Epoch 317/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3146 - accuracy: 0.8551 - val_loss: 0.6064 - val_accuracy: 0.7174\n",
            "Epoch 318/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3144 - accuracy: 0.8659 - val_loss: 0.6155 - val_accuracy: 0.7120\n",
            "Epoch 319/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3149 - accuracy: 0.8587 - val_loss: 0.6090 - val_accuracy: 0.7228\n",
            "Epoch 320/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3212 - accuracy: 0.8333 - val_loss: 0.6231 - val_accuracy: 0.7228\n",
            "Epoch 321/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3215 - accuracy: 0.8442 - val_loss: 0.6007 - val_accuracy: 0.7391\n",
            "Epoch 322/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3158 - accuracy: 0.8587 - val_loss: 0.6194 - val_accuracy: 0.7174\n",
            "Epoch 323/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3145 - accuracy: 0.8623 - val_loss: 0.6178 - val_accuracy: 0.7228\n",
            "Epoch 324/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3159 - accuracy: 0.8514 - val_loss: 0.6271 - val_accuracy: 0.7120\n",
            "Epoch 325/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3221 - accuracy: 0.8587 - val_loss: 0.6135 - val_accuracy: 0.7228\n",
            "Epoch 326/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3161 - accuracy: 0.8551 - val_loss: 0.6096 - val_accuracy: 0.7228\n",
            "Epoch 327/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3222 - accuracy: 0.8587 - val_loss: 0.6145 - val_accuracy: 0.7174\n",
            "Epoch 328/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3145 - accuracy: 0.8623 - val_loss: 0.6181 - val_accuracy: 0.7228\n",
            "Epoch 329/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3230 - accuracy: 0.8478 - val_loss: 0.6025 - val_accuracy: 0.7446\n",
            "Epoch 330/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3283 - accuracy: 0.8514 - val_loss: 0.6212 - val_accuracy: 0.7174\n",
            "Epoch 331/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3140 - accuracy: 0.8659 - val_loss: 0.6150 - val_accuracy: 0.7228\n",
            "Epoch 332/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3128 - accuracy: 0.8514 - val_loss: 0.6194 - val_accuracy: 0.7120\n",
            "Epoch 333/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3141 - accuracy: 0.8514 - val_loss: 0.6222 - val_accuracy: 0.7174\n",
            "Epoch 334/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3138 - accuracy: 0.8659 - val_loss: 0.6177 - val_accuracy: 0.7228\n",
            "Epoch 335/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3141 - accuracy: 0.8551 - val_loss: 0.6239 - val_accuracy: 0.7120\n",
            "Epoch 336/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3111 - accuracy: 0.8514 - val_loss: 0.6219 - val_accuracy: 0.7174\n",
            "Epoch 337/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3144 - accuracy: 0.8551 - val_loss: 0.6100 - val_accuracy: 0.7337\n",
            "Epoch 338/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3124 - accuracy: 0.8514 - val_loss: 0.6317 - val_accuracy: 0.7120\n",
            "Epoch 339/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3164 - accuracy: 0.8514 - val_loss: 0.6183 - val_accuracy: 0.7228\n",
            "Epoch 340/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3139 - accuracy: 0.8551 - val_loss: 0.6252 - val_accuracy: 0.7174\n",
            "Epoch 341/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3129 - accuracy: 0.8587 - val_loss: 0.6131 - val_accuracy: 0.7337\n",
            "Epoch 342/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3105 - accuracy: 0.8659 - val_loss: 0.6279 - val_accuracy: 0.7120\n",
            "Epoch 343/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3120 - accuracy: 0.8587 - val_loss: 0.6281 - val_accuracy: 0.7174\n",
            "Epoch 344/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3226 - accuracy: 0.8623 - val_loss: 0.6446 - val_accuracy: 0.7228\n",
            "Epoch 345/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3155 - accuracy: 0.8406 - val_loss: 0.6201 - val_accuracy: 0.7174\n",
            "Epoch 346/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3176 - accuracy: 0.8551 - val_loss: 0.6133 - val_accuracy: 0.7337\n",
            "Epoch 347/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3159 - accuracy: 0.8587 - val_loss: 0.6224 - val_accuracy: 0.7283\n",
            "Epoch 348/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3085 - accuracy: 0.8551 - val_loss: 0.6199 - val_accuracy: 0.7283\n",
            "Epoch 349/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3102 - accuracy: 0.8551 - val_loss: 0.6236 - val_accuracy: 0.7174\n",
            "Epoch 350/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3223 - accuracy: 0.8442 - val_loss: 0.6310 - val_accuracy: 0.7228\n",
            "Epoch 351/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3088 - accuracy: 0.8659 - val_loss: 0.6225 - val_accuracy: 0.7228\n",
            "Epoch 352/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3087 - accuracy: 0.8623 - val_loss: 0.6214 - val_accuracy: 0.7120\n",
            "Epoch 353/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3093 - accuracy: 0.8623 - val_loss: 0.6299 - val_accuracy: 0.7228\n",
            "Epoch 354/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3138 - accuracy: 0.8659 - val_loss: 0.6446 - val_accuracy: 0.7174\n",
            "Epoch 355/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3088 - accuracy: 0.8623 - val_loss: 0.6250 - val_accuracy: 0.7174\n",
            "Epoch 356/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3204 - accuracy: 0.8659 - val_loss: 0.6437 - val_accuracy: 0.7283\n",
            "Epoch 357/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3084 - accuracy: 0.8587 - val_loss: 0.6272 - val_accuracy: 0.7228\n",
            "Epoch 358/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3104 - accuracy: 0.8623 - val_loss: 0.6334 - val_accuracy: 0.7174\n",
            "Epoch 359/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3151 - accuracy: 0.8587 - val_loss: 0.6328 - val_accuracy: 0.7228\n",
            "Epoch 360/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3097 - accuracy: 0.8659 - val_loss: 0.6313 - val_accuracy: 0.7228\n",
            "Epoch 361/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3107 - accuracy: 0.8551 - val_loss: 0.6379 - val_accuracy: 0.7174\n",
            "Epoch 362/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3182 - accuracy: 0.8551 - val_loss: 0.6567 - val_accuracy: 0.7228\n",
            "Epoch 363/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3090 - accuracy: 0.8659 - val_loss: 0.6341 - val_accuracy: 0.7283\n",
            "Epoch 364/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3074 - accuracy: 0.8551 - val_loss: 0.6317 - val_accuracy: 0.7283\n",
            "Epoch 365/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3092 - accuracy: 0.8623 - val_loss: 0.6175 - val_accuracy: 0.7283\n",
            "Epoch 366/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3172 - accuracy: 0.8478 - val_loss: 0.6553 - val_accuracy: 0.7120\n",
            "Epoch 367/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3332 - accuracy: 0.8442 - val_loss: 0.6227 - val_accuracy: 0.7337\n",
            "Epoch 368/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3122 - accuracy: 0.8551 - val_loss: 0.6382 - val_accuracy: 0.7174\n",
            "Epoch 369/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3103 - accuracy: 0.8659 - val_loss: 0.6370 - val_accuracy: 0.7228\n",
            "Epoch 370/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3112 - accuracy: 0.8587 - val_loss: 0.6326 - val_accuracy: 0.7228\n",
            "Epoch 371/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3095 - accuracy: 0.8587 - val_loss: 0.6385 - val_accuracy: 0.7174\n",
            "Epoch 372/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3343 - accuracy: 0.8297 - val_loss: 0.6273 - val_accuracy: 0.7228\n",
            "Epoch 373/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3251 - accuracy: 0.8442 - val_loss: 0.6471 - val_accuracy: 0.7228\n",
            "Epoch 374/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3078 - accuracy: 0.8623 - val_loss: 0.6408 - val_accuracy: 0.7174\n",
            "Epoch 375/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3050 - accuracy: 0.8623 - val_loss: 0.6324 - val_accuracy: 0.7337\n",
            "Epoch 376/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3052 - accuracy: 0.8659 - val_loss: 0.6355 - val_accuracy: 0.7228\n",
            "Epoch 377/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3055 - accuracy: 0.8696 - val_loss: 0.6340 - val_accuracy: 0.7283\n",
            "Epoch 378/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3057 - accuracy: 0.8587 - val_loss: 0.6384 - val_accuracy: 0.7228\n",
            "Epoch 379/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3120 - accuracy: 0.8659 - val_loss: 0.6290 - val_accuracy: 0.7228\n",
            "Epoch 380/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3144 - accuracy: 0.8514 - val_loss: 0.6561 - val_accuracy: 0.7120\n",
            "Epoch 381/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3073 - accuracy: 0.8732 - val_loss: 0.6334 - val_accuracy: 0.7283\n",
            "Epoch 382/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3084 - accuracy: 0.8623 - val_loss: 0.6241 - val_accuracy: 0.7391\n",
            "Epoch 383/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3049 - accuracy: 0.8659 - val_loss: 0.6451 - val_accuracy: 0.7120\n",
            "Epoch 384/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3130 - accuracy: 0.8551 - val_loss: 0.6361 - val_accuracy: 0.7337\n",
            "Epoch 385/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3034 - accuracy: 0.8659 - val_loss: 0.6415 - val_accuracy: 0.7228\n",
            "Epoch 386/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3041 - accuracy: 0.8623 - val_loss: 0.6429 - val_accuracy: 0.7174\n",
            "Epoch 387/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3019 - accuracy: 0.8732 - val_loss: 0.6338 - val_accuracy: 0.7228\n",
            "Epoch 388/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3056 - accuracy: 0.8696 - val_loss: 0.6367 - val_accuracy: 0.7228\n",
            "Epoch 389/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3056 - accuracy: 0.8659 - val_loss: 0.6573 - val_accuracy: 0.7174\n",
            "Epoch 390/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3050 - accuracy: 0.8696 - val_loss: 0.6316 - val_accuracy: 0.7228\n",
            "Epoch 391/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3091 - accuracy: 0.8587 - val_loss: 0.6460 - val_accuracy: 0.7174\n",
            "Epoch 392/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3119 - accuracy: 0.8623 - val_loss: 0.6292 - val_accuracy: 0.7283\n",
            "Epoch 393/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3013 - accuracy: 0.8623 - val_loss: 0.6438 - val_accuracy: 0.7228\n",
            "Epoch 394/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3081 - accuracy: 0.8587 - val_loss: 0.6293 - val_accuracy: 0.7283\n",
            "Epoch 395/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3022 - accuracy: 0.8659 - val_loss: 0.6454 - val_accuracy: 0.7174\n",
            "Epoch 396/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3031 - accuracy: 0.8587 - val_loss: 0.6316 - val_accuracy: 0.7283\n",
            "Epoch 397/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3012 - accuracy: 0.8623 - val_loss: 0.6548 - val_accuracy: 0.7174\n",
            "Epoch 398/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3072 - accuracy: 0.8623 - val_loss: 0.6536 - val_accuracy: 0.7228\n",
            "Epoch 399/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3058 - accuracy: 0.8696 - val_loss: 0.6353 - val_accuracy: 0.7228\n",
            "Epoch 400/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3037 - accuracy: 0.8732 - val_loss: 0.6453 - val_accuracy: 0.7228\n",
            "Epoch 401/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3024 - accuracy: 0.8659 - val_loss: 0.6488 - val_accuracy: 0.7120\n",
            "Epoch 402/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3023 - accuracy: 0.8696 - val_loss: 0.6544 - val_accuracy: 0.7283\n",
            "Epoch 403/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3036 - accuracy: 0.8732 - val_loss: 0.6420 - val_accuracy: 0.7283\n",
            "Epoch 404/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3073 - accuracy: 0.8659 - val_loss: 0.6457 - val_accuracy: 0.7228\n",
            "Epoch 405/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2989 - accuracy: 0.8659 - val_loss: 0.6604 - val_accuracy: 0.7174\n",
            "Epoch 406/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3051 - accuracy: 0.8732 - val_loss: 0.6316 - val_accuracy: 0.7337\n",
            "Epoch 407/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3029 - accuracy: 0.8587 - val_loss: 0.6274 - val_accuracy: 0.7446\n",
            "Epoch 408/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3003 - accuracy: 0.8659 - val_loss: 0.6522 - val_accuracy: 0.7174\n",
            "Epoch 409/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3158 - accuracy: 0.8587 - val_loss: 0.6382 - val_accuracy: 0.7228\n",
            "Epoch 410/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3235 - accuracy: 0.8514 - val_loss: 0.6406 - val_accuracy: 0.7337\n",
            "Epoch 411/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3047 - accuracy: 0.8587 - val_loss: 0.6437 - val_accuracy: 0.7283\n",
            "Epoch 412/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3095 - accuracy: 0.8696 - val_loss: 0.6636 - val_accuracy: 0.7174\n",
            "Epoch 413/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3065 - accuracy: 0.8551 - val_loss: 0.6457 - val_accuracy: 0.7337\n",
            "Epoch 414/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2997 - accuracy: 0.8696 - val_loss: 0.6612 - val_accuracy: 0.7283\n",
            "Epoch 415/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2982 - accuracy: 0.8841 - val_loss: 0.6491 - val_accuracy: 0.7283\n",
            "Epoch 416/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3010 - accuracy: 0.8732 - val_loss: 0.6484 - val_accuracy: 0.7283\n",
            "Epoch 417/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2979 - accuracy: 0.8659 - val_loss: 0.6532 - val_accuracy: 0.7337\n",
            "Epoch 418/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2981 - accuracy: 0.8587 - val_loss: 0.6443 - val_accuracy: 0.7391\n",
            "Epoch 419/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3002 - accuracy: 0.8587 - val_loss: 0.6519 - val_accuracy: 0.7228\n",
            "Epoch 420/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2990 - accuracy: 0.8696 - val_loss: 0.6504 - val_accuracy: 0.7391\n",
            "Epoch 421/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3026 - accuracy: 0.8732 - val_loss: 0.6365 - val_accuracy: 0.7446\n",
            "Epoch 422/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3131 - accuracy: 0.8551 - val_loss: 0.6796 - val_accuracy: 0.7228\n",
            "Epoch 423/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3031 - accuracy: 0.8696 - val_loss: 0.6482 - val_accuracy: 0.7283\n",
            "Epoch 424/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2984 - accuracy: 0.8659 - val_loss: 0.6509 - val_accuracy: 0.7283\n",
            "Epoch 425/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2975 - accuracy: 0.8659 - val_loss: 0.6555 - val_accuracy: 0.7337\n",
            "Epoch 426/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2959 - accuracy: 0.8696 - val_loss: 0.6571 - val_accuracy: 0.7283\n",
            "Epoch 427/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.2983 - accuracy: 0.8732 - val_loss: 0.6535 - val_accuracy: 0.7337\n",
            "Epoch 428/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.2959 - accuracy: 0.8659 - val_loss: 0.6593 - val_accuracy: 0.7391\n",
            "Epoch 429/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.2977 - accuracy: 0.8696 - val_loss: 0.6688 - val_accuracy: 0.7228\n",
            "Epoch 430/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.2957 - accuracy: 0.8696 - val_loss: 0.6441 - val_accuracy: 0.7391\n",
            "Epoch 431/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2964 - accuracy: 0.8659 - val_loss: 0.6730 - val_accuracy: 0.7283\n",
            "Epoch 432/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2999 - accuracy: 0.8659 - val_loss: 0.6610 - val_accuracy: 0.7283\n",
            "Epoch 433/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3024 - accuracy: 0.8696 - val_loss: 0.6548 - val_accuracy: 0.7337\n",
            "Epoch 434/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2982 - accuracy: 0.8696 - val_loss: 0.6547 - val_accuracy: 0.7391\n",
            "Epoch 435/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3003 - accuracy: 0.8587 - val_loss: 0.6800 - val_accuracy: 0.7283\n",
            "Epoch 436/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2928 - accuracy: 0.8659 - val_loss: 0.6526 - val_accuracy: 0.7337\n",
            "Epoch 437/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2997 - accuracy: 0.8696 - val_loss: 0.6903 - val_accuracy: 0.7228\n",
            "Epoch 438/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3007 - accuracy: 0.8659 - val_loss: 0.6611 - val_accuracy: 0.7446\n",
            "Epoch 439/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2996 - accuracy: 0.8732 - val_loss: 0.6798 - val_accuracy: 0.7283\n",
            "Epoch 440/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2954 - accuracy: 0.8768 - val_loss: 0.6552 - val_accuracy: 0.7391\n",
            "Epoch 441/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.2951 - accuracy: 0.8732 - val_loss: 0.6700 - val_accuracy: 0.7337\n",
            "Epoch 442/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2954 - accuracy: 0.8659 - val_loss: 0.6649 - val_accuracy: 0.7446\n",
            "Epoch 443/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3035 - accuracy: 0.8659 - val_loss: 0.6767 - val_accuracy: 0.7283\n",
            "Epoch 444/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2933 - accuracy: 0.8768 - val_loss: 0.6627 - val_accuracy: 0.7337\n",
            "Epoch 445/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.2963 - accuracy: 0.8732 - val_loss: 0.6783 - val_accuracy: 0.7283\n",
            "Epoch 446/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3036 - accuracy: 0.8768 - val_loss: 0.6700 - val_accuracy: 0.7391\n",
            "Epoch 447/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2978 - accuracy: 0.8804 - val_loss: 0.6665 - val_accuracy: 0.7446\n",
            "Epoch 448/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2909 - accuracy: 0.8768 - val_loss: 0.6545 - val_accuracy: 0.7337\n",
            "Epoch 449/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2920 - accuracy: 0.8732 - val_loss: 0.6653 - val_accuracy: 0.7446\n",
            "Epoch 450/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2939 - accuracy: 0.8841 - val_loss: 0.6723 - val_accuracy: 0.7337\n",
            "Epoch 451/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2917 - accuracy: 0.8804 - val_loss: 0.6669 - val_accuracy: 0.7337\n",
            "Epoch 452/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2899 - accuracy: 0.8841 - val_loss: 0.6617 - val_accuracy: 0.7391\n",
            "Epoch 453/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2904 - accuracy: 0.8804 - val_loss: 0.6618 - val_accuracy: 0.7500\n",
            "Epoch 454/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2982 - accuracy: 0.8659 - val_loss: 0.6875 - val_accuracy: 0.7228\n",
            "Epoch 455/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2974 - accuracy: 0.8732 - val_loss: 0.6895 - val_accuracy: 0.7283\n",
            "Epoch 456/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2947 - accuracy: 0.8732 - val_loss: 0.6817 - val_accuracy: 0.7283\n",
            "Epoch 457/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.2901 - accuracy: 0.8804 - val_loss: 0.6776 - val_accuracy: 0.7446\n",
            "Epoch 458/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2908 - accuracy: 0.8768 - val_loss: 0.6710 - val_accuracy: 0.7500\n",
            "Epoch 459/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2923 - accuracy: 0.8877 - val_loss: 0.6760 - val_accuracy: 0.7391\n",
            "Epoch 460/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3067 - accuracy: 0.8841 - val_loss: 0.6605 - val_accuracy: 0.7391\n",
            "Epoch 461/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3039 - accuracy: 0.8768 - val_loss: 0.6721 - val_accuracy: 0.7228\n",
            "Epoch 462/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3029 - accuracy: 0.8696 - val_loss: 0.6843 - val_accuracy: 0.7283\n",
            "Epoch 463/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2968 - accuracy: 0.8732 - val_loss: 0.6684 - val_accuracy: 0.7337\n",
            "Epoch 464/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2963 - accuracy: 0.8768 - val_loss: 0.6662 - val_accuracy: 0.7337\n",
            "Epoch 465/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2920 - accuracy: 0.8768 - val_loss: 0.6723 - val_accuracy: 0.7391\n",
            "Epoch 466/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2934 - accuracy: 0.8768 - val_loss: 0.6637 - val_accuracy: 0.7337\n",
            "Epoch 467/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2885 - accuracy: 0.8804 - val_loss: 0.6765 - val_accuracy: 0.7337\n",
            "Epoch 468/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2946 - accuracy: 0.8804 - val_loss: 0.6828 - val_accuracy: 0.7283\n",
            "Epoch 469/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.2893 - accuracy: 0.8841 - val_loss: 0.6800 - val_accuracy: 0.7446\n",
            "Epoch 470/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2894 - accuracy: 0.8804 - val_loss: 0.6862 - val_accuracy: 0.7391\n",
            "Epoch 471/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2888 - accuracy: 0.8841 - val_loss: 0.6691 - val_accuracy: 0.7500\n",
            "Epoch 472/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2863 - accuracy: 0.8841 - val_loss: 0.6848 - val_accuracy: 0.7391\n",
            "Epoch 473/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2894 - accuracy: 0.8877 - val_loss: 0.6910 - val_accuracy: 0.7391\n",
            "Epoch 474/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2855 - accuracy: 0.8804 - val_loss: 0.6814 - val_accuracy: 0.7446\n",
            "Epoch 475/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.2879 - accuracy: 0.8768 - val_loss: 0.6949 - val_accuracy: 0.7337\n",
            "Epoch 476/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3018 - accuracy: 0.8587 - val_loss: 0.6719 - val_accuracy: 0.7337\n",
            "Epoch 477/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2973 - accuracy: 0.8768 - val_loss: 0.6830 - val_accuracy: 0.7391\n",
            "Epoch 478/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2897 - accuracy: 0.8732 - val_loss: 0.6757 - val_accuracy: 0.7337\n",
            "Epoch 479/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2947 - accuracy: 0.8804 - val_loss: 0.6721 - val_accuracy: 0.7337\n",
            "Epoch 480/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2854 - accuracy: 0.8841 - val_loss: 0.6916 - val_accuracy: 0.7337\n",
            "Epoch 481/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2859 - accuracy: 0.8768 - val_loss: 0.6809 - val_accuracy: 0.7446\n",
            "Epoch 482/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2843 - accuracy: 0.8877 - val_loss: 0.6816 - val_accuracy: 0.7337\n",
            "Epoch 483/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2845 - accuracy: 0.8841 - val_loss: 0.6935 - val_accuracy: 0.7391\n",
            "Epoch 484/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2860 - accuracy: 0.8841 - val_loss: 0.6773 - val_accuracy: 0.7337\n",
            "Epoch 485/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2865 - accuracy: 0.8804 - val_loss: 0.7004 - val_accuracy: 0.7391\n",
            "Epoch 486/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2845 - accuracy: 0.8804 - val_loss: 0.6914 - val_accuracy: 0.7337\n",
            "Epoch 487/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2887 - accuracy: 0.8913 - val_loss: 0.6841 - val_accuracy: 0.7337\n",
            "Epoch 488/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2865 - accuracy: 0.8877 - val_loss: 0.6913 - val_accuracy: 0.7391\n",
            "Epoch 489/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2841 - accuracy: 0.8877 - val_loss: 0.7056 - val_accuracy: 0.7337\n",
            "Epoch 490/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2919 - accuracy: 0.8841 - val_loss: 0.6825 - val_accuracy: 0.7337\n",
            "Epoch 491/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2844 - accuracy: 0.8913 - val_loss: 0.6915 - val_accuracy: 0.7446\n",
            "Epoch 492/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2859 - accuracy: 0.8877 - val_loss: 0.6893 - val_accuracy: 0.7337\n",
            "Epoch 493/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2867 - accuracy: 0.8949 - val_loss: 0.6881 - val_accuracy: 0.7337\n",
            "Epoch 494/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2827 - accuracy: 0.8841 - val_loss: 0.7031 - val_accuracy: 0.7283\n",
            "Epoch 495/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2830 - accuracy: 0.8877 - val_loss: 0.7023 - val_accuracy: 0.7283\n",
            "Epoch 496/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2862 - accuracy: 0.8877 - val_loss: 0.7130 - val_accuracy: 0.7337\n",
            "Epoch 497/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2843 - accuracy: 0.8877 - val_loss: 0.6897 - val_accuracy: 0.7391\n",
            "Epoch 498/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2850 - accuracy: 0.8877 - val_loss: 0.6951 - val_accuracy: 0.7446\n",
            "Epoch 499/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2860 - accuracy: 0.8768 - val_loss: 0.6937 - val_accuracy: 0.7337\n",
            "Epoch 500/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2889 - accuracy: 0.8804 - val_loss: 0.6950 - val_accuracy: 0.7337\n",
            "Epoch 501/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2859 - accuracy: 0.8877 - val_loss: 0.7203 - val_accuracy: 0.7337\n",
            "Epoch 502/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2865 - accuracy: 0.8841 - val_loss: 0.7025 - val_accuracy: 0.7391\n",
            "Epoch 503/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2858 - accuracy: 0.8877 - val_loss: 0.7049 - val_accuracy: 0.7446\n",
            "Epoch 504/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2822 - accuracy: 0.8877 - val_loss: 0.6953 - val_accuracy: 0.7391\n",
            "Epoch 505/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2825 - accuracy: 0.8913 - val_loss: 0.7121 - val_accuracy: 0.7500\n",
            "Epoch 506/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2970 - accuracy: 0.8659 - val_loss: 0.7068 - val_accuracy: 0.7283\n",
            "Epoch 507/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2825 - accuracy: 0.8804 - val_loss: 0.6819 - val_accuracy: 0.7337\n",
            "Epoch 508/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2961 - accuracy: 0.8659 - val_loss: 0.6893 - val_accuracy: 0.7391\n",
            "Epoch 509/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2831 - accuracy: 0.8913 - val_loss: 0.7082 - val_accuracy: 0.7500\n",
            "Epoch 510/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2932 - accuracy: 0.8841 - val_loss: 0.6898 - val_accuracy: 0.7228\n",
            "Epoch 511/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2834 - accuracy: 0.8841 - val_loss: 0.7150 - val_accuracy: 0.7391\n",
            "Epoch 512/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2812 - accuracy: 0.8949 - val_loss: 0.6950 - val_accuracy: 0.7391\n",
            "Epoch 513/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2808 - accuracy: 0.8877 - val_loss: 0.7086 - val_accuracy: 0.7446\n",
            "Epoch 514/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2887 - accuracy: 0.8841 - val_loss: 0.6945 - val_accuracy: 0.7391\n",
            "Epoch 515/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2850 - accuracy: 0.8841 - val_loss: 0.7207 - val_accuracy: 0.7283\n",
            "Epoch 516/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2915 - accuracy: 0.8732 - val_loss: 0.7063 - val_accuracy: 0.7609\n",
            "Epoch 517/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2889 - accuracy: 0.8768 - val_loss: 0.6916 - val_accuracy: 0.7337\n",
            "Epoch 518/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2877 - accuracy: 0.8877 - val_loss: 0.7135 - val_accuracy: 0.7391\n",
            "Epoch 519/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2800 - accuracy: 0.8949 - val_loss: 0.7012 - val_accuracy: 0.7446\n",
            "Epoch 520/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2896 - accuracy: 0.8841 - val_loss: 0.6942 - val_accuracy: 0.7446\n",
            "Epoch 521/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2872 - accuracy: 0.8804 - val_loss: 0.6913 - val_accuracy: 0.7283\n",
            "Epoch 522/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2971 - accuracy: 0.8587 - val_loss: 0.7155 - val_accuracy: 0.7554\n",
            "Epoch 523/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2839 - accuracy: 0.8804 - val_loss: 0.6961 - val_accuracy: 0.7337\n",
            "Epoch 524/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2890 - accuracy: 0.8696 - val_loss: 0.7123 - val_accuracy: 0.7337\n",
            "Epoch 525/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2834 - accuracy: 0.8877 - val_loss: 0.7095 - val_accuracy: 0.7446\n",
            "Epoch 526/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2804 - accuracy: 0.8841 - val_loss: 0.7048 - val_accuracy: 0.7391\n",
            "Epoch 527/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2772 - accuracy: 0.8986 - val_loss: 0.7095 - val_accuracy: 0.7446\n",
            "Epoch 528/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2789 - accuracy: 0.8949 - val_loss: 0.6890 - val_accuracy: 0.7337\n",
            "Epoch 529/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2806 - accuracy: 0.8949 - val_loss: 0.7098 - val_accuracy: 0.7391\n",
            "Epoch 530/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2802 - accuracy: 0.8986 - val_loss: 0.6988 - val_accuracy: 0.7337\n",
            "Epoch 531/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2791 - accuracy: 0.8949 - val_loss: 0.7039 - val_accuracy: 0.7446\n",
            "Epoch 532/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2797 - accuracy: 0.8949 - val_loss: 0.7145 - val_accuracy: 0.7337\n",
            "Epoch 533/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2771 - accuracy: 0.8986 - val_loss: 0.6996 - val_accuracy: 0.7337\n",
            "Epoch 534/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2796 - accuracy: 0.8877 - val_loss: 0.7238 - val_accuracy: 0.7337\n",
            "Epoch 535/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2890 - accuracy: 0.8732 - val_loss: 0.6971 - val_accuracy: 0.7337\n",
            "Epoch 536/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2791 - accuracy: 0.8877 - val_loss: 0.7283 - val_accuracy: 0.7391\n",
            "Epoch 537/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2819 - accuracy: 0.8841 - val_loss: 0.7002 - val_accuracy: 0.7337\n",
            "Epoch 538/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2881 - accuracy: 0.8913 - val_loss: 0.7211 - val_accuracy: 0.7391\n",
            "Epoch 539/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2806 - accuracy: 0.8986 - val_loss: 0.6937 - val_accuracy: 0.7391\n",
            "Epoch 540/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2871 - accuracy: 0.8804 - val_loss: 0.7007 - val_accuracy: 0.7337\n",
            "Epoch 541/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.2793 - accuracy: 0.8949 - val_loss: 0.7075 - val_accuracy: 0.7337\n",
            "Epoch 542/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2824 - accuracy: 0.8877 - val_loss: 0.7036 - val_accuracy: 0.7337\n",
            "Epoch 543/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2796 - accuracy: 0.8986 - val_loss: 0.7342 - val_accuracy: 0.7391\n",
            "Epoch 544/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2773 - accuracy: 0.8913 - val_loss: 0.7184 - val_accuracy: 0.7391\n",
            "Epoch 545/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.2776 - accuracy: 0.8877 - val_loss: 0.7046 - val_accuracy: 0.7337\n",
            "Epoch 546/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.2754 - accuracy: 0.8986 - val_loss: 0.7247 - val_accuracy: 0.7500\n",
            "Epoch 547/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2774 - accuracy: 0.8877 - val_loss: 0.7119 - val_accuracy: 0.7391\n",
            "Epoch 548/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2769 - accuracy: 0.8913 - val_loss: 0.7097 - val_accuracy: 0.7446\n",
            "Epoch 549/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2748 - accuracy: 0.8949 - val_loss: 0.7085 - val_accuracy: 0.7337\n",
            "Epoch 550/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2756 - accuracy: 0.8986 - val_loss: 0.7184 - val_accuracy: 0.7446\n",
            "Epoch 551/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2770 - accuracy: 0.8986 - val_loss: 0.7093 - val_accuracy: 0.7337\n",
            "Epoch 552/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2739 - accuracy: 0.8986 - val_loss: 0.7119 - val_accuracy: 0.7391\n",
            "Epoch 553/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2792 - accuracy: 0.8877 - val_loss: 0.7090 - val_accuracy: 0.7337\n",
            "Epoch 554/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2758 - accuracy: 0.9022 - val_loss: 0.7143 - val_accuracy: 0.7446\n",
            "Epoch 555/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2839 - accuracy: 0.8877 - val_loss: 0.7045 - val_accuracy: 0.7337\n",
            "Epoch 556/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2731 - accuracy: 0.8949 - val_loss: 0.7247 - val_accuracy: 0.7446\n",
            "Epoch 557/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2750 - accuracy: 0.8986 - val_loss: 0.7168 - val_accuracy: 0.7500\n",
            "Epoch 558/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2738 - accuracy: 0.8986 - val_loss: 0.7064 - val_accuracy: 0.7446\n",
            "Epoch 559/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2748 - accuracy: 0.8986 - val_loss: 0.7070 - val_accuracy: 0.7337\n",
            "Epoch 560/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2760 - accuracy: 0.8949 - val_loss: 0.7302 - val_accuracy: 0.7500\n",
            "Epoch 561/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2793 - accuracy: 0.8949 - val_loss: 0.7144 - val_accuracy: 0.7391\n",
            "Epoch 562/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2723 - accuracy: 0.8949 - val_loss: 0.7165 - val_accuracy: 0.7500\n",
            "Epoch 563/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2793 - accuracy: 0.8877 - val_loss: 0.7150 - val_accuracy: 0.7446\n",
            "Epoch 564/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2896 - accuracy: 0.8986 - val_loss: 0.7533 - val_accuracy: 0.7337\n",
            "Epoch 565/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2811 - accuracy: 0.8913 - val_loss: 0.7134 - val_accuracy: 0.7337\n",
            "Epoch 566/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2728 - accuracy: 0.8949 - val_loss: 0.7229 - val_accuracy: 0.7337\n",
            "Epoch 567/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2720 - accuracy: 0.8986 - val_loss: 0.7213 - val_accuracy: 0.7446\n",
            "Epoch 568/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2725 - accuracy: 0.8986 - val_loss: 0.7268 - val_accuracy: 0.7391\n",
            "Epoch 569/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2721 - accuracy: 0.9022 - val_loss: 0.7149 - val_accuracy: 0.7337\n",
            "Epoch 570/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2725 - accuracy: 0.8986 - val_loss: 0.7204 - val_accuracy: 0.7337\n",
            "Epoch 571/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2733 - accuracy: 0.9022 - val_loss: 0.7242 - val_accuracy: 0.7391\n",
            "Epoch 572/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2747 - accuracy: 0.8913 - val_loss: 0.7168 - val_accuracy: 0.7446\n",
            "Epoch 573/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2749 - accuracy: 0.8986 - val_loss: 0.7384 - val_accuracy: 0.7391\n",
            "Epoch 574/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2708 - accuracy: 0.8986 - val_loss: 0.7177 - val_accuracy: 0.7337\n",
            "Epoch 575/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2704 - accuracy: 0.8986 - val_loss: 0.7270 - val_accuracy: 0.7500\n",
            "Epoch 576/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2700 - accuracy: 0.8949 - val_loss: 0.7194 - val_accuracy: 0.7391\n",
            "Epoch 577/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2755 - accuracy: 0.9058 - val_loss: 0.7195 - val_accuracy: 0.7337\n",
            "Epoch 578/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2794 - accuracy: 0.8877 - val_loss: 0.7212 - val_accuracy: 0.7337\n",
            "Epoch 579/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2783 - accuracy: 0.8949 - val_loss: 0.7462 - val_accuracy: 0.7500\n",
            "Epoch 580/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2747 - accuracy: 0.9022 - val_loss: 0.7150 - val_accuracy: 0.7283\n",
            "Epoch 581/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2758 - accuracy: 0.8949 - val_loss: 0.7315 - val_accuracy: 0.7446\n",
            "Epoch 582/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2777 - accuracy: 0.8949 - val_loss: 0.7279 - val_accuracy: 0.7391\n",
            "Epoch 583/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2736 - accuracy: 0.8877 - val_loss: 0.7268 - val_accuracy: 0.7337\n",
            "Epoch 584/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2751 - accuracy: 0.8949 - val_loss: 0.7166 - val_accuracy: 0.7337\n",
            "Epoch 585/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2710 - accuracy: 0.8949 - val_loss: 0.7262 - val_accuracy: 0.7391\n",
            "Epoch 586/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2749 - accuracy: 0.8913 - val_loss: 0.7484 - val_accuracy: 0.7391\n",
            "Epoch 587/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2780 - accuracy: 0.8913 - val_loss: 0.7292 - val_accuracy: 0.7446\n",
            "Epoch 588/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2699 - accuracy: 0.8949 - val_loss: 0.7237 - val_accuracy: 0.7337\n",
            "Epoch 589/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2731 - accuracy: 0.9058 - val_loss: 0.7404 - val_accuracy: 0.7446\n",
            "Epoch 590/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2731 - accuracy: 0.9022 - val_loss: 0.7205 - val_accuracy: 0.7337\n",
            "Epoch 591/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2695 - accuracy: 0.9022 - val_loss: 0.7319 - val_accuracy: 0.7446\n",
            "Epoch 592/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2711 - accuracy: 0.8986 - val_loss: 0.7218 - val_accuracy: 0.7337\n",
            "Epoch 593/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2732 - accuracy: 0.8913 - val_loss: 0.7262 - val_accuracy: 0.7500\n",
            "Epoch 594/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2697 - accuracy: 0.9022 - val_loss: 0.7255 - val_accuracy: 0.7500\n",
            "Epoch 595/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2783 - accuracy: 0.9058 - val_loss: 0.7419 - val_accuracy: 0.7446\n",
            "Epoch 596/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2728 - accuracy: 0.8986 - val_loss: 0.7099 - val_accuracy: 0.7446\n",
            "Epoch 597/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2723 - accuracy: 0.8913 - val_loss: 0.7335 - val_accuracy: 0.7446\n",
            "Epoch 598/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2698 - accuracy: 0.9058 - val_loss: 0.7264 - val_accuracy: 0.7446\n",
            "Epoch 599/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2739 - accuracy: 0.8986 - val_loss: 0.7416 - val_accuracy: 0.7446\n",
            "Epoch 600/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2806 - accuracy: 0.8913 - val_loss: 0.7440 - val_accuracy: 0.7446\n",
            "Epoch 601/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2871 - accuracy: 0.8913 - val_loss: 0.7169 - val_accuracy: 0.7391\n",
            "Epoch 602/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2773 - accuracy: 0.8841 - val_loss: 0.7360 - val_accuracy: 0.7609\n",
            "Epoch 603/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2819 - accuracy: 0.8986 - val_loss: 0.7223 - val_accuracy: 0.7337\n",
            "Epoch 604/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2709 - accuracy: 0.8986 - val_loss: 0.7384 - val_accuracy: 0.7446\n",
            "Epoch 605/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2717 - accuracy: 0.8986 - val_loss: 0.7291 - val_accuracy: 0.7391\n",
            "Epoch 606/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2676 - accuracy: 0.9022 - val_loss: 0.7507 - val_accuracy: 0.7391\n",
            "Epoch 607/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2831 - accuracy: 0.8913 - val_loss: 0.7546 - val_accuracy: 0.7446\n",
            "Epoch 608/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2761 - accuracy: 0.8841 - val_loss: 0.7264 - val_accuracy: 0.7283\n",
            "Epoch 609/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2708 - accuracy: 0.8986 - val_loss: 0.7486 - val_accuracy: 0.7554\n",
            "Epoch 610/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2889 - accuracy: 0.8841 - val_loss: 0.7450 - val_accuracy: 0.7391\n",
            "Epoch 611/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2820 - accuracy: 0.8949 - val_loss: 0.7308 - val_accuracy: 0.7337\n",
            "Epoch 612/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2709 - accuracy: 0.8913 - val_loss: 0.7390 - val_accuracy: 0.7446\n",
            "Epoch 613/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2812 - accuracy: 0.8986 - val_loss: 0.7575 - val_accuracy: 0.7391\n",
            "Epoch 614/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2914 - accuracy: 0.8696 - val_loss: 0.7136 - val_accuracy: 0.7391\n",
            "Epoch 615/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2767 - accuracy: 0.8949 - val_loss: 0.7638 - val_accuracy: 0.7337\n",
            "Epoch 616/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2702 - accuracy: 0.8986 - val_loss: 0.7281 - val_accuracy: 0.7337\n",
            "Epoch 617/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2787 - accuracy: 0.8804 - val_loss: 0.7272 - val_accuracy: 0.7554\n",
            "Epoch 618/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2695 - accuracy: 0.8986 - val_loss: 0.7357 - val_accuracy: 0.7337\n",
            "Epoch 619/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2653 - accuracy: 0.9022 - val_loss: 0.7209 - val_accuracy: 0.7500\n",
            "Epoch 620/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2674 - accuracy: 0.9022 - val_loss: 0.7184 - val_accuracy: 0.7446\n",
            "Epoch 621/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2682 - accuracy: 0.9094 - val_loss: 0.7307 - val_accuracy: 0.7446\n",
            "Epoch 622/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2653 - accuracy: 0.8986 - val_loss: 0.7368 - val_accuracy: 0.7446\n",
            "Epoch 623/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2684 - accuracy: 0.9058 - val_loss: 0.7382 - val_accuracy: 0.7500\n",
            "Epoch 624/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2664 - accuracy: 0.9058 - val_loss: 0.7261 - val_accuracy: 0.7446\n",
            "Epoch 625/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2646 - accuracy: 0.9022 - val_loss: 0.7494 - val_accuracy: 0.7554\n",
            "Epoch 626/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2645 - accuracy: 0.9058 - val_loss: 0.7293 - val_accuracy: 0.7391\n",
            "Epoch 627/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2641 - accuracy: 0.9094 - val_loss: 0.7439 - val_accuracy: 0.7500\n",
            "Epoch 628/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2649 - accuracy: 0.9022 - val_loss: 0.7439 - val_accuracy: 0.7500\n",
            "Epoch 629/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2668 - accuracy: 0.9022 - val_loss: 0.7430 - val_accuracy: 0.7500\n",
            "Epoch 630/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2678 - accuracy: 0.9022 - val_loss: 0.7320 - val_accuracy: 0.7337\n",
            "Epoch 631/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2656 - accuracy: 0.9022 - val_loss: 0.7476 - val_accuracy: 0.7446\n",
            "Epoch 632/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2620 - accuracy: 0.9058 - val_loss: 0.7185 - val_accuracy: 0.7391\n",
            "Epoch 633/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2664 - accuracy: 0.9022 - val_loss: 0.7393 - val_accuracy: 0.7500\n",
            "Epoch 634/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2645 - accuracy: 0.9094 - val_loss: 0.7285 - val_accuracy: 0.7554\n",
            "Epoch 635/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2653 - accuracy: 0.8949 - val_loss: 0.7563 - val_accuracy: 0.7446\n",
            "Epoch 636/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2682 - accuracy: 0.9058 - val_loss: 0.7267 - val_accuracy: 0.7391\n",
            "Epoch 637/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2683 - accuracy: 0.9094 - val_loss: 0.7673 - val_accuracy: 0.7337\n",
            "Epoch 638/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2606 - accuracy: 0.9058 - val_loss: 0.7263 - val_accuracy: 0.7391\n",
            "Epoch 639/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2673 - accuracy: 0.9022 - val_loss: 0.7439 - val_accuracy: 0.7446\n",
            "Epoch 640/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2643 - accuracy: 0.9022 - val_loss: 0.7407 - val_accuracy: 0.7446\n",
            "Epoch 641/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2660 - accuracy: 0.9022 - val_loss: 0.7373 - val_accuracy: 0.7337\n",
            "Epoch 642/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2623 - accuracy: 0.9022 - val_loss: 0.7443 - val_accuracy: 0.7446\n",
            "Epoch 643/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2651 - accuracy: 0.9094 - val_loss: 0.7445 - val_accuracy: 0.7283\n",
            "Epoch 644/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2695 - accuracy: 0.9022 - val_loss: 0.7482 - val_accuracy: 0.7446\n",
            "Epoch 645/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2657 - accuracy: 0.9022 - val_loss: 0.7253 - val_accuracy: 0.7391\n",
            "Epoch 646/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2665 - accuracy: 0.9058 - val_loss: 0.7356 - val_accuracy: 0.7446\n",
            "Epoch 647/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2612 - accuracy: 0.9022 - val_loss: 0.7451 - val_accuracy: 0.7337\n",
            "Epoch 648/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2638 - accuracy: 0.9022 - val_loss: 0.7380 - val_accuracy: 0.7337\n",
            "Epoch 649/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2649 - accuracy: 0.9058 - val_loss: 0.7375 - val_accuracy: 0.7337\n",
            "Epoch 650/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2661 - accuracy: 0.9022 - val_loss: 0.7663 - val_accuracy: 0.7337\n",
            "Epoch 651/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2665 - accuracy: 0.9094 - val_loss: 0.7400 - val_accuracy: 0.7446\n",
            "Epoch 652/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2657 - accuracy: 0.9130 - val_loss: 0.7287 - val_accuracy: 0.7391\n",
            "Epoch 653/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2616 - accuracy: 0.9058 - val_loss: 0.7520 - val_accuracy: 0.7391\n",
            "Epoch 654/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2644 - accuracy: 0.8986 - val_loss: 0.7447 - val_accuracy: 0.7337\n",
            "Epoch 655/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2775 - accuracy: 0.8949 - val_loss: 0.7591 - val_accuracy: 0.7446\n",
            "Epoch 656/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2670 - accuracy: 0.9058 - val_loss: 0.7549 - val_accuracy: 0.7337\n",
            "Epoch 657/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2697 - accuracy: 0.9058 - val_loss: 0.7415 - val_accuracy: 0.7337\n",
            "Epoch 658/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2700 - accuracy: 0.9058 - val_loss: 0.7468 - val_accuracy: 0.7337\n",
            "Epoch 659/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2639 - accuracy: 0.9022 - val_loss: 0.7448 - val_accuracy: 0.7337\n",
            "Epoch 660/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2611 - accuracy: 0.9058 - val_loss: 0.7494 - val_accuracy: 0.7446\n",
            "Epoch 661/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2671 - accuracy: 0.9094 - val_loss: 0.7635 - val_accuracy: 0.7391\n",
            "Epoch 662/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2630 - accuracy: 0.9058 - val_loss: 0.7510 - val_accuracy: 0.7283\n",
            "Epoch 663/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2615 - accuracy: 0.9058 - val_loss: 0.7527 - val_accuracy: 0.7391\n",
            "Epoch 664/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2635 - accuracy: 0.8986 - val_loss: 0.7634 - val_accuracy: 0.7391\n",
            "Epoch 665/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2630 - accuracy: 0.9094 - val_loss: 0.7470 - val_accuracy: 0.7337\n",
            "Epoch 666/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.2622 - accuracy: 0.9022 - val_loss: 0.7645 - val_accuracy: 0.7391\n",
            "Epoch 667/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2588 - accuracy: 0.9094 - val_loss: 0.7536 - val_accuracy: 0.7391\n",
            "Epoch 668/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2604 - accuracy: 0.9130 - val_loss: 0.7647 - val_accuracy: 0.7337\n",
            "Epoch 669/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2608 - accuracy: 0.9022 - val_loss: 0.7506 - val_accuracy: 0.7337\n",
            "Epoch 670/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2583 - accuracy: 0.9022 - val_loss: 0.7503 - val_accuracy: 0.7391\n",
            "Epoch 671/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2601 - accuracy: 0.9058 - val_loss: 0.7528 - val_accuracy: 0.7283\n",
            "Epoch 672/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2585 - accuracy: 0.9094 - val_loss: 0.7519 - val_accuracy: 0.7283\n",
            "Epoch 673/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2599 - accuracy: 0.9130 - val_loss: 0.7655 - val_accuracy: 0.7446\n",
            "Epoch 674/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2595 - accuracy: 0.9058 - val_loss: 0.7554 - val_accuracy: 0.7446\n",
            "Epoch 675/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2597 - accuracy: 0.9058 - val_loss: 0.7585 - val_accuracy: 0.7446\n",
            "Epoch 676/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2570 - accuracy: 0.9167 - val_loss: 0.7511 - val_accuracy: 0.7500\n",
            "Epoch 677/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2602 - accuracy: 0.9022 - val_loss: 0.7655 - val_accuracy: 0.7446\n",
            "Epoch 678/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2606 - accuracy: 0.9094 - val_loss: 0.7456 - val_accuracy: 0.7337\n",
            "Epoch 679/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2671 - accuracy: 0.8949 - val_loss: 0.7641 - val_accuracy: 0.7391\n",
            "Epoch 680/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2598 - accuracy: 0.9130 - val_loss: 0.7676 - val_accuracy: 0.7391\n",
            "Epoch 681/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2617 - accuracy: 0.9094 - val_loss: 0.7714 - val_accuracy: 0.7391\n",
            "Epoch 682/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2626 - accuracy: 0.9058 - val_loss: 0.7502 - val_accuracy: 0.7500\n",
            "Epoch 683/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2569 - accuracy: 0.9058 - val_loss: 0.7657 - val_accuracy: 0.7337\n",
            "Epoch 684/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2598 - accuracy: 0.9058 - val_loss: 0.7618 - val_accuracy: 0.7446\n",
            "Epoch 685/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2673 - accuracy: 0.8949 - val_loss: 0.7666 - val_accuracy: 0.7283\n",
            "Epoch 686/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2596 - accuracy: 0.9130 - val_loss: 0.7780 - val_accuracy: 0.7391\n",
            "Epoch 687/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2616 - accuracy: 0.9094 - val_loss: 0.7597 - val_accuracy: 0.7337\n",
            "Epoch 688/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2598 - accuracy: 0.8986 - val_loss: 0.7728 - val_accuracy: 0.7337\n",
            "Epoch 689/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2642 - accuracy: 0.9058 - val_loss: 0.7690 - val_accuracy: 0.7337\n",
            "Epoch 690/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2557 - accuracy: 0.9058 - val_loss: 0.7736 - val_accuracy: 0.7391\n",
            "Epoch 691/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2597 - accuracy: 0.9094 - val_loss: 0.7456 - val_accuracy: 0.7391\n",
            "Epoch 692/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2539 - accuracy: 0.9022 - val_loss: 0.7742 - val_accuracy: 0.7228\n",
            "Epoch 693/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2573 - accuracy: 0.9058 - val_loss: 0.7729 - val_accuracy: 0.7283\n",
            "Epoch 694/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2570 - accuracy: 0.9058 - val_loss: 0.7638 - val_accuracy: 0.7337\n",
            "Epoch 695/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2594 - accuracy: 0.9167 - val_loss: 0.7703 - val_accuracy: 0.7283\n",
            "Epoch 696/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2745 - accuracy: 0.8804 - val_loss: 0.7782 - val_accuracy: 0.7391\n",
            "Epoch 697/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2861 - accuracy: 0.8841 - val_loss: 0.7664 - val_accuracy: 0.7337\n",
            "Epoch 698/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2803 - accuracy: 0.8913 - val_loss: 0.7874 - val_accuracy: 0.7337\n",
            "Epoch 699/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2658 - accuracy: 0.8949 - val_loss: 0.7604 - val_accuracy: 0.7337\n",
            "Epoch 700/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2662 - accuracy: 0.9094 - val_loss: 0.7573 - val_accuracy: 0.7283\n",
            "Epoch 701/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2555 - accuracy: 0.9022 - val_loss: 0.7888 - val_accuracy: 0.7391\n",
            "Epoch 702/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2700 - accuracy: 0.8877 - val_loss: 0.7617 - val_accuracy: 0.7228\n",
            "Epoch 703/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2727 - accuracy: 0.8913 - val_loss: 0.7658 - val_accuracy: 0.7283\n",
            "Epoch 704/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2628 - accuracy: 0.8949 - val_loss: 0.7662 - val_accuracy: 0.7391\n",
            "Epoch 705/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2559 - accuracy: 0.9130 - val_loss: 0.7641 - val_accuracy: 0.7337\n",
            "Epoch 706/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2631 - accuracy: 0.9094 - val_loss: 0.7519 - val_accuracy: 0.7283\n",
            "Epoch 707/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2572 - accuracy: 0.9094 - val_loss: 0.7646 - val_accuracy: 0.7337\n",
            "Epoch 708/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2550 - accuracy: 0.9094 - val_loss: 0.7579 - val_accuracy: 0.7337\n",
            "Epoch 709/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2527 - accuracy: 0.9058 - val_loss: 0.7689 - val_accuracy: 0.7228\n",
            "Epoch 710/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2538 - accuracy: 0.9094 - val_loss: 0.7729 - val_accuracy: 0.7337\n",
            "Epoch 711/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2561 - accuracy: 0.9094 - val_loss: 0.7617 - val_accuracy: 0.7337\n",
            "Epoch 712/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2565 - accuracy: 0.9130 - val_loss: 0.7571 - val_accuracy: 0.7337\n",
            "Epoch 713/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2577 - accuracy: 0.9058 - val_loss: 0.7728 - val_accuracy: 0.7337\n",
            "Epoch 714/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2516 - accuracy: 0.9058 - val_loss: 0.7613 - val_accuracy: 0.7337\n",
            "Epoch 715/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2539 - accuracy: 0.9058 - val_loss: 0.7796 - val_accuracy: 0.7391\n",
            "Epoch 716/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2571 - accuracy: 0.9022 - val_loss: 0.7619 - val_accuracy: 0.7337\n",
            "Epoch 717/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2531 - accuracy: 0.9167 - val_loss: 0.7890 - val_accuracy: 0.7283\n",
            "Epoch 718/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2519 - accuracy: 0.9167 - val_loss: 0.7638 - val_accuracy: 0.7337\n",
            "Epoch 719/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2543 - accuracy: 0.9022 - val_loss: 0.7734 - val_accuracy: 0.7228\n",
            "Epoch 720/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2696 - accuracy: 0.8804 - val_loss: 0.7889 - val_accuracy: 0.7283\n",
            "Epoch 721/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2509 - accuracy: 0.9130 - val_loss: 0.7609 - val_accuracy: 0.7337\n",
            "Epoch 722/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2551 - accuracy: 0.9094 - val_loss: 0.7653 - val_accuracy: 0.7337\n",
            "Epoch 723/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2525 - accuracy: 0.9094 - val_loss: 0.7772 - val_accuracy: 0.7337\n",
            "Epoch 724/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2519 - accuracy: 0.9058 - val_loss: 0.7794 - val_accuracy: 0.7228\n",
            "Epoch 725/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2497 - accuracy: 0.9094 - val_loss: 0.7785 - val_accuracy: 0.7337\n",
            "Epoch 726/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2560 - accuracy: 0.9167 - val_loss: 0.7715 - val_accuracy: 0.7228\n",
            "Epoch 727/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2512 - accuracy: 0.9094 - val_loss: 0.7702 - val_accuracy: 0.7337\n",
            "Epoch 728/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2511 - accuracy: 0.9094 - val_loss: 0.7819 - val_accuracy: 0.7228\n",
            "Epoch 729/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2529 - accuracy: 0.9022 - val_loss: 0.7751 - val_accuracy: 0.7337\n",
            "Epoch 730/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2512 - accuracy: 0.9130 - val_loss: 0.7892 - val_accuracy: 0.7337\n",
            "Epoch 731/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2541 - accuracy: 0.9130 - val_loss: 0.7794 - val_accuracy: 0.7283\n",
            "Epoch 732/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2506 - accuracy: 0.8986 - val_loss: 0.7821 - val_accuracy: 0.7283\n",
            "Epoch 733/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2508 - accuracy: 0.9094 - val_loss: 0.7892 - val_accuracy: 0.7228\n",
            "Epoch 734/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2561 - accuracy: 0.8986 - val_loss: 0.8043 - val_accuracy: 0.7283\n",
            "Epoch 735/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2505 - accuracy: 0.9094 - val_loss: 0.7986 - val_accuracy: 0.7228\n",
            "Epoch 736/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2516 - accuracy: 0.9130 - val_loss: 0.7862 - val_accuracy: 0.7228\n",
            "Epoch 737/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2608 - accuracy: 0.8986 - val_loss: 0.7914 - val_accuracy: 0.7391\n",
            "Epoch 738/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2529 - accuracy: 0.9094 - val_loss: 0.7983 - val_accuracy: 0.7337\n",
            "Epoch 739/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2584 - accuracy: 0.9022 - val_loss: 0.7814 - val_accuracy: 0.7228\n",
            "Epoch 740/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2457 - accuracy: 0.9022 - val_loss: 0.7996 - val_accuracy: 0.7283\n",
            "Epoch 741/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2477 - accuracy: 0.9058 - val_loss: 0.7882 - val_accuracy: 0.7391\n",
            "Epoch 742/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2611 - accuracy: 0.8949 - val_loss: 0.8258 - val_accuracy: 0.7283\n",
            "Epoch 743/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2638 - accuracy: 0.8913 - val_loss: 0.7862 - val_accuracy: 0.7446\n",
            "Epoch 744/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2605 - accuracy: 0.9130 - val_loss: 0.8153 - val_accuracy: 0.7283\n",
            "Epoch 745/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.2475 - accuracy: 0.9094 - val_loss: 0.7797 - val_accuracy: 0.7337\n",
            "Epoch 746/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2492 - accuracy: 0.9130 - val_loss: 0.7792 - val_accuracy: 0.7337\n",
            "Epoch 747/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2489 - accuracy: 0.9094 - val_loss: 0.8017 - val_accuracy: 0.7337\n",
            "Epoch 748/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.2496 - accuracy: 0.9058 - val_loss: 0.7901 - val_accuracy: 0.7283\n",
            "Epoch 749/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2489 - accuracy: 0.9130 - val_loss: 0.7940 - val_accuracy: 0.7283\n",
            "Epoch 750/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2517 - accuracy: 0.9058 - val_loss: 0.8011 - val_accuracy: 0.7337\n",
            "Epoch 751/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2601 - accuracy: 0.8986 - val_loss: 0.7745 - val_accuracy: 0.7446\n",
            "Epoch 752/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2538 - accuracy: 0.9094 - val_loss: 0.8191 - val_accuracy: 0.7120\n",
            "Epoch 753/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2461 - accuracy: 0.9094 - val_loss: 0.7966 - val_accuracy: 0.7228\n",
            "Epoch 754/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2454 - accuracy: 0.9094 - val_loss: 0.8089 - val_accuracy: 0.7228\n",
            "Epoch 755/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2491 - accuracy: 0.9094 - val_loss: 0.7930 - val_accuracy: 0.7283\n",
            "Epoch 756/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2503 - accuracy: 0.9130 - val_loss: 0.8072 - val_accuracy: 0.7228\n",
            "Epoch 757/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2428 - accuracy: 0.9094 - val_loss: 0.7903 - val_accuracy: 0.7446\n",
            "Epoch 758/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2466 - accuracy: 0.8986 - val_loss: 0.8128 - val_accuracy: 0.7283\n",
            "Epoch 759/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2557 - accuracy: 0.9022 - val_loss: 0.8030 - val_accuracy: 0.7228\n",
            "Epoch 760/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2565 - accuracy: 0.8986 - val_loss: 0.8188 - val_accuracy: 0.7283\n",
            "Epoch 761/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2508 - accuracy: 0.9167 - val_loss: 0.7921 - val_accuracy: 0.7554\n",
            "Epoch 762/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2469 - accuracy: 0.9022 - val_loss: 0.8119 - val_accuracy: 0.7228\n",
            "Epoch 763/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2472 - accuracy: 0.9130 - val_loss: 0.7909 - val_accuracy: 0.7391\n",
            "Epoch 764/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2481 - accuracy: 0.9022 - val_loss: 0.8102 - val_accuracy: 0.7337\n",
            "Epoch 765/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2500 - accuracy: 0.9094 - val_loss: 0.8199 - val_accuracy: 0.7174\n",
            "Epoch 766/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2461 - accuracy: 0.9022 - val_loss: 0.8021 - val_accuracy: 0.7337\n",
            "Epoch 767/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2476 - accuracy: 0.9130 - val_loss: 0.8072 - val_accuracy: 0.7283\n",
            "Epoch 768/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2530 - accuracy: 0.9058 - val_loss: 0.8044 - val_accuracy: 0.7337\n",
            "Epoch 769/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2500 - accuracy: 0.9130 - val_loss: 0.8094 - val_accuracy: 0.7283\n",
            "Epoch 770/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2456 - accuracy: 0.9130 - val_loss: 0.8233 - val_accuracy: 0.7391\n",
            "Epoch 771/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2501 - accuracy: 0.8986 - val_loss: 0.7987 - val_accuracy: 0.7391\n",
            "Epoch 772/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2460 - accuracy: 0.9130 - val_loss: 0.8084 - val_accuracy: 0.7391\n",
            "Epoch 773/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2430 - accuracy: 0.9058 - val_loss: 0.8230 - val_accuracy: 0.7337\n",
            "Epoch 774/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2427 - accuracy: 0.9167 - val_loss: 0.8157 - val_accuracy: 0.7283\n",
            "Epoch 775/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2466 - accuracy: 0.9130 - val_loss: 0.8381 - val_accuracy: 0.7228\n",
            "Epoch 776/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2457 - accuracy: 0.9167 - val_loss: 0.8169 - val_accuracy: 0.7337\n",
            "Epoch 777/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2437 - accuracy: 0.9022 - val_loss: 0.8112 - val_accuracy: 0.7391\n",
            "Epoch 778/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2454 - accuracy: 0.9094 - val_loss: 0.8169 - val_accuracy: 0.7391\n",
            "Epoch 779/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2513 - accuracy: 0.9203 - val_loss: 0.8042 - val_accuracy: 0.7391\n",
            "Epoch 780/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2421 - accuracy: 0.9058 - val_loss: 0.8233 - val_accuracy: 0.7391\n",
            "Epoch 781/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2495 - accuracy: 0.9058 - val_loss: 0.8165 - val_accuracy: 0.7500\n",
            "Epoch 782/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2516 - accuracy: 0.9022 - val_loss: 0.8476 - val_accuracy: 0.7228\n",
            "Epoch 783/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2463 - accuracy: 0.9094 - val_loss: 0.8093 - val_accuracy: 0.7391\n",
            "Epoch 784/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2472 - accuracy: 0.9167 - val_loss: 0.8217 - val_accuracy: 0.7337\n",
            "Epoch 785/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2416 - accuracy: 0.9094 - val_loss: 0.8171 - val_accuracy: 0.7337\n",
            "Epoch 786/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2480 - accuracy: 0.9094 - val_loss: 0.8173 - val_accuracy: 0.7337\n",
            "Epoch 787/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2410 - accuracy: 0.9130 - val_loss: 0.8197 - val_accuracy: 0.7283\n",
            "Epoch 788/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2426 - accuracy: 0.9022 - val_loss: 0.8343 - val_accuracy: 0.7228\n",
            "Epoch 789/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2440 - accuracy: 0.9167 - val_loss: 0.8232 - val_accuracy: 0.7283\n",
            "Epoch 790/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2419 - accuracy: 0.9130 - val_loss: 0.8316 - val_accuracy: 0.7337\n",
            "Epoch 791/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2424 - accuracy: 0.9094 - val_loss: 0.8170 - val_accuracy: 0.7391\n",
            "Epoch 792/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2433 - accuracy: 0.9130 - val_loss: 0.8225 - val_accuracy: 0.7283\n",
            "Epoch 793/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2528 - accuracy: 0.8949 - val_loss: 0.8511 - val_accuracy: 0.7337\n",
            "Epoch 794/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2467 - accuracy: 0.9058 - val_loss: 0.8508 - val_accuracy: 0.7228\n",
            "Epoch 795/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2459 - accuracy: 0.9094 - val_loss: 0.8289 - val_accuracy: 0.7337\n",
            "Epoch 796/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2433 - accuracy: 0.9022 - val_loss: 0.8353 - val_accuracy: 0.7337\n",
            "Epoch 797/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2604 - accuracy: 0.9058 - val_loss: 0.8341 - val_accuracy: 0.7391\n",
            "Epoch 798/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2526 - accuracy: 0.9094 - val_loss: 0.8647 - val_accuracy: 0.7283\n",
            "Epoch 799/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2494 - accuracy: 0.9130 - val_loss: 0.8309 - val_accuracy: 0.7283\n",
            "Epoch 800/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2506 - accuracy: 0.9167 - val_loss: 0.8379 - val_accuracy: 0.7391\n",
            "Epoch 801/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2480 - accuracy: 0.8949 - val_loss: 0.8649 - val_accuracy: 0.7228\n",
            "Epoch 802/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2666 - accuracy: 0.8949 - val_loss: 0.8250 - val_accuracy: 0.7446\n",
            "Epoch 803/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2476 - accuracy: 0.9094 - val_loss: 0.8503 - val_accuracy: 0.7337\n",
            "Epoch 804/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2395 - accuracy: 0.9167 - val_loss: 0.8284 - val_accuracy: 0.7337\n",
            "Epoch 805/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2438 - accuracy: 0.9094 - val_loss: 0.8614 - val_accuracy: 0.7337\n",
            "Epoch 806/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2432 - accuracy: 0.9130 - val_loss: 0.8217 - val_accuracy: 0.7446\n",
            "Epoch 807/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2431 - accuracy: 0.9058 - val_loss: 0.8373 - val_accuracy: 0.7283\n",
            "Epoch 808/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2409 - accuracy: 0.9130 - val_loss: 0.8188 - val_accuracy: 0.7283\n",
            "Epoch 809/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2497 - accuracy: 0.9022 - val_loss: 0.8286 - val_accuracy: 0.7337\n",
            "Epoch 810/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2442 - accuracy: 0.9058 - val_loss: 0.8364 - val_accuracy: 0.7391\n",
            "Epoch 811/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2563 - accuracy: 0.9022 - val_loss: 0.8318 - val_accuracy: 0.7283\n",
            "Epoch 812/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2417 - accuracy: 0.9167 - val_loss: 0.8307 - val_accuracy: 0.7391\n",
            "Epoch 813/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2409 - accuracy: 0.9058 - val_loss: 0.8404 - val_accuracy: 0.7283\n",
            "Epoch 814/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2423 - accuracy: 0.9130 - val_loss: 0.8297 - val_accuracy: 0.7446\n",
            "Epoch 815/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2448 - accuracy: 0.9203 - val_loss: 0.8490 - val_accuracy: 0.7228\n",
            "Epoch 816/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2387 - accuracy: 0.9058 - val_loss: 0.8315 - val_accuracy: 0.7283\n",
            "Epoch 817/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2411 - accuracy: 0.9022 - val_loss: 0.8393 - val_accuracy: 0.7283\n",
            "Epoch 818/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2393 - accuracy: 0.9058 - val_loss: 0.8491 - val_accuracy: 0.7283\n",
            "Epoch 819/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2449 - accuracy: 0.8986 - val_loss: 0.8374 - val_accuracy: 0.7228\n",
            "Epoch 820/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2356 - accuracy: 0.9022 - val_loss: 0.8613 - val_accuracy: 0.7283\n",
            "Epoch 821/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2400 - accuracy: 0.9094 - val_loss: 0.8466 - val_accuracy: 0.7283\n",
            "Epoch 822/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2405 - accuracy: 0.9167 - val_loss: 0.8484 - val_accuracy: 0.7337\n",
            "Epoch 823/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2440 - accuracy: 0.9022 - val_loss: 0.8489 - val_accuracy: 0.7283\n",
            "Epoch 824/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2387 - accuracy: 0.9203 - val_loss: 0.8440 - val_accuracy: 0.7283\n",
            "Epoch 825/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2404 - accuracy: 0.8949 - val_loss: 0.8491 - val_accuracy: 0.7337\n",
            "Epoch 826/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2365 - accuracy: 0.9167 - val_loss: 0.8536 - val_accuracy: 0.7337\n",
            "Epoch 827/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2350 - accuracy: 0.9094 - val_loss: 0.8767 - val_accuracy: 0.7283\n",
            "Epoch 828/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2387 - accuracy: 0.9130 - val_loss: 0.8550 - val_accuracy: 0.7337\n",
            "Epoch 829/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2367 - accuracy: 0.9130 - val_loss: 0.8648 - val_accuracy: 0.7228\n",
            "Epoch 830/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2383 - accuracy: 0.9094 - val_loss: 0.8531 - val_accuracy: 0.7283\n",
            "Epoch 831/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2350 - accuracy: 0.9167 - val_loss: 0.8515 - val_accuracy: 0.7283\n",
            "Epoch 832/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.2366 - accuracy: 0.9022 - val_loss: 0.8443 - val_accuracy: 0.7283\n",
            "Epoch 833/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2386 - accuracy: 0.9094 - val_loss: 0.8428 - val_accuracy: 0.7446\n",
            "Epoch 834/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2348 - accuracy: 0.9130 - val_loss: 0.8529 - val_accuracy: 0.7446\n",
            "Epoch 835/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2436 - accuracy: 0.9203 - val_loss: 0.8483 - val_accuracy: 0.7391\n",
            "Epoch 836/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2341 - accuracy: 0.9167 - val_loss: 0.8635 - val_accuracy: 0.7337\n",
            "Epoch 837/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.2388 - accuracy: 0.9094 - val_loss: 0.8453 - val_accuracy: 0.7391\n",
            "Epoch 838/1000\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.2415 - accuracy: 0.8986 - val_loss: 0.8691 - val_accuracy: 0.7337\n",
            "Epoch 839/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.2389 - accuracy: 0.9094 - val_loss: 0.8603 - val_accuracy: 0.7391\n",
            "Epoch 840/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.2464 - accuracy: 0.9130 - val_loss: 0.8653 - val_accuracy: 0.7337\n",
            "Epoch 841/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2430 - accuracy: 0.9094 - val_loss: 0.8830 - val_accuracy: 0.7283\n",
            "Epoch 842/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2371 - accuracy: 0.9130 - val_loss: 0.8531 - val_accuracy: 0.7391\n",
            "Epoch 843/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2336 - accuracy: 0.9167 - val_loss: 0.8639 - val_accuracy: 0.7283\n",
            "Epoch 844/1000\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.2353 - accuracy: 0.9130 - val_loss: 0.8794 - val_accuracy: 0.7337\n",
            "Epoch 845/1000\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.2361 - accuracy: 0.9094 - val_loss: 0.8627 - val_accuracy: 0.7283\n",
            "Epoch 846/1000\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.2339 - accuracy: 0.9094 - val_loss: 0.8640 - val_accuracy: 0.7337\n",
            "Epoch 847/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2317 - accuracy: 0.9167 - val_loss: 0.8701 - val_accuracy: 0.7283\n",
            "Epoch 848/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2361 - accuracy: 0.9058 - val_loss: 0.8708 - val_accuracy: 0.7337\n",
            "Epoch 849/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2346 - accuracy: 0.9167 - val_loss: 0.8598 - val_accuracy: 0.7391\n",
            "Epoch 850/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2306 - accuracy: 0.9167 - val_loss: 0.8721 - val_accuracy: 0.7283\n",
            "Epoch 851/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2319 - accuracy: 0.9130 - val_loss: 0.8671 - val_accuracy: 0.7337\n",
            "Epoch 852/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2368 - accuracy: 0.9022 - val_loss: 0.8615 - val_accuracy: 0.7391\n",
            "Epoch 853/1000\n",
            "18/18 [==============================] - 0s 15ms/step - loss: 0.2336 - accuracy: 0.9167 - val_loss: 0.8663 - val_accuracy: 0.7337\n",
            "Epoch 854/1000\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.2395 - accuracy: 0.9058 - val_loss: 0.8813 - val_accuracy: 0.7283\n",
            "Epoch 855/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2364 - accuracy: 0.9094 - val_loss: 0.9046 - val_accuracy: 0.7337\n",
            "Epoch 856/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2347 - accuracy: 0.9094 - val_loss: 0.8700 - val_accuracy: 0.7337\n",
            "Epoch 857/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2334 - accuracy: 0.9094 - val_loss: 0.8842 - val_accuracy: 0.7337\n",
            "Epoch 858/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2353 - accuracy: 0.9094 - val_loss: 0.8683 - val_accuracy: 0.7283\n",
            "Epoch 859/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2363 - accuracy: 0.9094 - val_loss: 0.8662 - val_accuracy: 0.7337\n",
            "Epoch 860/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2385 - accuracy: 0.9058 - val_loss: 0.8756 - val_accuracy: 0.7391\n",
            "Epoch 861/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2314 - accuracy: 0.9167 - val_loss: 0.8826 - val_accuracy: 0.7337\n",
            "Epoch 862/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.2308 - accuracy: 0.9130 - val_loss: 0.8825 - val_accuracy: 0.7283\n",
            "Epoch 863/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2308 - accuracy: 0.9167 - val_loss: 0.8760 - val_accuracy: 0.7337\n",
            "Epoch 864/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2313 - accuracy: 0.9058 - val_loss: 0.8781 - val_accuracy: 0.7337\n",
            "Epoch 865/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2437 - accuracy: 0.9130 - val_loss: 0.8815 - val_accuracy: 0.7283\n",
            "Epoch 866/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2338 - accuracy: 0.9022 - val_loss: 0.8785 - val_accuracy: 0.7337\n",
            "Epoch 867/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2324 - accuracy: 0.9203 - val_loss: 0.8819 - val_accuracy: 0.7337\n",
            "Epoch 868/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2335 - accuracy: 0.9094 - val_loss: 0.8737 - val_accuracy: 0.7337\n",
            "Epoch 869/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2332 - accuracy: 0.9167 - val_loss: 0.8624 - val_accuracy: 0.7391\n",
            "Epoch 870/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2347 - accuracy: 0.9094 - val_loss: 0.8919 - val_accuracy: 0.7391\n",
            "Epoch 871/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2319 - accuracy: 0.9094 - val_loss: 0.8833 - val_accuracy: 0.7337\n",
            "Epoch 872/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2394 - accuracy: 0.9058 - val_loss: 0.8748 - val_accuracy: 0.7337\n",
            "Epoch 873/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2307 - accuracy: 0.9130 - val_loss: 0.8806 - val_accuracy: 0.7337\n",
            "Epoch 874/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2317 - accuracy: 0.9167 - val_loss: 0.8877 - val_accuracy: 0.7391\n",
            "Epoch 875/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2327 - accuracy: 0.9094 - val_loss: 0.8823 - val_accuracy: 0.7283\n",
            "Epoch 876/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2377 - accuracy: 0.9130 - val_loss: 0.8671 - val_accuracy: 0.7554\n",
            "Epoch 877/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2472 - accuracy: 0.9167 - val_loss: 0.9025 - val_accuracy: 0.7337\n",
            "Epoch 878/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2367 - accuracy: 0.9130 - val_loss: 0.8882 - val_accuracy: 0.7337\n",
            "Epoch 879/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2383 - accuracy: 0.9058 - val_loss: 0.8767 - val_accuracy: 0.7446\n",
            "Epoch 880/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.2362 - accuracy: 0.9022 - val_loss: 0.8932 - val_accuracy: 0.7283\n",
            "Epoch 881/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2280 - accuracy: 0.9130 - val_loss: 0.8780 - val_accuracy: 0.7391\n",
            "Epoch 882/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2355 - accuracy: 0.9094 - val_loss: 0.8934 - val_accuracy: 0.7337\n",
            "Epoch 883/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2288 - accuracy: 0.9203 - val_loss: 0.8885 - val_accuracy: 0.7446\n",
            "Epoch 884/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2296 - accuracy: 0.9094 - val_loss: 0.8966 - val_accuracy: 0.7391\n",
            "Epoch 885/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2373 - accuracy: 0.9203 - val_loss: 0.8940 - val_accuracy: 0.7337\n",
            "Epoch 886/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2281 - accuracy: 0.9167 - val_loss: 0.8870 - val_accuracy: 0.7391\n",
            "Epoch 887/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2333 - accuracy: 0.9130 - val_loss: 0.8803 - val_accuracy: 0.7446\n",
            "Epoch 888/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2317 - accuracy: 0.9094 - val_loss: 0.9000 - val_accuracy: 0.7337\n",
            "Epoch 889/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2285 - accuracy: 0.9167 - val_loss: 0.8876 - val_accuracy: 0.7391\n",
            "Epoch 890/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2287 - accuracy: 0.9130 - val_loss: 0.8989 - val_accuracy: 0.7337\n",
            "Epoch 891/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2396 - accuracy: 0.9094 - val_loss: 0.8868 - val_accuracy: 0.7446\n",
            "Epoch 892/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2314 - accuracy: 0.9130 - val_loss: 0.9043 - val_accuracy: 0.7283\n",
            "Epoch 893/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2560 - accuracy: 0.8949 - val_loss: 0.8688 - val_accuracy: 0.7663\n",
            "Epoch 894/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2276 - accuracy: 0.9203 - val_loss: 0.9079 - val_accuracy: 0.7283\n",
            "Epoch 895/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2301 - accuracy: 0.9094 - val_loss: 0.8788 - val_accuracy: 0.7446\n",
            "Epoch 896/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2367 - accuracy: 0.9094 - val_loss: 0.8845 - val_accuracy: 0.7446\n",
            "Epoch 897/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2449 - accuracy: 0.9022 - val_loss: 0.9024 - val_accuracy: 0.7337\n",
            "Epoch 898/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2340 - accuracy: 0.9130 - val_loss: 0.8871 - val_accuracy: 0.7446\n",
            "Epoch 899/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2236 - accuracy: 0.9203 - val_loss: 0.9140 - val_accuracy: 0.7337\n",
            "Epoch 900/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2333 - accuracy: 0.9167 - val_loss: 0.8817 - val_accuracy: 0.7554\n",
            "Epoch 901/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2325 - accuracy: 0.9130 - val_loss: 0.9005 - val_accuracy: 0.7391\n",
            "Epoch 902/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2287 - accuracy: 0.9130 - val_loss: 0.9118 - val_accuracy: 0.7283\n",
            "Epoch 903/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2302 - accuracy: 0.9022 - val_loss: 0.8878 - val_accuracy: 0.7446\n",
            "Epoch 904/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2256 - accuracy: 0.9094 - val_loss: 0.8950 - val_accuracy: 0.7446\n",
            "Epoch 905/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2266 - accuracy: 0.9167 - val_loss: 0.8861 - val_accuracy: 0.7446\n",
            "Epoch 906/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2274 - accuracy: 0.9239 - val_loss: 0.9027 - val_accuracy: 0.7391\n",
            "Epoch 907/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2265 - accuracy: 0.9094 - val_loss: 0.8982 - val_accuracy: 0.7391\n",
            "Epoch 908/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2276 - accuracy: 0.9203 - val_loss: 0.9043 - val_accuracy: 0.7391\n",
            "Epoch 909/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2300 - accuracy: 0.9058 - val_loss: 0.9031 - val_accuracy: 0.7391\n",
            "Epoch 910/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2302 - accuracy: 0.9130 - val_loss: 0.9223 - val_accuracy: 0.7337\n",
            "Epoch 911/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2322 - accuracy: 0.9167 - val_loss: 0.9068 - val_accuracy: 0.7337\n",
            "Epoch 912/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2282 - accuracy: 0.9058 - val_loss: 0.8932 - val_accuracy: 0.7446\n",
            "Epoch 913/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2277 - accuracy: 0.9167 - val_loss: 0.8863 - val_accuracy: 0.7446\n",
            "Epoch 914/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2325 - accuracy: 0.9203 - val_loss: 0.8890 - val_accuracy: 0.7446\n",
            "Epoch 915/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2283 - accuracy: 0.9167 - val_loss: 0.9111 - val_accuracy: 0.7446\n",
            "Epoch 916/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2367 - accuracy: 0.9167 - val_loss: 0.8899 - val_accuracy: 0.7609\n",
            "Epoch 917/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2299 - accuracy: 0.9130 - val_loss: 0.9128 - val_accuracy: 0.7283\n",
            "Epoch 918/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2254 - accuracy: 0.9167 - val_loss: 0.8941 - val_accuracy: 0.7554\n",
            "Epoch 919/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.2255 - accuracy: 0.9130 - val_loss: 0.9235 - val_accuracy: 0.7228\n",
            "Epoch 920/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2451 - accuracy: 0.9058 - val_loss: 0.8985 - val_accuracy: 0.7554\n",
            "Epoch 921/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2288 - accuracy: 0.9094 - val_loss: 0.8995 - val_accuracy: 0.7391\n",
            "Epoch 922/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2229 - accuracy: 0.9203 - val_loss: 0.8904 - val_accuracy: 0.7446\n",
            "Epoch 923/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2251 - accuracy: 0.9167 - val_loss: 0.9092 - val_accuracy: 0.7391\n",
            "Epoch 924/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2335 - accuracy: 0.9058 - val_loss: 0.8923 - val_accuracy: 0.7554\n",
            "Epoch 925/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2283 - accuracy: 0.9167 - val_loss: 0.9055 - val_accuracy: 0.7391\n",
            "Epoch 926/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2238 - accuracy: 0.9167 - val_loss: 0.8943 - val_accuracy: 0.7500\n",
            "Epoch 927/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2199 - accuracy: 0.9167 - val_loss: 0.9301 - val_accuracy: 0.7283\n",
            "Epoch 928/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2302 - accuracy: 0.9094 - val_loss: 0.8995 - val_accuracy: 0.7500\n",
            "Epoch 929/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2267 - accuracy: 0.9058 - val_loss: 0.9025 - val_accuracy: 0.7391\n",
            "Epoch 930/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2223 - accuracy: 0.9167 - val_loss: 0.8950 - val_accuracy: 0.7554\n",
            "Epoch 931/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2255 - accuracy: 0.9022 - val_loss: 0.9169 - val_accuracy: 0.7391\n",
            "Epoch 932/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2304 - accuracy: 0.9094 - val_loss: 0.9070 - val_accuracy: 0.7446\n",
            "Epoch 933/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2259 - accuracy: 0.9130 - val_loss: 0.9140 - val_accuracy: 0.7391\n",
            "Epoch 934/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2268 - accuracy: 0.9130 - val_loss: 0.9035 - val_accuracy: 0.7500\n",
            "Epoch 935/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2238 - accuracy: 0.9130 - val_loss: 0.9053 - val_accuracy: 0.7446\n",
            "Epoch 936/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2248 - accuracy: 0.9167 - val_loss: 0.9137 - val_accuracy: 0.7391\n",
            "Epoch 937/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2235 - accuracy: 0.9167 - val_loss: 0.9113 - val_accuracy: 0.7500\n",
            "Epoch 938/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2215 - accuracy: 0.9130 - val_loss: 0.9212 - val_accuracy: 0.7283\n",
            "Epoch 939/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2306 - accuracy: 0.9094 - val_loss: 0.9061 - val_accuracy: 0.7554\n",
            "Epoch 940/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2522 - accuracy: 0.8768 - val_loss: 0.9272 - val_accuracy: 0.7337\n",
            "Epoch 941/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2459 - accuracy: 0.8949 - val_loss: 0.9231 - val_accuracy: 0.7500\n",
            "Epoch 942/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2375 - accuracy: 0.9022 - val_loss: 0.9227 - val_accuracy: 0.7446\n",
            "Epoch 943/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2385 - accuracy: 0.9022 - val_loss: 0.9079 - val_accuracy: 0.7391\n",
            "Epoch 944/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2266 - accuracy: 0.9167 - val_loss: 0.9068 - val_accuracy: 0.7500\n",
            "Epoch 945/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2419 - accuracy: 0.8949 - val_loss: 0.9363 - val_accuracy: 0.7228\n",
            "Epoch 946/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2393 - accuracy: 0.9022 - val_loss: 0.9021 - val_accuracy: 0.7500\n",
            "Epoch 947/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2404 - accuracy: 0.9058 - val_loss: 0.9115 - val_accuracy: 0.7500\n",
            "Epoch 948/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2301 - accuracy: 0.9022 - val_loss: 0.9053 - val_accuracy: 0.7391\n",
            "Epoch 949/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2244 - accuracy: 0.9167 - val_loss: 0.8990 - val_accuracy: 0.7446\n",
            "Epoch 950/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2200 - accuracy: 0.9203 - val_loss: 0.9107 - val_accuracy: 0.7446\n",
            "Epoch 951/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2281 - accuracy: 0.9058 - val_loss: 0.9163 - val_accuracy: 0.7446\n",
            "Epoch 952/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2221 - accuracy: 0.9058 - val_loss: 0.9213 - val_accuracy: 0.7391\n",
            "Epoch 953/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2206 - accuracy: 0.9167 - val_loss: 0.9151 - val_accuracy: 0.7500\n",
            "Epoch 954/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2222 - accuracy: 0.9203 - val_loss: 0.9162 - val_accuracy: 0.7446\n",
            "Epoch 955/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2212 - accuracy: 0.9130 - val_loss: 0.9152 - val_accuracy: 0.7500\n",
            "Epoch 956/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2196 - accuracy: 0.9167 - val_loss: 0.9250 - val_accuracy: 0.7446\n",
            "Epoch 957/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2222 - accuracy: 0.9167 - val_loss: 0.9144 - val_accuracy: 0.7500\n",
            "Epoch 958/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2249 - accuracy: 0.8986 - val_loss: 0.9201 - val_accuracy: 0.7446\n",
            "Epoch 959/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2232 - accuracy: 0.9058 - val_loss: 0.9260 - val_accuracy: 0.7500\n",
            "Epoch 960/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2237 - accuracy: 0.9094 - val_loss: 0.9345 - val_accuracy: 0.7391\n",
            "Epoch 961/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2283 - accuracy: 0.9094 - val_loss: 0.9330 - val_accuracy: 0.7228\n",
            "Epoch 962/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2275 - accuracy: 0.9167 - val_loss: 0.9345 - val_accuracy: 0.7446\n",
            "Epoch 963/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2218 - accuracy: 0.9094 - val_loss: 0.9123 - val_accuracy: 0.7500\n",
            "Epoch 964/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2330 - accuracy: 0.9094 - val_loss: 0.9292 - val_accuracy: 0.7337\n",
            "Epoch 965/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2193 - accuracy: 0.9167 - val_loss: 0.9248 - val_accuracy: 0.7391\n",
            "Epoch 966/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2212 - accuracy: 0.9130 - val_loss: 0.9195 - val_accuracy: 0.7609\n",
            "Epoch 967/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2237 - accuracy: 0.9167 - val_loss: 0.9349 - val_accuracy: 0.7283\n",
            "Epoch 968/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2301 - accuracy: 0.9058 - val_loss: 0.9148 - val_accuracy: 0.7500\n",
            "Epoch 969/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2281 - accuracy: 0.9094 - val_loss: 0.9198 - val_accuracy: 0.7609\n",
            "Epoch 970/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2307 - accuracy: 0.9022 - val_loss: 0.9426 - val_accuracy: 0.7228\n",
            "Epoch 971/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2210 - accuracy: 0.9094 - val_loss: 0.9126 - val_accuracy: 0.7554\n",
            "Epoch 972/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2200 - accuracy: 0.9167 - val_loss: 0.9349 - val_accuracy: 0.7446\n",
            "Epoch 973/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2242 - accuracy: 0.9022 - val_loss: 0.9277 - val_accuracy: 0.7228\n",
            "Epoch 974/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2207 - accuracy: 0.9167 - val_loss: 0.9145 - val_accuracy: 0.7500\n",
            "Epoch 975/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2238 - accuracy: 0.9094 - val_loss: 0.9471 - val_accuracy: 0.7228\n",
            "Epoch 976/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2243 - accuracy: 0.9130 - val_loss: 0.9230 - val_accuracy: 0.7609\n",
            "Epoch 977/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2223 - accuracy: 0.9130 - val_loss: 0.9213 - val_accuracy: 0.7554\n",
            "Epoch 978/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2273 - accuracy: 0.9058 - val_loss: 0.9366 - val_accuracy: 0.7283\n",
            "Epoch 979/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2246 - accuracy: 0.9094 - val_loss: 0.9216 - val_accuracy: 0.7554\n",
            "Epoch 980/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2186 - accuracy: 0.9167 - val_loss: 0.9239 - val_accuracy: 0.7391\n",
            "Epoch 981/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2208 - accuracy: 0.9130 - val_loss: 0.9381 - val_accuracy: 0.7228\n",
            "Epoch 982/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2202 - accuracy: 0.9094 - val_loss: 0.9258 - val_accuracy: 0.7500\n",
            "Epoch 983/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2223 - accuracy: 0.9094 - val_loss: 0.9284 - val_accuracy: 0.7500\n",
            "Epoch 984/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2260 - accuracy: 0.9094 - val_loss: 0.9474 - val_accuracy: 0.7228\n",
            "Epoch 985/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2265 - accuracy: 0.9058 - val_loss: 0.9195 - val_accuracy: 0.7609\n",
            "Epoch 986/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.2281 - accuracy: 0.9058 - val_loss: 0.9191 - val_accuracy: 0.7500\n",
            "Epoch 987/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2163 - accuracy: 0.9239 - val_loss: 0.9331 - val_accuracy: 0.7337\n",
            "Epoch 988/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2193 - accuracy: 0.9167 - val_loss: 0.9285 - val_accuracy: 0.7500\n",
            "Epoch 989/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2162 - accuracy: 0.9167 - val_loss: 0.9356 - val_accuracy: 0.7500\n",
            "Epoch 990/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2175 - accuracy: 0.9167 - val_loss: 0.9312 - val_accuracy: 0.7500\n",
            "Epoch 991/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2212 - accuracy: 0.9058 - val_loss: 0.9419 - val_accuracy: 0.7228\n",
            "Epoch 992/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2233 - accuracy: 0.9167 - val_loss: 0.9179 - val_accuracy: 0.7554\n",
            "Epoch 993/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2204 - accuracy: 0.9130 - val_loss: 0.9437 - val_accuracy: 0.7500\n",
            "Epoch 994/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2192 - accuracy: 0.9094 - val_loss: 0.9414 - val_accuracy: 0.7391\n",
            "Epoch 995/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2209 - accuracy: 0.9094 - val_loss: 0.9405 - val_accuracy: 0.7500\n",
            "Epoch 996/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2214 - accuracy: 0.9130 - val_loss: 0.9674 - val_accuracy: 0.7228\n",
            "Epoch 997/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2187 - accuracy: 0.9167 - val_loss: 0.9269 - val_accuracy: 0.7554\n",
            "Epoch 998/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2192 - accuracy: 0.9130 - val_loss: 0.9295 - val_accuracy: 0.7500\n",
            "Epoch 999/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2202 - accuracy: 0.9094 - val_loss: 0.9395 - val_accuracy: 0.7391\n",
            "Epoch 1000/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2242 - accuracy: 0.9130 - val_loss: 0.9545 - val_accuracy: 0.7228\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80o1i3fzZsA-"
      },
      "source": [
        "**11. Plot the training loss and accuracy**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt \n",
        "acc = hist.history['accuracy']\n",
        "val_acc = hist.history['val_accuracy']\n",
        "loss = hist.history['loss']\n",
        "val_loss = hist.history['val_loss']\n",
        " \n",
        "epochs = range(len(acc))\n",
        " \n",
        "plt.plot(epochs, acc, 'b', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "plt.savefig('custom_trainvalacc.png')\n",
        "plt.figure()\n",
        " \n",
        "plt.plot(epochs, loss, 'b', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        " \n",
        "#plt.show()\n",
        "plt.savefig('custom_trainvalloss.png')\n",
        "plt.figure()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 580
        },
        "id": "69dOEi6HAiXT",
        "outputId": "336d07ca-3efc-4ccd-cded-d47fb4b9db6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO2dZ5gUVdaA38MQRnJGFBRUgrpIGkFRFNeECcyKEd01gGHNq2sA066ucV1zQBAVVPxEVFyzYpZBTGAgKoMiiGSEGeB+P25dqrq7Ok739Exz3uepp6pu3ao6VdV96tS5554rxhgURVGUwqVWvgVQFEVRcosqekVRlAJHFb2iKEqBo4peURSlwFFFryiKUuCoolcURSlwVNFvgYjIqyJyerbr5hMRmS8iB+TguEZEdvKWHxSRa1Opm8F5ThaR1zOVU1ESIRpHXzMQkdWB1frAemCjt36OMeapqpeq+iAi84G/GmPezPJxDdDJGDM7W3VFpAMwD6hjjNmQDTkVJRG18y2AkhrGmIZuOZFSE5HaqjyU6oL+HqsH6rqp4YjIABEpE5G/i8gi4HERaSYiL4vIEhFZ5i23C+zzroj81VseKiIfiMjtXt15InJIhnU7isgUEVklIm+KyH0i8mQcuVOR8UYR+dA73usi0jKw/VQR+VFElorI1QnuT18RWSQiRYGyo0TkK2+5j4h8LCLLReQXEblXROrGOdZoEbkpsH65t8/PInJmVN3DRGS6iKwUkQUiMjKweYo3Xy4iq0VkT3dvA/v3E5GpIrLCm/dL9d6keZ+bi8jj3jUsE5GJgW2DReQL7xrmiMhArzzCTSYiI91zFpEOngvrLyLyE/C2V/6c9xxWeL+RXQP7byUid3jPc4X3G9tKRF4RkQuirucrETkq7FqV+KiiLwy2BpoD2wNnY5/r4976dsAfwL0J9u8LfA+0BP4NPCYikkHdp4HPgBbASODUBOdMRcaTgDOA1kBd4DIAEdkFeMA7/jbe+doRgjHmU2AN8Oeo4z7tLW8ELvauZ09gf2B4ArnxZBjoyXMg0AmIbh9YA5wGNAUOA4aJyJHetn28eVNjTENjzMdRx24OvALc413bncArItIi6hpi7k0Iye7zWKwrcFfvWHd5MvQBngAu965hH2B+vPsRwr7AzsDB3vqr2PvUGvgcCLoabwd6A/2wv+MrgE3AGOAUV0lEugPbYu+Nkg7GGJ1q2IT9wx3gLQ8AyoHiBPV7AMsC6+9iXT8AQ4HZgW31AQNsnU5drBLZANQPbH8SeDLFawqT8ZrA+nDgf97ydcD4wLYG3j04IM6xbwJGecuNsEp4+zh1LwJeCKwbYCdveTRwk7c8CrglUK9zsG7Ice8G7vKWO3h1awe2DwU+8JZPBT6L2v9jYGiye5POfQbaYhVqs5B6Dzl5E/3+vPWR7jkHrm2HBDI09eo0wb6I/gC6h9QrBpZh2z3AvhDur+r/WyFMatEXBkuMMevciojUF5GHvE/hlVhXQdOg+yKKRW7BGLPWW2yYZt1tgN8DZQAL4gmcooyLAstrAzJtEzy2MWYNsDTeubDW+9EiUg84GvjcGPOjJ0dnz52xyJPjn1jrPhkRMgA/Rl1fXxF5x3OZrADOTfG47tg/RpX9iLVmHfHuTQRJ7nN77DNbFrJre2BOivKGsfneiEiRiNziuX9W4n8ZtPSm4rBzeb/pZ4BTRKQWMAT7BaKkiSr6wiA6dOpSoAvQ1xjTGN9VEM8dkw1+AZqLSP1AWfsE9Ssj4y/BY3vnbBGvsjFmJlZRHkKk2wasC+g7rNXYGPhHJjJgv2iCPA1MAtobY5oADwaOmyzU7WesqyXIdsDCFOSKJtF9XoB9Zk1D9lsA7BjnmGuwX3OOrUPqBK/xJGAw1r3VBGv1Oxl+A9YlONcY4GSsS22tiXJzKamhir4waYT9HF7u+XtH5PqEnoVcCowUkboisidwRI5knAAcLiJ7ew2nN5D8t/w08DesonsuSo6VwGoR6QoMS1GGZ4GhIrKL96KJlr8R1lpe5/m7TwpsW4J1mewQ59iTgc4icpKI1BaRE4BdgJdTlC1ajtD7bIz5Bes7v99rtK0jIu5F8BhwhojsLyK1RGRb7/4AfAGc6NUvAY5NQYb12K+u+tivJifDJqwb7E4R2caz/vf0vr7wFPsm4A7Ums8YVfSFyd3AVlhr6RPgf1V03pOxDZpLsX7xZ7B/8DAyltEYMwM4D6u8f8H6ccuS7DYO20D4tjHmt0D5ZVglvAp4xJM5FRle9a7hbWC2Nw8yHLhBRFZh2xSeDey7FrgZ+FBstM8eUcdeChyOtcaXYhsnD4+SO1WS3edTgQrsV81ibBsFxpjPsI29dwErgPfwvzKuxVrgy4DrifxCCuMJ7BfVQmCmJ0eQy4CvganA78CtROqmJ4Bu2DYfJQO0w5SSM0TkGeA7Y0zOvyiUwkVETgPONsbsnW9Zaipq0StZQ0R2F5EdvU/9gVi/7MRk+ylKPDy32HDg4XzLUpNRRa9kk62xoX+rsTHgw4wx0/MqkVJjEZGDse0Zv5LcPaQkQF03iqIoBY5a9IqiKAVOtUtq1rJlS9OhQ4d8i6EoilKjmDZt2m/GmFZh26qdou/QoQOlpaX5FkNRFKVGISLRvak3o64bRVGUAkcVvaIoSoGjil5RFKXAqXY++jAqKiooKytj3bp1ySsreaG4uJh27dpRp06dfIuiKEoUNULRl5WV0ahRIzp06ED88TCUfGGMYenSpZSVldGxY8d8i6MoShQ1wnWzbt06WrRooUq+miIitGjRQr+4FKWaUiMUPaBKvpqjz0dRqi81RtEriqJUFWvWwBNPQC4zxHz9NXzwQfJ62UAVfQosXbqUHj160KNHD7beemu23Xbbzevl5eUJ9y0tLeXCCy9Meo5+/fplS1xFUSrJBRfA6afDxzkcz2q33aB//9wdP0iNaIzNNy1atOCLL74AYOTIkTRs2JDLLrts8/YNGzZQu3b4rSwpKaGkpCTpOT766KPsCKsoSqWZPdvOKyryK0e2UIs+Q4YOHcq5555L3759ueKKK/jss8/Yc8896dmzJ/369eP7778H4N133+Xwww8H7EvizDPPZMCAAeywww7cc889m4/XsGHDzfUHDBjAscceS9euXTn55JNxGUYnT55M165d6d27NxdeeOHm4waZP38+/fv3p1evXvTq1SviBXLrrbfSrVs3unfvzpVXXgnA7NmzOeCAA+jevTu9evVizpzKjAetKKmzdi2IwJ13Jq+7fLmt+9BD8MILdnn+fOtaEYF//CPx/tOm2XpBe+qZZ2xZy5awaZNdrlfPzlevtnUGDLDrw4fDrbfa5UTKX8ROPXokv6aqpMZZ9BddBJ5xnTV69IC7705/v7KyMj766COKiopYuXIl77//PrVr1+bNN9/kH//4B88//3zMPt999x3vvPMOq1atokuXLgwbNiwm9nz69OnMmDGDbbbZhr322osPP/yQkpISzjnnHKZMmULHjh0ZMmRIqEytW7fmjTfeoLi4mFmzZjFkyBBKS0t59dVXefHFF/n000+pX78+v//+OwAnn3wyV155JUcddRTr1q1j06ZN6d8IRcmA37yBEe+6Cy65JHHduXPt/MEHYTtvGPYvvoBWXgqvf/0L/vnP8H0B3njDzl98EZyX9JFH7HzpUnAeWDd353M88AC0aWOXFy6EsLyLy5f7y19+mfh6gqxfb18wuaTGKfrqxHHHHUdRUREAK1as4PTTT2fWrFmICBVxXvuHHXYY9erVo169erRu3Zpff/2Vdu3aRdTp06fP5rIePXowf/58GjZsyA477LA5Tn3IkCE8/HDsoDsVFRWcf/75fPHFFxQVFfHDDz8A8Oabb3LGGWdQv359AJo3b86qVatYuHAhRx11FGA7PSlbFgsWWMv20kutJer46CO77YQTYve55x5o2BBOPRVuvtnu26hR4vPMmGGPedZZdn36dDjoILtcVmYt9YoKOPBA6NLFNlJ+4o0se+mlvtVfXAyTJtnlSZPglVf8c3z5Jbz2GkyYAO3awQEHwLBhcN55VlGDbWCtXx9+/hlWrPD3/e9/I+UNbnP8+qud778/7L03XHmlffEMGWJfWt99F1n/hRfg9ddh6lS49lq4/3446SR7r5o29et17gz33WfPefLJie9jptQ4RZ+J5Z0rGjRosHn52muvZb/99uOFF15g/vz5DBgwIHSfeoFXd1FRERs2bMioTjzuuusu2rRpw5dffsmmTZtUeSsJOfJI+PxzOPbYSCt1r73sPEzR/+1vdl6nDlx/PaxaBXfckfg83bpZN4tT9L16RW4/91w7r1/fRrwEGymPPhqeesouBy3fxx+PPEbQXTJ1qlW0RxzhK3mARYtg5MhY+a64IrH8QebOtdMTT9j1Tz6Bzz6LrXf00f7ykUfa+euvx9b76ScrJ+RO0auPPkusWLGCbbfdFoDRo0dn/fhdunRh7ty5zJ8/H4Bnnnkmrhxt27alVq1ajB07lo0bNwJw4IEH8vjjj7N27VoAfv/9dxo1akS7du2YONEO67p+/frN25XCYe1aOwVZtcq6DJwVunSpVcSeRy+C8nJYuRI2boRly/xy53qZM8dao+4Yf/xhlZfb/vvvfpji8uXgfWTGlTXaezhzpr+cbrhjUN5csWhRZvt17RpbNmNG5WSJhyr6LHHFFVdw1VVX0bNnz7Qs8FTZaqutuP/++xk4cCC9e/emUaNGNGnSJKbe8OHDGTNmDN27d+e7777b/NUxcOBABg0aRElJCT169OD2228HYOzYsdxzzz3stttu9OvXj0WZ/mqVakvr1rDNNpFljRtbN4h7AZSUWCu6RQuYNy+y7qBB0KQJXHwxNG/ulzu/+osvWldEy5YwerR1TWy/vfWfP/SQPaajWTPrmknEbbdFrjtrFyDdztdLlqRXPxOSRFjH5Y8/Yst2371yssTFGFOtpt69e5toZs6cGVO2JbJq1SpjjDGbNm0yw4YNM3feeWeeJYpEn1P1xNrB/npFhV8WNj33XOQ+iepGT2eeGbneq1d6+4Mx3bvH37bbbukda9y49M8fNp1ySnh548bGiGTnHGDMVltV5jlTauLoVbXoaxCPPPIIPXr0YNddd2XFihWcc845+RZJySNr18KZZ1r/8F//al0nAwfC4MHw/vtw2WXW3eIwxpaFROVGcOml/rLznafKqFGR659/nt7+kDhixYU9pkqc4LS02X//8PKLLgp3J2WaEWSrrTLbLynx3gD5mtSir7noc6paHn000ho85JBYC3HOHH956dLsWZ6JpsaNc3fshg0Tb+/bN/1jnnFG8jpvvBFe/uyz4eXNmqUnw5/+ZMyJJxozdWrmvwfUoleU6s2KFbYDkGPuXNtg+s031io2IVbj+vWR62GNnBMm+MvRIYS5IlqunXbK3rGDFn10QFmnTpHhlolwvvAnnrBfIcm+crbeOrzc6+cYg7sH991n2zeiiY6ueestGDfOtpXkAlX0ilIN6NULgqn8d9zRNmZ26wa9e1uFEU10I2BYp+a//91fDgsrzAXRir5169ycJyzrSLTi7d49cr1RIygq8sM0vW4l1EqiCV1nqVRkCNK+vc2ZE82gQZHr8V4Y2SIlRS8iA0XkexGZLSJXhmzfXkTeEpGvRORdEWkX2Ha6iMzyppBLVhQl2BPTWe9Bhek6DwXJRh6WP/85tXr9+9sOQ8H49o4d4ZRTwusHY8gro+ijFWKQMD94vXq2rcIxfTosXuyvL1pkQzxbtrTrLpQzTNFff72tv2yZfekuXmz3DUbLeP0lI5g3z0YXgY04iu5jsGQJHHec/QJbv97K6144uSKpoheRIuA+4BBgF2CIiOwSVe124AljzG7ADcC/vH2bAyOAvkAfYISINMue+IpSc3j44cjGwY0b7Wd9UGFdeGF4uN66dTafy003+WVjx1Zepj33TK1evXpWYQdfDMXFsWGbjmCjYmX67CVKDRCt6N16MARUxE+TAFahNmzodw5z4aVhir5pU2vJu16srVrZ5xW8njCLvkMH/7hNm8bWadnSytWpE9StGylvrkjFou8DzDbGzDXGlAPjgcFRdXYB3vaW3wlsPxh4wxjzuzFmGfAGMLDyYlct++23H6+99lpE2d13382wYcPi7jNgwABKS0sBOPTQQ1keTIThMXLkyM3x7PGYOHEiMwM9Rq677jrefPPNdMRXqgnnnAPjx/vrCxfajkhB/vvf2M5NYBX9v/5lu9I7gp2BBg2KjE8//nhrTbZuHekWCAZqDR8ev0doUDmCVUhg6++8s13euDFSniBB5fbVV/7yLgETceJEePpp61KaNSvyWMccY+dFRTYXzsEHh3cmGj3aThDZjjFhgvV7O7780sb0O264Aa6+Gk480a47Rd+9u5Xl6qsj71U0kyfDSy/FWvSDPc3nrH73knjqKevCyXaerpSJ10rrJuBY4NHA+qnAvVF1ngb+5i0fDRigBXAZcE2g3rXAZSHnOBsoBUq32267mNbkfEdzPPTQQ2bo0KERZX379jXvvfde3H323XdfMzVJE/qIESPMbbfdlrDO6aefbp577rnUhc0j+X5O+eaLL2zc9rhxxvz2mzGvvGLMlCnGPPNMZNTGgw8a8913xpx7bngExoIFsWXt2/vL779vzJNPRm43xph16yLXHdOn++XTptl5jx7+9jAZrrsucv3II/36L71ky3baya4fcEDs/ief7C/vvHOkXLVr2+W1a2Pvoat37712ftJJ4dvBmCZNbNm339r1Tp0yf3bHH2+PMW5cevt98kmkTB98ECnnmjWZy5QuVEHUzWXAviIyHdgXWAhsTLyLjzHmYWNMiTGmpFW0KVENOPbYY3nllVc2DzIyf/58fv75Z/r378+wYcMoKSlh1113ZcSIEaH7d+jQgd+8/uA333wznTt3Zu+9996cyhhsjPzuu+9O9+7dOeaYY1i7di0fffQRkyZN4vLLL6dHjx7MmTOHoUOHMsELpXjrrbfo2bMn3bp148wzz2S959Tt0KEDI0aMoFevXnTr1o3vorMtoemMc0GPHtY1M2SI/Tw/7DDYZx+bL+bAA/16555ru78/+GD4cdasiS1bsMBf7t8/0jfurF9ndUcT7JnqGnwTWas9esS6G4IuFJds1VnQZ5wRe4yKCr8R0sXiu1h07yeV0C3jzhFtMTdq5GefdK4a5z664IL4x0uGs+jDopsSES2fs+BdI3jO4uLTJJWkZguB9oH1dl7ZZowxP2MteUSkIXCMMWa5iCwEBkTt+24l5M1LnuLmzZvTp08fXn31VQYPHsz48eM5/vjjERFuvvlmmjdvzsaNG9l///356quv2G233UKPM23aNMaPH88XX3zBhg0b6NWrF7179wbg6KOP5iwv49M111zDY489xgUXXMCgQYM4/PDDOfbYYyOOtW7dOoYOHcpbb71F586dOe2003jggQe46KKLAGjZsiWff/45999/P7fffjuPPvpoxP6azrj6Emw8TMbo0b5CjddJp21bf7lZs+TKbPr02JS/wZeIU8LuJ3DSSXYCm2jszDOton/mGd+tcsEFvnw33minRDgFGq1IV660jZfOzw02nUO6Cjoad6x0f9bRL0QXSnnLLXaqLqRi0U8FOolIRxGpC5wITApWEJGWIuKOdRXg+se9BhwkIs28RtiDvLIax5AhQxjvOVjHjx+/OR/8s88+S69evejZsyczZsyI8KdH8/7773PUUUdRv359GjduzKBASME333xD//796datG0899RQzkmQ3+v777+nYsSOdO3cG4PTTT2fKlCmbtx/thT307t17cyK0IBUVFZx11ll069aN4447brPcqaYzrp/rMIFqwo8/xg5YATa/iwhMmWLnIR9NKREWkbLPPqnvn0oe82QhgGENqtEKNqjo3XKYUnQJXaNDLNPtKepkbhYSuuG2BcNRK4u7B8nSLUcTfZ8aN86OPNkmqUVvjNkgIudjFXQRMMoYM0NEbsD6hCZhrfZ/iYgBpgDnefv+LiI3Yl8WADcYY0Ly46VBnvIUDx48mIsvvpjPP/+ctWvX0rt3b+bNm8ftt9/O1KlTadasGUOHDmVdulmXPIYOHcrEiRPp3r07o0eP5t13362UvC7Vcbw0x5rOODXcgBWPPea7DMC3eK+5xs4nTSJlWrXyk221aZOeBR9NtLvm1VdtNEc0774brjTBhm5+/rmNFlm1ypZFK7DgV0G0RR9WL9NkYh9+aKNadtjBWsSnnhpbp0kTeO657I63etNNtpE5mEAtFYIv0QkTqq+iT8lHb4yZbIzpbIzZ0Rhzs1d2nafkMcZMMMZ08ur81RizPrDvKGPMTt70eG4uI/c0bNiQ/fbbjzPPPHOzNb9y5UoaNGhAkyZN+PXXX3n11VcTHmOfffZh4sSJ/PHHH6xatYqXXnpp87ZVq1bRtm1bKioqeMol3wYaNWrEKvfvC9ClSxfmz5/PbG9wy7Fjx7LvvvumfD2azjg5Tz/t5zx3ym3ePBvW6PKPu/d6rVo2dO/yy8MVbZBgiGVgSIOMiLboBw60na2i2XdfOxh1GO3b22iR7t3tgBoQq+iDueqjffRB3OhPCxfGbkuFfv1s57GmTa2fO1745rHHxu/ElAnFxfCXv6T/5RG8T66tpDqiPWPTYMiQIXz55ZebFX337t3p2bMnXbt25aSTTmIvN1pDHHr16sUJJ5xA9+7dOeSQQ9g9kJP0xhtvpG/fvuy11150DSSqPvHEE7ntttvo2bNnRANocXExjz/+OMcddxzdunWjVq1anJtGBipNZ5yY9ettN3XnsnGWc9eucNppfj3XcCpilX5xcfIGuGC8wV132WP37RtZp1+/yPPEI14DbGWJdvcEFX0i182229rG31tvzY1c1Y1kbrFqQ7xwnHxNmtSs5lKTntOmTcZs2BBZ5tY3bTJmyZLIsLkhQyLDF93Utq2d//vfdn7zzckTa91xR2wY5OWXx4ZLOj77LP6xEkT4Vor77os8z+zZ/rbvvrNlW2+dm3PXJObPD39m+QBNaqYokVx4obXGnPvhjTfs+pdf2sCu6CjfcePCe3i6UZScBbtuXfLUBGGulfbtY8scwfFFo8mVRR/tugnKl8hHv6VRUyz6GiKmomSXe++18+XLbSOlaxaZOtUOfp0qTqm7/Co//hgbcfLgg7Dffjbz4owZthfrV19FNo6ed57t2dqxY2x3/Hwq+gEDbKNoqlE3WxphuW6qIzVG0RtjkEyz+Ss5x1Q2kLkS3Huv34iXiJUrbeji+efbMLpVq2xq4IULYcwYWyeVcMVELF0aa+UFOyc5Gbt1i6xTqxYcdFD4McPS3DpypWjcX2277WLbD9Si96kpFn2NcN0UFxezdOnSvCoTJT7GGJYuXZq3EM0LLrCpfJNx113WNXPWWb6V/Msv1mp1jBsXuU/durZHZ7B3aSJuuy3z0YXiUbeujTIJ5snJNW6Q8LCEW4mibrY0aoqirxFitmvXjrKyMpZUxUi/SkYUFxfTrl275BWzTDrKxvnTAX7+2c5XrIhMaztrVuQ+77xjvxauu8725mza1Lp7wJbdcINft3ZtG4udiw/P556z8xNOsD1hn3gi++cI4lIuhLUduK8ItejVdZNV6tSpQ8dsdoNTCoawlL5hfPyx75cHfyzVQLohIHbwDpe33PniGzb0FX20S8X1Swsq+nhx4NnCyZdtXCbMsDTGzr01sMbloc0+NcWirxGuG0WJR6odkadPDy+f6vXZvuYa2xsz+IXw6afgZZjY/DUQHFIuXiOpU/TPPQcJMmJkjJPx2mtt3HouGDbMpnUIU/TFxXagFNeusSVTUyx6VfRKjSaZov/xR+vfPu+88O2TJ9v5qafC9ttHbuvTx192+cWD3ql4jaTBhsxEDamVJZtjsUZTq1ZkfvtoOnasfMN1IeAs+uqu8GvIh4eihJNM0V9xBTz/fOI6bdrY2PagNf/yy5F1brnFKu3eve2AGRA/r0mug8O0EbT6UKsWjBjhDzhSXVGLXqmWbNpk88msXh05QtHKlfDeezZr5Pz5kYq+tNT67IPjq6Yyrupjj1mLLGiVHXZYZJ127ewA3cE68Y6daW7zVHHH1Wjj6sHIkdCzZ76lSIwqeqVacs89Nn67fXubbGv1alt+8ME2HHLffa37IKjod9/dNk7uuSe40RbDxgKNJpjHJRnBRKDx4gNOOMHOE/V2VZSqRBW9Ui1xjZguwsWF+wWtdYh13bhEny71r/Otg03h++GHsedyvnlnIY8aFVvHsTEwbtrOO9vwzGjr/6KLrBy5irhRi15JF1X0SrVjzBh45JHIsuCg0kEOOSS8/OSTrSJ0ja1g89e4DkDBAbPdslOgiQafiE7t37hxrMIViTx+tnENvNVlmDql+qONsUq1Y+jQ1OsuW5Z63QYN/MRkxcXw9ts2KieaRNEkG0NGQnYviL/9LXVZKsOtt9qvkCOPrJrzKTUfVfRK1li82KYYcANh//wz/O9/1sWxxx52BJ4jj7RujRdegJ9+gr32grIy61f/5RdbNx6vvFI5+erX95VycbH16QeGBNiM6+IfRpiidwQHAM8ljRr5g08rSiqooleyxkEHWUVfUWHji3ff3U81MGkSHH+8DUWbPj3+0HuJsigcfnjmsjVqZBtqnaK/+ur4dRM14B5wQGyZ+sqV6o4qeiVrfPONna9YYZOAOSUPfuPojz/Cr7/GP0ZZWfLz3H67HQM1OtbdYYxNFezcNJs2WUvcdW6JF/boFHYixf2nP8Xur3HtSnVHG2OVSjFjhlWMU6f6Lo+WLSMHkw4yenRiqz0VEuVndwT97CKp5SRxClsVt1JoqKJXKsW779r5Y49F+rajh5QNJh9z+WNSJbor/tFHp57jpipQ141S3VFFr2TE2LE206OLFX/oIT+GPYyg4p84Mb3QwB12iFxv1qx6KXr9AlCqO6rolbTZtAlOO83maU81mdO8ef7yt99a6//f/05t39NO85ePOcbOb7wxsk5YF/TDDrM541NlxAj7EgkmM0uFq6+2se1hmR4VpTqgjbEKYBsva9eOVNx//GGt1fr17box1pJ2vU0XL05sxQcJSxN8+eV2/2BtPVoAACAASURBVGilHU10+mCwaRAaNIA1a+z655/HulDiNdbGo39/f2SldNhzT78Hr6JUR9SiVwAbobL//v76xo1WwTdoYMdUBbj5ZlsWHFbvlFNSO76LyHGsXGnnqQycETacnaIoqZOSoheRgSLyvYjMFpErQ7ZvJyLviMh0EflKRA71yjuIyB8i8oU3PZjtC1Cyx3vv+cvB0Eg3vN4dd2T/nH/9Kzz+ePztn3ySPO/6Sy/Z+ezZ/ktJURSfpIpeRIqA+4BDgF2AISISnXnkGuBZY0xP4ETg/sC2OcaYHt50bpbkVjLgo4/sANnXXusPoXfTTbaTk+Oii2yHp2ee8ctcOt7KuifCepzWr5845UHfvsmP26+fne+4Y+6H7lOUmkgqPvo+wGxjzFwAERkPDAaCg6QZwA3D0AT4GaXasdde/vLYsfDDD1bpX3utX/6f/9ixQIND4K1fn/zYffpYd8+0aXa9c2d7fEdRke3Z+sILqcn67LP+seLx5pvw6KO2AVVRlPik4rrZFlgQWC/zyoKMBE4RkTJgMnBBYFtHz6Xznoj0DzuBiJwtIqUiUrpkyZLUpS8wjLFjcUazeLHv0wYbqrh6tbW0f/ops3OVl8fvofrhh5HbVqyIdOWEMXlyZKbIm26y85ISe10bNsBuu6Uu33HH2VGdErHHHlbRaxy7oiQmW42xQ4DRxph2wKHAWBGpBfwCbOe5dC4BnhaRmAHYjDEPG2NKjDElrVq1ypJINY///Me6H774IrK8TRvYdVd/vW1b6NULhg+3WQyDL4FUEYFu3cK33XRTpNJevjz5INR16kS6Zrbbzs6PO84vS5QQTFGU3JGK62YhEBwrp51XFuQvwEAAY8zHIlIMtDTGLAbWe+XTRGQO0Bkorazghcg779j5vHnQo0fktugcMLNm+T7zFSvij18aDxG7Xyq40Z0SUbdu5NB6vXrZ6wgOuK2KXlHyQyoW/VSgk4h0FJG62MbW6NyDPwH7A4jIzkAxsEREWnmNuYjIDkAnIMQ5oYDtiAQ2T3rjxnDeeTbjYxD3MgD47Tc7dwr7/fdt5yJj7HirJ59se6+2bRs+OEaqRLt49t47tk60RV+njh2iL3ged32KolQtSS16Y8wGETkfeA0oAkYZY2aIyA1AqTFmEnAp8IiIXIxtmB1qjDEisg9wg4hUAJuAc40xGXRJ2TJwFu+999r5/ffH1vnzn/1l14nIWfaHH27dOLffbvO+//KLDTmMzjsD6Sn64P4iMG5c7HioRUXJUwG46+vTJzaf+ocfwsMP29GlFEXJLin1jDXGTMY2sgbLrgsszwT2CtnveeD5SspY0EybZv3yGzeG9x4NMmdOePnzz9uIGuerHzXKKvlE+yxYEF4eTf368NVX/vqdd8bPPpksHYJT9McdZxOTBenXzw6/p4peUbKP9ozNI+XlNirl6KOtog6zvIOEDXoBcPfdNp2A46qr/OWlSysnY3GxTUXsqFs3cnv/QBxVsq8EN77rPvuEb3ephFPNn6MoSmporps84qzqL79MLcfK/Pnxt/3vf1kRKQY3eIcjutPTSy/5uXCSceCB9uUWb6g+VfSKkhvUoq9irrzS97M/8ICdZ5JIK5qg1V1Zgvnio+Pno5V048aJx1iNJlFdVfSKkhtU0Vcxt97qR864qJnKcNhh8RVjSUnkeqKBt/fd1847dbJRP/GIdt1ks7OSKnpFyQ2q6HNMeTk88URsRMrzz2fe8LjrrnDEEXb5zDPDe9MCXHhh5HrdurHK3+HyxQwdmrhzVDrWe7qooleU3KCKPsfcdBOcfnpsjpdjj838mCK2VyzYRtx4ibx23DFy/corYeTI8LouXn/wYDtv1Qouvjg2jNIp+pNOCu9Zu+22Nv4/E5yCV0WvKNlFG2NzjAtzXLYsed0jjvBT7t56q401P/RQO4BGrcAruVYtm3gsLG7dGN+dEj1c34knxj93jx6Rx1u82M6vuCJyoG/nunnqqfDjRPfgTQd3flX0ipJd1KLPIVdfbZNupUqDBv5y0I0R7QevleJTi46YyYSmTSPXc+m6ccdOJ/mZoijJUYs+h/zzn/5yKgNIB33jTtE7pT53rrXsL7wwvAH022/9dMKzZtm0CEFFH0yUNmOGTWsgYt0+bmjAMKJfFrnMFNmiBbz+Ouy+e+7OoShbIqroq4izzvLdIdEMG2ZDLV3GR4hV9B07+oNPh1n0Xbv6y25EJuc2Auje3V/eZRc7ZcKGDZntlyoHHpjb4yvKloi6bqqQq68OLz/ySKuoBwywDaZ/+1t4BIpLCpaqVZ0N1w1E+vY1A6Wi1DzUoq8GHHSQdb2A758eNcrOg9a7U/RV6aMHm8RszRrbUBxMRawoSs1ALfo807FjeHlYqKEbk8XFvCejXr3M5YrGjd2qY7IqSs1DLfo8E29cVNewGozEcaNPpepfT9XyT4WrrrJJyXr1yt4xFUWpGtSizwFlZanHgscb2NqN6tSwYWR59+65DXGMR61aquQVpaaiij4H/P3viUdTcql9x42LX2fNGjuPVvTpMnKkDVlUFGXLRV03lWD9evjxR+s7//Zb6NnTWvPxfOOHHQavvGLrTZmS+NjOog+6bjJhxIjK7a8oSs1HLfpKcM450KULHHWUzTnTr59N8Rud4RHs+K0uJUEq0TB9+th5qg2viqIo8VBFXwneeMPO33vPzl3v03nz/Dp9+8J338Hjj/vumOhEYWEcc4wdcSreaEyKoiipoq6bShDPDx/0ibdsaa3+INtvn9rx27TJTC5FUZQgqugrQaIG1+23t/77YE/SkSNt+YABuZZMURTFR103lSCRonc52YN1+vSxOW0aNcqtXIqiKEFU0VeCRIq+d287P+20qpFFURQlHuq6qQSJUg/vuGNqqYkVRVFyjVr0abBypc0cOXGizeGeaNSobCUUUxRFqSwpKXoRGSgi34vIbBG5MmT7diLyjohMF5GvROTQwLarvP2+F5GDsyl8VTNnjp1ff33sgNwXXgijR/vrqugVRakuJFX0IlIE3AccAuwCDBGR6LRa1wDPGmN6AicC93v77uKt7woMBO73jlcjcUnCNm60PVyDNG5sBwF3qKJXFKW6kIpF3weYbYyZa4wpB8YDg6PqGKCxt9wE+NlbHgyMN8asN8bMA2Z7x6uRuMbXTZvgs88it0UPyBHWO1ZRFCUfpKLotwUWBNbLvLIgI4FTRKQMmAxckMa+iMjZIlIqIqVLlixJUfSqxRh/bNWNG2Hdusjt0Yo+l2OrKoqipEO2GmOHAKONMe2AQ4GxIpLysY0xDxtjSowxJa3c6BrVjOOPt/lswKY0iHbddOhg523bVqlYiqIoSUklvHIhEMzO0s4rC/IXrA8eY8zHIlIMtExx3xrBhAmJt59zjp1Pnw4LFiSuqyiKUpWkYnVPBTqJSEcRqYttXJ0UVecnYH8AEdkZKAaWePVOFJF6ItIR6AREeberNxs22IiaROy9t99Q26YNlJTkXi5FUZRUSWrRG2M2iMj5wGtAETDKGDNDRG4ASo0xk4BLgUdE5GJsw+xQY4wBZojIs8BMYANwnjFmY/iZqiezZ8N//5u4TqqjSSmKouSDlHrGGmMmYxtZg2XXBZZnAnvF2fdm4OZKyJhXysqS16mt/YsVRanGaM/YBCxfDgcemLye5oxXFKU6o7ZoApYuTV7n22/tqFKKoijVFVX0CVi1Knmdrl1zL4eiKEplUEWfgOXLI9eHD7cDe++4Ixx6KLzzTn7kUhRFSQdV9HFYtgxefDGy7Iwz/NBJ10tWURSluqOKPg69e0cO8g1Qv35+ZFEURakMGnUTh2glD9CgQdXLoSiKUllU0aeBWvSKotREVNGngVr0iqLURFTRR/Hmm/Hj53UwEUVRaiLaGBtg/frYnrDNmvljw9bS16KiKDUQVV0BogcTAbj0UjvoiDFVL4+iKEo2UEUfIKjo7+RiDMI5/9k5vYNceSU0aZJdwRRFUSqBmGpmqpaUlJjS0tK8nPvHH/2RogyBsQDTuUduDMFqdl8VRSlsRGSaMSZ0NAy16AOEuW4yxo0kriiKkme0MTZASop+/nz4/nto1Qp69bIjk7z3HnTvHpkF7fvvYdEi2GknmDYN2rWzvbD23lsHllWU6samTfDZZ7DHHvmWJCeoosdG29StCytX2vXJk7FDnIfRsaO/bAx06hReb5ddwstPOw3GjMlUVEVRcsHtt8Pf/24zFQ4YkG9pss4W77pZscLGx//zn/4AIsV1U3S7lJenf8Kff05/H0VRcsvXX9v5ggX5lSNHbPGKfskSO3/sMb+s4Yao/MTxGlZ/+SXzEyqKolQRW7yi3+gNVT5vHrTlZ8ZxIj1OigqpbNPGRtNEDw576qnpn/DLL6FFCxg/Htq3h/ffz0xwJf9UVMAll6Q2FFllue02mD499+dRYvn9d7j44sy+4I2xIddHHWWNvOuvh5kzrSvhoouyHAGSUA5TrabevXubquTzz113KGNOZYy/ksrUvbu/3LZteJ26dY3ZfffEx1FqJuPG2ec3dGjuz6W/ldxy8sn2/o4ZE7vtr3+128aOTf+4337rP7tjj7XzJk2Muewyu/zf/1Zedg+g1MTRq1u8Rb9okb/cmsWp7/jAA/DFF/76zJnhanz9evj0U7/eofFaeZUahwuhXb8+t+dxn51KfnCjDIkkrhfGhg3+svu9rFjhH2vNmsrJliJbvKIP6t2tWRS/YjTRqSwTpbYM/kCKimK3uz+y/qFrFpn88TOhoqJqzrMl455l2DN1yjrsv5uMYH+aOnX85Xr17DzXRoLHFq/oAc7lAQzCZdyR+k6NGtn5dtvZefAhJmLHHWPLatf22wB++CF1GZTqwUsv2eeXq4iqoKJv3x6OOw6eeMKec/lyO7/uOhs5IgJTp+ZGjspw9dVV92JMxr/+ZWUJC7KYO9due+stv8wp+iFD7DY3v/deePdduzxrVvi5gor+mWf8ZTdOqTtf69a2b06OSCmOXkQGAv8BioBHjTG3RG2/C9jPW60PtDbGNPW2bQS82CV+MsYMyobg2eQabkq98hln2Nj5gw6y6x9/DDNmJN9v2jQbrL/TTnD33fHrzZ8PnTunLo+Sf1avtvPPP4dttsn+8YONgGVlMGGCbxC4odBuvNEPFnjxRdh99+zLURn++c98S+Dzj3/Y+YYNsQbahx/a+eOPw/77+/WCjB9v5zfdBIcdZpffey+8T028HvIunNM1sOc4Gi+poheRIuA+4ECgDJgqIpOMMTNdHWPMxYH6FwA9A4f4wxjTI3siZw/nKVlDArfL3/4GW28NV11l10eNity+zTap/bl79fKXg7mPo6miTzklC0RbqLnKb5TIdbN2rb/s/L06Qk5iatWyCriiIlbRO/dM0I2ayKXqcpfHe/bJfhNbbRW5Xl5uDcIsk4pF3weYbYyZCyAi44HBwMw49YcAI7IjXm5x/5EN9RpAPP3atGn2TxxtIQR56y044ojsn1OxVFRY10aLFtC4sZ+OYuZMaNnSfkInYvlya0WvXh2r6ONZb6Wl0LUrNGxoLfKZM+G33+CEE3zFMmWKdQfusIOf/XTuXDt16RJfno8+8pddcEA6Y16uXWuty44drUzxenRnC2Mi79vatfaLuCq/QNz5y8tj71U6iv7XX+1IRQCvvWb/14MHw5w59hk3bmx/L4kIBmqAfQa5+CqMF47jJuBYrLvGrZ8K3Bun7vbAL0BRoGwDUAp8AhwZZ7+zvTql2223XdbCjZLxyy82NGbm9gf7cTKdOkXGzXz0kZ2yGd6WLGzzww+zcx4llgsv9O9znTp+uQt7S0YwpPaccyKf28SJsfVXrbLbDjvMP4+brrnGlk2e7Jf16ePvu/POtuzjj2N/I7vtFv/3c/fdqd+Pk06qmlBfd/yKisjyo46y5UuX5u7c0RQV2XMuXuyXnXKKLRs82M6POsrfduCBqYdc9+6det2w6auvMr4sEoRXZjvXzYnABGNM8BW4vTFmoYjsALwtIl8bY+ZEvWweBh4Gm6Y4yzLFxVn0xW2aYNa0RH780fo+e3qepz/+8McPXL069QbXVKlTJ/yzXNMk5I7PPvOXo+/9ihXJ9//yS395cVQ4bthnunPFOd9vmCxlZeHyffutnf/0U3K5ggTdOckIkyuXbNgQ2fHQdRisysiiWrWslR52znRdN9FMm1Y52XIUbplK1M1CoH1gvZ1XFsaJwLhggTFmoTefC7xLpP8+rwwcaOfFG9Yg7dvbz7igzyw4SGyDBtn3nbVsmd3jKcnJpHdjPFyInCPMdeMUfZi7zinkZGF7C+P93eJQRbHZGRGtNN3zyFX7RhhB1028bUE5E7las02unl08U99NWD/+XKAjUBf4Etg1pF5XYD7eYCZeWTOgnrfcEpgF7JLofFXZMxaMOZoJdmHvvW3hvHlV9xm7ww7hn2/NmxuzcWPuzp8uDz5ozOuvp7dPebl1k/zyS25k+vFHYy65xL9PFRXGXHSRMT/9FFnv3/+2vRAfecSYP/0p9l4bY8xnn/nrn31mzMMPW3eKMban5AsvGPPKK8bcd1/yT+9LLjHmnnv888+d62+79NLY+vfcY0yzZpFl779fuc//YC/tK64w5qqr7LnHjDHmvPOMWbvWv4fR+37+eeWey6ZNxlx3nXVBTJlizJ13GjN+vH/85csj6xcX2/IFC2KPc/XVVu6XX4593o433rDup1WrUpexXj17zkGDjBk+3E5h9/GuuyLdtlUxTZqU2X03iV03SRW93Z9DgR+AOcDVXtkNwKBAnZHALVH79cOGVn7pzf+S7FxVpeg3bLBX/z8O8v9wxhizfr0xRxxh/+y5IpU/9Pz5uTt/umTy4ps0ye5zzDG5kWnvve3xP/nErr/+ul0/4ojIesn+WMb4PluIXE5l/0THNSayC3x1mR56yMo2dmzstqKiyj2X1avtcaJfXm6K9sWL2PJ58yLLlyyJ3K9/fzv/+OPIer162fJ3301dRvdySWW65JKqfTbjxmV0240xJpGiT8lHb4yZDEyOKrsuan1kyH4fAd1SOUdV43LPt2IJawYcRoMLLrAFdevCpElVI0S3BLdmyRLYfvuqkSMXuM/dXH32Rrs9fv/dzqPdKakQ/EzP9shglQ2XLSqyfTZefTV8+847+778VHED5ITJVtne2c7vHS9ZV/TvwZjw8mjc8aIjndx+6cShp9NxK1NXyltv+XH46ZBHH31B4qKeujRbQoMOueuRlpBESmnhQvsjrqlDEro/cK56QzqF4hrI3QNt1ixWhnRIJzQxEcZYH3Bl/7jFxYlDfGtl8BdevtzKFk8Zl5dndu8geTbGjRvtb3rdushzRDeMRq+7/0H09TZubOfRDePxKC9P7zf588+Z/YYz/d+m05CeBluUop82ze8hvmwZrKIhDZaV5a9R1Cn6sB51Rx5plVhRkRX6mGOs1SIC48bF1s8Vzz6bXv2zzorsXp6pojfG7nvjjeHbg/lH1q+Hc8+1640b2/1EUlOC0cM6BhVzZV5StWrZ57vXXpkfA+wxEn35ZSLjTTfZ455/fvxz7rabfx9F4C9/sduuuCL+Odu1Sz5M5lln2d/2VltFjuQ0cKCf1uHkk2NjyV00S/S5Gza08/POs9uOO84O1ylie60+95xd/vVXK3u9eukp05deyuwrMbojVKqoRV95XnnFzidNshFtDfFuqrMKqopvvrFheiK2w8UHH8Ann9jcGfH+fP/3f/DVV3b5oYeqTtZ086Y8+qidV1bRO8swmaLfsCEyBanLNJgqi9JIZJcPioqsgopHrVqReVac4qss33wTue56hN92m52HRaykEh30yivw9tt2ecoUv/ynn+Df/7bLTz8df//oL41oV9OECX7I6OTJ8N//2uUZM/zlVHEvreBXSvCL8YYbYvf597/h+eczf8HnKD/9FqXonYG3aZM1ADZT1V3Gd93VWkxg/XitW0Pfvlaoe+6Jv5+zRKpS3kxzcGRL0UcP9uIIKvpgOolMBwHp1CkynLa6sHFj4vDLoiKbP6lDB7vufle55rffEm9P9NyDv9/gV1cq1my0SydZG0gwlDJdd1RYfp7Ro/3la6+N3T5wIBx9dHrnCZKjFChb1ODg7pn/+sk8GpQFbmh1yg2S6A8y2WsPb9DAKv3/+z/bdbxLF2vJTptmP1uDLFpk/5R/+lNm8qTq+4wmqOjnz7cyGGP/2B07QvPmkfWXLLH+0O7dbYIop7jiWejuD//ii34mUYjMOpgOf/xRdaP9pEOyxtHouO94L8Zs4Kx5gEcesWkkNm60z3TIkMi6idwjwd/UNtv4Hcbmz08uQ0WFTQT2ww/2Be+iKuLhvhpGjEhfibZrF1uWzCVT2fufq1xX8cJx8jXlMrzyn/+0EUwxIU1PPJGzc2ZEw4aJQ7DOPtuYJ5+0y67LvBsFZ/bsyGO5ULJMKSnxz5sKrq6LnT7++Fj5d9kldr9ttrHb3JBfgwb59b/7LrZ+mzbZD2077bTchs4Fp5YtU6t31VX2evv0Cd/uwoJvvNGuP/10+rKkE24YbzrjjMz2C/6+UplcGG1VTAsW2PnRR/tl773nLwd/726aNSv2v5DONHx46v/NmL+ejjAFJDCWq9sn+/LlNuXC0qWRDVadOtmGoVq1/CgTF1boUiVHD1heWSs1U9eNszDDbvrMkHx4Lu2Du55gsqcwGTIN23z33fjbRo2y51q0yN63336LTEH90UfW/xoPF8ny66/22a1ZY49RXu5vKy+3VunixfaaV660VlzQ5+3K1q+Hm2+2ZR9/7KfHHTzY1lm71m/Tufpqe9whQ+yxnEtk5kxr+ZaXR6ZaCPrTV6+OvJ+Jvv7OOiu8PJVU3WEkSxoY3Rs9LOvr0UfDrbemdr7oL4CRI+P3lt52W3u+oLsmXu94Z+mna9FHexPUdVN54gZhpNuAl2uKiuwPoEEDP5Mh2B9Z27ZWgTh/pvPfuh+My42eLTJ13WT6gnHXE7yOsJwkmSr6Nm0SnzsYgVWvXmRD/a672syE8XChnsEMmInCNeNFqARdUY5atfzji8TWCQ5eX6eOXS4vt64R9xvadlu/fnCQi+g2gEShgT3jZDBxsfnpkiwQomFD/+UP4Q2+W20V6wqMR/R9Ky6On8NKxL6Igso3WbqKdBV99PFypOi3GIv+66+9QW4I+RFXN0UfJPhHqF/fTq+/Dn//uy37/nsbRuaU4SGH2O3RrFtnQxDjKe4VK+DssyP/sGvWxL83P/0EF1zgK9xnn4UxY/ztbr94b9fycrjlFuuPv+8+vzxsLM3ychg2zG4bNcpaYakkIAsj3T9iUAk0apTcJ5xLwhJuJSOeBZooQV+iawzzW0P6nbYcyfotRBsMl1wSW6devczb2aJ/D2G/j3SGEEz39xX9xasWfeXYf3+rk5oRlR96r73gpJPyI1QqDB9u31KrVlkF9/XXMHasdQ84Jk+O3Ofgg63HL8iECTYsc926yE9Rxx132Aa2jh39QVYSuW3OPNM2fB5/PPTvb3OrB3GKOp6/bO5c/zzBl0HYF0lFBTz4oF128dyZMGZMuIL7z39sw2I8rrzSvrhE4JRT4OWX/Z6qF1xgrz+VhsRkjBuXOHPpwIE2xty5cxIxZQo8+WSsW/LJJ/3IpOHDIy37p5+2v6vrvE7vRxxh48iDpKpQw/YNsssu1q2ULEb9ggvsvXahxY769f0G30GDbO/htm191+WgQfbai4rs7+uzz/womrvvts/y4499V9TEiTa+//337YvOZdWEWEV/+eXWoAIbq/35535oaNjv6777osL8AlSRog913OdzylVjbOPGtq2jC37ukV/GvpGTc+WcGTOSN+o43Pojj9j5ySeHH/Oqq+z2G2/0yz79NPyYxvi5R957L/I8brruOjuPznfuptLS8PKnnootGzcus4atyy6z81tv9eUuK4t/r1LF5XPJZN+agLu2uXP9Rm+Xu+a992xitET3/Ywz7HHiJYEbM8bP/37qqeF1dt3Vzl95xR5rzpzYZ1aVz8Dlmf/00/Dt9evb7cGkbYkabd3UtGnk+sEHZywi2hjrux3b4jdWbtU6xBdaE8hkEOFMfOapNMQaE17u/KrxXDfxLNfgl4pjwYLkcoThrKtgY5v7tA7zg6dKLkMYqxOtWweSQgV+c8l6ljp3TKL7lKxNyXX8cn/cmnLP03HzQJVZ9FuUol9GU97hz5vLmuyUpxw3lSWVhqeFCyN/RO4H9NRTkX7O/v0jG+muvdb/DI1W9C4m3hj/03bAgHD3zL332vmTT4bLNyjOGPFhPthEPUMT0bGjnW+9tV/mXjyu52Kwp2OquBdIvIbJmo5LpteggT+0oLtfTZvG99M73NCHiZRz1652vsMO4dvdvXW/9XQVaLbZeWc7j9d43L27nQflTEXm6A5u6qPPjHnzrDt57Vpoim3A+5XWzB3xBHvG+5FVd4qKrF/+0EPt+iGHWB/lxRf7ddz4oY5go+pdd8Gdd9rlDz6IPf7111vlGtZwW1qamXLMNd9+a32lffrY9TVrbI6YVq0iXyqtWtnG6j328MdKTZdatWyYZqad0Ko7H39s/zhg/ePffms75h17rFVMXbtCSYnt1DZmjA1v/Okn6x9v08bvPBU0AJ54wravVFTY8gsvtC+UI4+E/faDffe16UD22cemB+nXzwYZ9Otn9992W/jf/6xP33Wmmz49eykfkvHgg7Z9xr2gonn5ZduOEOxQNX++/+U6bZr9vZWXw1FHwRtv2Jdcly72d1tcbK871eihdInn08nXlG0fvXMF2iu1C1dzo3nhhayeJj+0a2evyeXybtXKv9jHH4/0/UUPeuFw685HH9zufNzB6ZlnjPnhh8x85rmclOrHgw/aZ3P22Xbd/RmrWwfFAoEqHDO22hE2CPsaGlQ67Xa1wF2EcyUEY8vPOSey7h13RK4/8ECkyyY6x87o0eFJNdzQoAAADM5JREFUoB56KPtDKiqFiXNDZJL9UckqBe+jD2s3Wkv9zS61Go3rFelcKcG3V7KxUYcPtz0sHdEJpc44I9xf+Pbb9hO6OnHwwfmWQAnDBQA4RX/ccXa+++75kWcLpuAVvW9M+NEhDz5gE/7VeP7xD9vK7KIcnEUfbHzMJckGV3CpbYP07evHV++1l305BV9QbmCKIK6OMX4s9OWX23qbNlW/F49icYaCi+UfNMg+w3h+biVnbDGKvja+W0PW5mik9XwQbPByCjPokgmSqPt/Zc8dRtjnVLNm/n6NG9uGzWAIZq1asccN1nGRHJs2+YNiKNUTdd1UGwpe0W/YALXYyDMEem5Wx3S02cDFtMdLFJVJ/H1lCHP9BCN2MhkGzyn6gmhkKXBcWg5t08k7Bd8Yu24dtKOMo3nBLxw+PH8C5ZIPPoBnnrG++44dbXqCJUts3PMee9hwrkMOseGZ8RRlp052xKKzz7adio44woZjrlplu+BfcYWNKXaNu++8Y8PjAO6/36Y26NvXhtqdfroNA12wwMYZ160Lt99uQ8jOPNPmCHfceqtNGuZ45RWbnOjssyPlO+ssG1Z39dXZu29KbrjiCvs7GDYs35Js8YiJ17MxT5SUlJjS0tKsHa9/f/jjg1JKsQ1APx1zEdtNuCtrx6+xxHN5VLPfg6IoqSEi04wxJWHbCt51s24dtMHvVr9dkzxmH1QURckDBa3or7jCduS8mIAFH6+hckujc+d8S6AoShVR0D56N8RlXcpZTQMaTn7O5itW4MMPrX997lzbQLpune2arShKwZGSoheRgcB/gCLgUWPMLVHb7wK8FjnqA62NMU29bacD13jbbjLGjKGKELEu51YsYTKHcrzLIa3YkZRcBxZFUQqapIpeRIqA+4ADgTJgqohMMsZsHvjTGHNxoP4FQE9vuTkwAijB9lia5u0bMvBj9qlbF8z69ezMd/zW7c/Jd1AURSlAUvHR9wFmG2PmGmPKgfHA4AT1hwDjvOWDgTeMMb97yv0NYGBlBE6HoiI4kDcA6H90DU1JrCiKUklSUfTbAsGRH8q8shhEZHugI/B2OvuKyNkiUioipUtSGewiRdavDww08te/Zu24iqIoNYlsR92cCEwwxqTVbdEY87AxpsQYU9Iqi703N26E1ng51au6V6iiKEo1IRVFvxBoH1hv55WFcSK+2ybdfXNCK5bwR51Gmm9DUZQtllQU/VSgk4h0FJG6WGU+KbqSiHQFmgEfB4pfAw4SkWYi0gw4yCurEg4+GBqymrotaujYsIqiKFkgadSNMWaDiJyPVdBFwChjzAwRuQE7oolT+icC400gp4Ix5ncRuRH7sgC4wRjze3YvIT516kDr5hsoqlenqk6pKIpS7Ugpjt4YMxmYHFV2XdT6yDj7jgJCEpPnnopyQ12pqDkjyCuKouSAgtaAk94opq4ph5Zd8i2KoihK3ijoXDd1jTecnlr0iqJswRS0ot9MHfXRK4qy5bJlKHq16BVF2YJRRa8oilLgbBmKXl03iqJswWwZil4tekVRtmAKV9EHB79WRa8oyhZM4Sr69ev9ZVX0iqJswWwZil599IqibMEUrKLfsEYtekVRFChgRf+/8wIJNt98M3+CKIqi5JmCVfTT31vlr6xcmT9BFEVR8kzBKvri2hX5FkFRFKVaULCKvsM2qugVRVGgQBX9pk2wuKzcLzj33PwJoyiKkmcKMhxl0iRYtayCcqlL3U3rk++gKIpSwBSkRf/tt1CHCmpvpfHziqIoBano58+HJsXl1KpXN9+iKIqi5J2CVfTNGlVoj1hFURQKzEf/ww8wdSrMnAnNGlRAhSp6RVGUglL0Z50FU6bY5Za7lcMqdd0oiqIUlOtm5Ur4859h1izo1lVdN4qiKFBgFn15OTRvDjvtBGxQRa8oigIFZtGvXw91nbemvDywoiiKsuWSkqIXkYEi8r2IzBaRK+PUOV5EZorIDBF5OlC+UUS+8KZJYftmi/JyqFfPW6lQi15RFAVScN2ISBFwH3AgUAZMFZFJxpiZgTqdgKuAvYwxy0SkdeAQfxhjemRZ7lAiLPqIFUVRlC2XVCz6PsBsY8xcY0w5MB4YHFXnLOA+Y8wyAGPM4uyKmRoR3pq1a6FBg3yIoSiKUq1IRdFvCywIrJd5ZUE6A51F5EMR+UREBga2FYtIqVd+ZNgJRORsr07pkiVL0rqAIBGumzVrVNEriqKQvaib2kAnYADQDpgiIt2MMcuB7Y0xC0VkB+BtEfnaGDMnuLMx5mHgYYCSkhKTqRAR3po1a6B+/UwPpSiKUjCkYtEvBNoH1tt5ZUHKgEnGmApjzDzgB6zixxiz0JvPBd4FelZS5lA2brTTZoteXTeKoihAaop+KtBJRDqKSF3gRCA6emYi1ppHRFpiXTlzRaSZiNQLlO8FzCQHlHvp59WiVxRFiSSp68YYs0FEzgdeA4qAUcaYGSJyA1BqjJnkbTtIRGYCG4HLjTFLRaQf8JCIbMK+VG4JRutkkwhFb4xa9IqiKB4p+eiNMZOByVFl1wWWDXCJNwXrfAR0q7yYyXGKvl494I8/rLJXRa8oilI4KRAaNoTx46FXL+C332xhy5Z5lUlRFKU6UDCKfqut4IQTvJVpXohmq1Z5k0dRFKW6UDCKHoD334e334bXXrPrqugVRVEKTNFfcgmUlvrrrVvHr6soirKFUFDZK1m0CE4/3V9Xi15RFKWAFL0xsGRJpBXfuHH+5FEURakmFI6iX73a5kAIKnqR/MmjKIpSTSgcH315uQ272W032yD744/5lkhRFKVaUDiKvkULG0ivKIqiRFA4rhtFURQlFFX0iqIoBY4qekVRlAJHFb2iKEqBo4peURSlwFFFryiKUuCoolcURSlwVNEriqIUOGIHh6o+iMgSoDLdWlsCv2VJnJqCXnPhs6VdL+g1p8v2xpjQTI7VTtFXFhEpNcaU5FuOqkSvufDZ0q4X9JqzibpuFEVRChxV9IqiKAVOISr6h/MtQB7Qay58trTrBb3mrFFwPnpFURQlkkK06BVFUZQAqugVRVEKnIJR9CIyUES+F5HZInJlvuXJFiLSXkTeEZGZIjJDRP7mlTcXkTdEZJY3b+aVi4jc492Hr0SkV36vIHNEpEhEpovIy956RxH51Lu2Z0Skrldez1uf7W3vkE+5M0VEmorIBBH5TkS+FZE9C/05i8jF3u/6GxEZJyLFhfacRWSUiCwWkW8CZWk/VxE53as/S0ROT0eGglD0IlIE3AccAuwCDBGRXfIrVdbYAFxqjNkF2AM4z7u2K4G3jDGdgLe8dbD3oJM3nQ08UPUiZ42/Ad8G1m8F7jLG7AQsA/7ilf8FWOaV3+XVq4n8B/ifMaYr0B177QX7nEVkW+BCoMQY8yegCDiRwnvOo4GBUWVpPVcRaQ6MAPoCfYAR7uWQEsaYGj8BewKvBdavAq7Kt1w5utYXgQOB74G2Xllb4Htv+SFgSKD+5no1aQLaeX+APwMvA4LtMVg7+pkDrwF7esu1vXqS72tI83qbAPOi5S7k5wxsCywAmnvP7WXg4EJ8zkAH4JtMnyswBHgoUB5RL9lUEBY9/g/GUeaVFRTep2pP4FOgjTHmF2/TIqCNt1wo9+Ju4Apgk7feAlhujNngrQeva/M1e9tXePVrEh2BJcDjnrvqURFpQAE/Z2PMQuB24CfgF+xzm0ZhP2dHus+1Us+7UBR9wSMiDYHngYuMMSuD24x9xRdMnKyIHA4sNsZMy7csVUhtoBfwgDGmJ7AG/3MeKMjn3AwYjH3JbQM0INbFUfBUxXMtFEW/EGgfWG/nlRUEIlIHq+SfMsb8n1f8q4i09ba3BRZ75YVwL/YCBonIfGA81n3zH6CpiNT26gSva/M1e9ubAEurUuAsUAaUGWM+9dYnYBV/IT/nA4B5xpglxpgK4P+wz76Qn7Mj3edaqeddKIp+KtDJa62vi23QmZRnmbKCiAjwGPCtMebOwKZJgGt5Px3ru3flp3mt93sAKwKfiDUCY8xVxph2xpgO2Gf5tjHmZOAd4FivWvQ1u3txrFe/Rlm+xphFwAIR6eIV7Q/MpICfM9Zls4eI1Pd+5+6aC/Y5B0j3ub4GHCQizbwvoYO8stTIdyNFFhs7DgV+AOYAV+dbnixe197Yz7qvgC+86VCsb/ItYBbwJtDcqy/YCKQ5wNfYiIa8X0clrn8A8LK3vAPwGTAbeA6o55UXe+uzve075FvuDK+1B1DqPeuJQLNCf87A9cB3wDfAWKBeoT1nYBy2DaIC++X2l0yeK3Cmd+2zgTPSkUFTICiKohQ4heK6URRFUeKgil5RFKXAUUWvKIpS4KiiVxRFKXBU0SuKohQ4qugVRVEKHFX0iqIoBc7/A5/IPh4G92QRAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd5hT1dbA4d+SKl2KgoKAShGlD6CiCBYEC4hiQRSRq9hRsGHnw2v32q7gFQtYUMB6URCuNAWxMBSVqlQZUMRRmggMsL4/VkIyNZmZzGQms97nyZPTcs7OBFZ29tl7bVFVnHPOFX8HxbsAzjnnYsMDunPOJQgP6M45lyA8oDvnXILwgO6ccwnCA7pzziUID+guSyLyqYhcGetj40lE1orIGQVwXhWRYwLL/xGR+6M5Ng/X6Ssi/8trOXM4b2cRSYn1eV3hKx3vArjYEZEdYasVgN3AvsD6tao6NtpzqWr3gjg20anqdbE4j4g0ANYAZVR1b+DcY4GoP0NX8nhATyCqWim4LCJrgatVdVrG40SkdDBIOOcShze5lADBn9QicpeI/AqMFpFDROQTEdksIn8GluuGvWaWiFwdWO4vInNE5KnAsWtEpHsej20oIl+IyHYRmSYiI0TkrWzKHU0ZHxKRLwPn+5+I1Azbf4WIrBORVBG5N4e/TwcR+VVESoVt6yUi3weW24vIVyKyRUR+EZEXRKRsNucaIyL/DFu/I/CajSIyIMOx54jIQhHZJiLrRWRY2O4vAs9bRGSHiJwY/NuGvf4kEZknIlsDzydF+7fJiYgcG3j9FhFZIiI9wvadLSJLA+fcICK3B7bXDHw+W0TkDxGZLSIeXwqZ/8FLjtpAdaA+MBD77EcH1o8E/gZeyOH1HYAVQE3gCeBVEZE8HPs28C1QAxgGXJHDNaMp42XAVcChQFkgGGCaAS8Gzn944Hp1yYKqfgP8BZyW4bxvB5b3AYMD7+dE4HTghhzKTaAM3QLlORNoBGRsv/8L6AdUA84BrheR8wP7OgWeq6lqJVX9KsO5qwOTgOcD7+1pYJKI1MjwHjL9bSKUuQzwMfC/wOtuBsaKSJPAIa9izXeVgeOBGYHttwEpQC3gMOAewPOKFDIP6CXHfuBBVd2tqn+raqqqvq+qO1V1O/AwcGoOr1+nqi+r6j7gdaAO9h836mNF5EigHfCAqu5R1TnAxOwuGGUZR6vqj6r6NzABaBXY3hv4RFW/UNXdwP2Bv0F23gH6AIhIZeDswDZUdb6qfq2qe1V1LfBSFuXIysWB8i1W1b+wL7Dw9zdLVX9Q1f2q+n3getGcF+wL4CdVfTNQrneA5cB5Ycdk97fJyQlAJeCxwGc0A/iEwN8GSAOaiUgVVf1TVReEba8D1FfVNFWdrZ4oqtB5QC85NqvqruCKiFQQkZcCTRLbsJ/41cKbHTL4NbigqjsDi5VyeezhwB9h2wDWZ1fgKMv4a9jyzrAyHR5+7kBATc3uWlht/AIRKQdcACxQ1XWBcjQONCf8GijHI1htPZJ0ZQDWZXh/HURkZqBJaStwXZTnDZ57XYZt64Ajwtaz+9tELLOqhn/5hZ/3QuzLbp2IfC4iJwa2PwmsBP4nIqtFZGh0b8PFkgf0kiNjbek2oAnQQVWrEPqJn10zSiz8AlQXkQph2+rlcHx+yvhL+LkD16yR3cGquhQLXN1J39wC1nSzHGgUKMc9eSkD1mwU7m3sF0o9Va0K/CfsvJFqtxuxpqhwRwIboihXpPPWy9D+feC8qjpPVXtizTEfYTV/VHW7qt6mqkcBPYAhInJ6PsvicskDeslVGWuT3hJoj32woC8YqPEmA8NEpGygdndeDi/JTxnfA84VkZMDNzCHE/nf+9vALdgXx7sZyrEN2CEiTYHroyzDBKC/iDQLfKFkLH9l7BfLLhFpj32RBG3GmoiOyubck4HGInKZiJQWkUuAZljzSH58g9Xm7xSRMiLSGfuMxgU+s74iUlVV07C/yX4AETlXRI4J3CvZit13yKmJyxUAD+gl17PAwcDvwNfAlEK6bl/sxmIq8E9gPNZfPit5LqOqLgFuxIL0L8Cf2E27nATbsGeo6u9h22/Hgu124OVAmaMpw6eB9zADa46YkeGQG4DhIrIdeIBAbTfw2p3YPYMvAz1HTshw7lTgXOxXTCpwJ3BuhnLnmqruwQJ4d+zvPhLop6rLA4dcAawNND1dh32eYDd9pwE7gK+Akao6Mz9lcbknft/CxZOIjAeWq2qB/0JwLtF5Dd0VKhFpJyJHi8hBgW59PbG2WOdcPvlIUVfYagMfYDcoU4DrVXVhfIvkXGKI2OQiIq9hbXW/qerxWewX4DmsK9NOoH9Y31TnnHOFJJomlzFAtxz2d8duiDTCRiC+mP9iOeecy62ITS6q+oVY5rfs9ATeCIwK+1pEqolIHVX9Jafz1qxZUxs0yOm0zjnnMpo/f/7vqlorq32xaEM/gvSj4VIC23IM6A0aNCA5OTkGl3fOuZJDRDKOED6gUHu5iMhAEUkWkeTNmzcX5qWdcy7hxSKgbyD98Oa6ZDP8WFVHqWqSqibVqpXlLwbnnHN5FIuAPhHoJ+YEYGuk9nPnnHOxF7ENXUTeAToDNcXmHXwQKAOgqv/BckqcjQ1t3onlX86TtLQ0UlJS2LVrV+SDXVyVL1+eunXrUqZMmXgXxTkXEE0vlz4R9iuWMyPfUlJSqFy5Mg0aNCD7uRNcvKkqqamppKSk0LBhw3gXxzkXUKSG/u/atYsaNWp4MC/iRIQaNWr4LynnipgiFdABD+bFhH9OzhU9RS6gO+dcQtq9G8aMgQLMcOsBPUxqaiqtWrWiVatW1K5dmyOOOOLA+p49e3J8bXJyMoMGDYp4jZNOOiniMdGYNWsW5557bkzO5ZwrBA88AFddBR9/XGCX8GyLYWrUqMGiRYsAGDZsGJUqVeL220MTpe/du5fSpbP+kyUlJZGUlBTxGnPnzo1NYZ1zxcv6wID67dsL7BJeQ4+gf//+XHfddXTo0IE777yTb7/9lhNPPJHWrVtz0kknsWLFCiB9jXnYsGEMGDCAzp07c9RRR/H8888fOF+lSpUOHN+5c2d69+5N06ZN6du3L8HMl5MnT6Zp06a0bduWQYMGRayJ//HHH5x//vm0aNGCE044ge+//x6Azz///MAvjNatW7N9+3Z++eUXOnXqRKtWrTj++OOZPXt2zP9mzrks7N1rzykpUEAdCopsDf3WWyFQWY6ZVq3g2Wdz/7qUlBTmzp1LqVKl2LZtG7Nnz6Z06dJMmzaNe+65h/fffz/Ta5YvX87MmTPZvn07TZo04frrr8/UZ3vhwoUsWbKEww8/nI4dO/Lll1+SlJTEtddeyxdffEHDhg3p0yfHXqMAPPjgg7Ru3ZqPPvqIGTNm0K9fPxYtWsRTTz3FiBEj6NixIzt27KB8+fKMGjWKs846i3vvvZd9+/axc+fO3P9BnHO5t2+fPQ8dCpUqwY0x6e2dTpEN6EXJRRddRKlSpQDYunUrV155JT/99BMiQlpaWpavOeeccyhXrhzlypXj0EMPZdOmTdStWzfdMe3btz+wrVWrVqxdu5ZKlSpx1FFHHejf3adPH0aNGpVj+ebMmXPgS+W0004jNTWVbdu20bFjR4YMGULfvn254IILqFu3Lu3atWPAgAGkpaVx/vnn06pVq3z9bZxzGezaBfv3Q4UKVhuvUQMOPjhUQweoWbNALl1kA3peatIFpWLFigeW77//frp06cKHH37I2rVr6dy5c5avKVeu3IHlUqVKsTf8w8zFMfkxdOhQzjnnHCZPnkzHjh2ZOnUqnTp14osvvmDSpEn079+fIUOG0K9fv5he17kSrX59+O03681Srx506waffgo//BA6poACureh59LWrVs54ogjABgzZkzMz9+kSRNWr17N2rVrARg/PvIE86eccgpjx44FrG2+Zs2aVKlShVWrVtG8eXPuuusu2rVrx/Lly1m3bh2HHXYY11xzDVdffTULFvjkUs7FxNKlIGLBHELt5FOmwAUXwJo1oWM9oBcNd955J3fffTetW7eOeY0a4OCDD2bkyJF069aNtm3bUrlyZapWrZrja4YNG8b8+fNp0aIFQ4cO5fXXXwfg2Wef5fjjj6dFixaUKVOG7t27M2vWLFq2bEnr1q0ZP348t9xyS8zfg3MJa+1a+P33rPd9+GH69fPOy35fjRoxLVZQxDlFC0pSUpJmnOBi2bJlHHvssXEpT1GyY8cOKlWqhKpy44030qhRIwYPHhzvYmXin5crcUSgYkXYscPW166Fhg2he3drVolWWhpk0wU6chFkvqpm2Ufaa+hF0Msvv0yrVq047rjj2Lp1K9dee228i+RcybJpE9x8M2Q1oPCvv0LLM2bYc26COeQ5mEc8bYGc1eXL4MGDi2SN3LkSY8gQePtt6NLF2r+Tk6Fv3/THbN8OEyfGp3zZ8IDunCvZFi+Gzz6DwYPhoousSSXYHTl4n+zqq+HHH0OvWbXKgv369ZnPl5P77oNLLolNubPgAd05V7KdeKK1id94I7z3nm0LBt2NGy24f/dd+tccc0x05y5VKjSgCOD//g8OKriWbm9Dd86VPN9+G+pGGLzBGd57JRh0Bw+GatVyf/4yZWxw0f/+BzfcAPfem/68BcQDunOu5OnQAY46Ct58MxRkA+NLAPjzz9BypPQY7dvb8+mnh7aNH289Yk47DUaMgH/+s0DT5gZFFdBFpJuIrBCRlSIyNIv99UVkuoh8LyKzRKRuVucp6rp06cLUqVPTbXv22We5/vrrs31N586dCXa/PPvss9myZUumY4YNG8ZTTz2V47U/+ugjli5demD9gQceYNq0abkpfpY8za5zYZKTrYklqF8/q01nNGVK5HOtWGFBesYMC+DTpsH8+dZDplev2JU5FyIGdBEpBYwAugPNgD4i0izDYU8Bb6hqC2A48GisC1oY+vTpw7hx49JtGzduXFQJssCyJFbLy88zMgf04cOHc8YZZ+TpXM6VGAsWWE14+fLM+375Bb7+OrSuCu3apd8GNvFEXgRr9BUrwsUX23KbNnDooXk7XwxEU0NvD6xU1dWqugcYB/TMcEwzINAhk5lZ7C8WevfuzaRJkw5MZrF27Vo2btzIKaecwvXXX09SUhLHHXccDz74YJavb9CgAb8H2uEefvhhGjduzMknn3wgxS5YH/N27drRsmVLLrzwQnbu3MncuXOZOHEid9xxB61atWLVqlX079+f9wI3aKZPn07r1q1p3rw5AwYMYHfgH2CDBg148MEHadOmDc2bN2d5Vv+ow3iaXZdw3nzTnidNyryvQ4dQbXz7dmjRIm/XqF/f8rCkpUF45S4sx1NREU0vlyOA8L45KUCHDMd8B1wAPAf0AiqLSA1VTQ0/SEQGAgMBjjzyyJyvGof8udWrV6d9+/Z8+umn9OzZk3HjxnHxxRcjIjz88MNUr16dffv2cfrpp/P999/TIpt/IPPnz2fcuHEsWrSIvXv30qZNG9q2bQvABRdcwDXXXAPAfffdx6uvvsrNN99Mjx49OPfcc+ndu3e6c+3atYv+/fszffp0GjduTL9+/XjxxRe59dZbAahZsyYLFixg5MiRPPXUU7zyyivZvj9Ps+sSTrB7YVbNJsEuhZMnwznn5P0aM2faaFCA11+3QB6h8hQvsbopejtwqogsBE4FNgD7Mh6kqqNUNUlVk2rVqhWjS8dWeLNLeHPLhAkTaNOmDa1bt2bJkiXpmkcymj17Nr169aJChQpUqVKFHj16HNi3ePFiTjnlFJo3b87YsWNZsmRJjuVZsWIFDRs2pHHjxgBceeWVfPHFFwf2X3DBBQC0bdv2QEKv7MyZM4crrrgCyDrN7vPPP8+WLVsoXbo07dq1Y/To0QwbNowffviBypUr53hu5+Ii2E88fOTl1KnWph0UKZhHyJWUrgmlTBl4+WUoor9Yo6mhbwDqha3XDWw7QFU3YjV0RKQScKGqZr47mBtxyp/bs2dPBg8ezIIFC9i5cydt27ZlzZo1PPXUU8ybN49DDjmE/v37syuPM47079+fjz76iJYtWzJmzBhmzZqVr/IGU/DmJ/2up9l1xVawj3d4Db1bt9ydo1o12Lo18/aVK+Hoo/NetjiIpoY+D2gkIg1FpCxwKZBuvKuI1BSR4LnuBl6LbTELT6VKlejSpQsDBgw4UDvftm0bFStWpGrVqmzatIlPI+Rt6NSpEx999BF///0327dv5+OwSWG3b99OnTp1SEtLO5DyFqBy5cpsz2KuwSZNmrB27VpWrlwJwJtvvsmpp56ap/fmaXZdsbd9O/z0U2g92OQybpxtz0vXwKQkCE7e/s038OuvsG1bsQvmEEUNXVX3ishNwFSgFPCaqi4RkeFAsqpOBDoDj4qIAl8AsZ9bqRD16dOHXr16HWh6Caabbdq0KfXq1aNjx445vr5NmzZccskltGzZkkMPPZR27dod2PfQQw/RoUMHatWqRYcOHQ4E8UsvvZRrrrmG559//sDNUIDy5cszevRoLrroIvbu3Uu7du247rrr8vS+gnOdtmjRggoVKqRLsztz5kwOOuggjjvuOLp37864ceN48sknKVOmDJUqVeKNN97I0zWdi6kzz7Sgu3w5NGkSanKZMQMCzZK58vXX0KyZ9XTZvBmKefZQT5/r8sw/L1fg3nvP2rjPPNPWRUL7VOHCC+GDDyKfp39/S3UbbOLs1MkScPUsfh3yckqf67lcnHNF10UX2XNWFc+FC+0RyXnnwWuv2ZdB8Ath+vQCS2EbTz703zlXPKxalX69TZv007qdfroF6owmTkxfs4eEDOZQBGvoqopk/OO7IideTXUugfz4I3zyiQ0AinBfit27I3c/rFMnNHrzsMNsCH7G7rbXXw/r1uW9zEVckQro5cuXJzU1lRo1anhQL8JUldTUVMqXLx/vorjirEmT0PJ//gPhM3O9+Sa0bh1av+suy52SlQsusJ4qF19sgRzg4INhyRKoXj39sSNHxqbsRVSRuimalpZGSkpKnvt4u8JTvnx56tatS5msRug5F42MlbZ9+0KZDzPu69LFRmxmJdjjJeiFF6Br17z1eikGis1N0TJlytAwOMTWOVey7N5tNev9+zPvW7Ys/frAgTBokAXtjJWKm24quDIWcUUqoDvnSoCtWyGrwXG7dlkwnzw5875ff02/fsUVcNxxBVO+Ysx7uTjnCt4zz0CFCra8enXmKd3AauiXXx5KRRt0Y4Zxiqpw8skFU85izgO6c67gDRkCf/9t7eTZZe7ctQvmzMm8vWvX0HK9epn3uwM8oDvnCs7y5ekzE+7enX1AX7Mm/byeffrYDEBnnQUDBlgWxfB+5y4Tb0N3zhWcjKkh5s/PevAP2Pyb4fr1s8FDAK++GvuyJSAP6M65wtOpU3THtW6d+zS4zptcnHN5sHUrpKZGPi6vPvyw4M6dwDygO+dyr3ZtqFkz+/379sEjj+R8jo8+slGe4b75xnKR16+f/zKWQN7k4pzLvfDR3CtWWG39xBPh009t0onXXrOkWDnp3t1GgB59NDz5pG1r0QI8pUSeeUB3zuXd1q3QtKktT5iQuQ95TsqWtccTT1iSrmXLPJjnkwd051zeXXVVaLl//+heM3Vq5sC9dGnWQ/5drkTVhi4i3URkhYisFJGhWew/UkRmishCEfleRM6OfVGdc0VOeL/w7PqXhxs82AYKZdXb5SC/pZdfEf+CIlIKGAF0B5oBfUSkWYbD7gMmqGprbBLpxM5R6VxJtH8/PP54+sE/0QThww+352uugX/+s2DK5oDoaujtgZWqulpV9wDjgIwT8SlQJbBcFdgYuyI654qEBQtg6FDLtxK+LZKRI6FWLXjuuVA+F1cgognoRwDrw9ZTAtvCDQMuF5EUYDJwc1YnEpGBIpIsIsmbN2/OQ3Gdc3ETbFKZOjXyscEmFRGbiPm33yw1ritQsWq06gOMUdW6wNnAmyKS6dyqOkpVk1Q1qVatWjG6tHOuUIQ3tUTSp4/d6NzoP9YLUzQBfQMQnuKsbmBbuH8AEwBU9SugPJDDqAPnXJGxcyeMGpW+b/nOnTBsGLz8sq2nptoNzWjVqWN5XGrXjmlRXc6i6bY4D2gkIg2xQH4pcFmGY34GTgfGiMixWED3NhXnirpff7XgC5an/LHHbPn+++Hpp225Uyd49FH4+eecz/Wvf0HfvvD119CjR8GV2WUrYkBX1b0ichMwFSgFvKaqS0RkOJCsqhOB24CXRWQwdoO0v/q08M4VfatXh5Y3bQothzev7NsHr78e+VxDhthzz4x9JlxhiWpgkapOxm52hm97IGx5KdAxtkVzzhWIDz6AUqUs8L71Vmh7+MCeN94ILYdP9da4sfVy+eyz9HnOXZHgI0WdK2kuvNCeO3aEL78Mbd+/39rRk5Ozf+3cuVCjhjXJLFwIK1fmbri/K1A+NMu5kmLBAjjqqNB6eDAHm6vz0kvhlFOyfv2AARbMg1q3hosuspunWU0d5wqdxKupOykpSZNzqgk457L3r3/Bhg2hG5czZ8KePTZdW9DevbBjB2zZYm3i7drl/XonnADvvx8a9eniRkTmq2pSlvs8oDtXRE2ZAr162c3KKlXS7xOx5+D/3/D1RYts6rZY/t/2Pg5FRk4B3ZtcnCuqrrrK2rSXLIn+NTfdZIN6og3A0aSrDR/q74o0vynqXEHaudNyfpfOxX+1zz+HqlWtjzhYt8FwCxdm/9oRI6K7RrVq1hRz663Wlp6xx0rp0jZRxcKF0Lx59GV3ceU1dOcKUsWKmadZy8nevdC5s91wDAp2JwyO5BwZg2Smd9wRWp42zXqrBK1ebe3zYOXIzZeRiysP6M4VtI8/Di3v2wc//GAB8+ijYdWq9MeG5xcP2r/f+osffLDdmHzlldC+99+Ha6/NXXmuvjr9etmyVpbJk+HVV6FhQzj00Nyd0xUJHtCdKyhZtWM/9JDNm3nvvVYTHjHCgvz27bZtypTMr9m7F95915Z7906/r3dvy8OSUfXq9jxlitXsP/vM1p94Al56CRo1svXGjUOv6d7duia6Yst/SzlXUPbuTb++dm2ov3ZwmP0zz8Aff+Q8tH73bmvvzo05cyw5VtAZZ8BXX0H79jYpRe/edsxJJ+XuvK5I8xq6c7Hw99+Zt4VnL/zmG2vKmD7d1suUCe2LlCdl2DD44ovoytGliyXHCg/mQSecEJphSMRGiga7O7qE4AHdufx6912biSdj98LwgL5sWfp9S5dGf/7cjNeoWhU6dIj+eJdQPKA7l1fr1lmPk0mTbP2bb0L71q9Pf2Nxx470r814MzSvzjvPnuvXt+ft22NzXlcseUB3Lq8aNIAbbwzVxIcOtRuhv/2WOWHVzVnOyph7d96Zfr1aNXu+5BLLw/LCC7G5jiuWPKA7l9G4celr1B9+CPPmpT/ml19CyzNn2vPmzdYlccgQa8fOq+OPtxuYGX3+uX2JACQlWTlHjoRBg+C+++Cdd6Bp07xf1xV73svFuXALF9rQ+SuuCOUEDw4M2rbN+oRXrZq+aeO330LLLVvCMcfkrwwzZkDGOXePPNJmDgp+kfTsabVygOeey9/1XMLwGrpzQQsX2uQPYINs1q1L3wukShVr4ti9O+fBPOGjLjO6997Q8g03WBPN22+HtvXsmTmYT50Kn35qyxddBG++CXfdFd17ciVKVDV0EekGPIdNQfeKqj6WYf8zQJfAagXgUFWtFsuCOlfg2rQJLaemhpo3MoomoVXQQQfBZZdZrf/ss21b1642pL5yZVsPDkC6/HIL1kHvvGPl6No1/fk8WZbLRsSALiKlgBHAmUAKME9EJgamnQNAVQeHHX8z0DrTiZwrqiZNyl2Qzo0//rAmmnCdOqVfv+ACG6H58MPpt196acGUySWsaJpc2gMrVXW1qu4BxgE5zQLbB3gnFoVzrsClpMC559pIyvyqUsVupjZpYusvvJA5mGelfHnLoVK7dv7L4Eq0aJpcjgDWh62nAFmOXBCR+kBDYEb+i+ZcAdu/H+rVi825HnkEbr/dRoB+953lZ6lQITbndi5Ksb4peinwnqruy2qniAwUkWQRSd68eXOML+1cFPbvt+aN5GRYsSJ2573qqtBw/nLlPJi7uIgmoG8AwqsxdQPbsnIpOTS3qOooVU1S1aRaGe/kO5dX8+fDe++l36Zq/cN3706//amnYPRom1+zWbPsz5ld+tiaNUPL+/bB449DpUpw2GF5K7tzMRRNQJ8HNBKRhiJSFgvaEzMeJCJNgUOALEZEOFeAkpKsO1+4CRPgtNMsVWzQqlXRdff78Ud48MHQ+saNNhnz8OE2uw9YL5WDDrKRm9u3e5IrVyREDOiquhe4CZgKLAMmqOoSERkuIj3CDr0UGKfxmnXauXA//WTPy5dbsH3iicgDfp57zppkGjUKTf92331Qpw4MHgz332/5wzdtCqXBda4IiaofuqpOBiZn2PZAhvVhsSuWc9nYscPaq597Dg4/3HqpBM2aZbXl7t1D6WznzrXnSDXzatVsoE+wpn3KKfbco0fmY302H1dEFbuh/5Mm2Wxcb70FpUrFuzSu0E2YYO3llSpZW3j4QJwugbFt990Hf/1ly999F/mcM2faPJ7hzjzTkm6VKxeTYjtXGIpdQF+1ynISvfAC1KgR79K4QhecoGHfPmsfv+eezMf885/Rny85Gdq2zXqfB3NXzBS7XC6HVtpJY1bw++/xLomLi2BA37kTrrsub+fo3NlupP73v9kHc+eKoWIX0NvMfpYVNOXPDTvjXRRXWNLS4PnnYc+eUDtbxhmAovXmmzYN3Lx5WbePO1eMFbuAXuaoIwH4a/n6CEe6Yu/nn+1G5ciRcMst1gQSDOgbN0Z+/ZFHhpZPO82aZy6/PFTLdy7BFLs29ErH2VRbfy9fBzSJb2Fc9BYtgrFjoVs3C67B3iSvvWY9SkqVsrkwv/7abniWLWuz/nzzTShLYbgtW7K+zs03w7//Dc2b2/VSUuD77z3drCsRil1Ar9GxKfsRyi+YC3SNeLwrIk47Df7800ZqvvGGTSCxbx/84x/WZfDmm+H3361J5P33YfHi0Gsnh/WY7dMn+2uUL29t4+I6JdUAACAASURBVADDhllQb97cujE6VwIUu9+eBx1Wi3kHd6LJd+NDeaRd0RfsFw6wejVs2BDqWrhliwV3sJp6eDCPxsknW+7wbdvsi+Lrr0OzDDlXghS7gA6wun0f6u1Yzt9zF8S7KC4r48eHRmq+9571F98Xlq/t55+hbt30XQ5/+MGeH0g3Xi17wenXAGbPttzhZcpYU06HLJOBOpfwimVAP2LIJeyiHBsfHh3voriMVC24tg7McXLRRZbdMC0tdEww0+aIEaFtH38c+dzhM96//LIl12rRIv9ldi5BSLxSryQlJWlycnKeXrt3L0yseClnyjQq7/gVShe7WwGJa/t2m+gBLNNhrAbntG4NCxaEbqb6KE5XQonIfFVNympfsayhly4Nv5x0IZV3p5L2hSd3LDJ27QrNSg82H2Z+3HBDaDk4SXIwC2LZsvk7t3MJqFgGdICG13UjjdKsH/VpvIvigqpVC02/BpY8K1qnnpp+vUULS1cbFMw3PmyYNet4ulrnMim2Af20npVZKG1RT2MaG3/8kbteQ7t32xyYwYkl9u/PPJlEJOG5yp9+Gl58MbQ+b54n63Eul4ptQC9fHlYffjJ1N36b+0Di0luxwoJneIDNyltvWWbCn36yD2DTJhgyBF55JXLqy/UZRva+9x4MHGh5xsHa3a+7zr5UVENNKgsWRJcx0TlXfAM6wJ72J1NOd7N77vx4F6V4C86tOWlS+u1jx1o3wp9+sr7iV1xhA4T69Qsds349XHNN9uc++mirvdetG9o2dy5ceKEtP/GEBe3sJp9o3dp7sjgXpWId0Gv06AjApvdmx7kkCSK8Xfq11yzvyUMP2Sw98+aF9n39dXTnGz7cpnMLnjd4k/PEE0PHlC4d6uLonMuXYh3Qj+9Si6UcS4WJ43zUaF6MGWPBNthzZOVKm0Bi7Vobkh+ua4Q0C5dfnnnbJZekT4Q1YoR/Ts4VoKgCuoh0E5EVIrJSRIZmc8zFIrJURJaIyNuxLWbWjjwSPijfl5opiyxPiMva4sV2w3HXLlv/6y9LIXvVVba+aJE9L1tmQbhhw9xfIzjC8/nn7fybN1vN3jlXaCKOyBGRUsAI4EwgBZgnIhNVdWnYMY2Au4GOqvqniBTKpIsisO+YJrAYG05evXphXLbo27wZnnwSHnnEmjSaN7ft8+bZXJxHHx0arRkr9eunr31XqBDb8zvnIoqmht4eWKmqq1V1DzAO6JnhmGuAEar6J4Cq/hbbYmavWktLp7t39c+Fdcmi7bHHbBLjJ5+0GXlefTW074MPrHkl2mAe3jPlkUdg+XJbDuZgqVMH/u//bNkH+jgXd9EE9COA8D5nKYFt4RoDjUXkSxH5WkS6ZXUiERkoIskikrw5RjXEI0+2SQw2fbsuJucr9u6+O7TcuzdcfXVofetWeOaZ9Mc/9FD25wr2TCld2s7bpIkF+eHDYepUq/E/8IC3iztXRMTqpmhpoBHQGegDvCwi1TIepKqjVDVJVZNq1aoVkws37XQouyjHlu88oOfK7NnWnfC+++CQQzLv37TJnv/4I32Nvm5d63PetSsckfF73TkXT9FktdoA1AtbrxvYFi4F+EZV04A1IvIjFuDnUcAaNRYWSXNqfVcCR4wuXw7vvgvXXmsDfrZujf61J58cWp41C1q2tOXDDoNBg6zZBrIO9s65IimagD4PaCQiDbFAfilwWYZjPsJq5qNFpCbWBLM6lgXNTunS8P2hZ9Lv1yctDWMiZ14cOdJyfs+YYTP7HHusbc8uh3jduhaQg7nGwfqCZ+zF0qKFzSR0++2hh3Ou2IkY/VR1r4jcBEwFSgGvqeoSERkOJKvqxMC+riKyFNgH3KGq+Uy1F739Rzei9Ka91n86uxGHxVVwYoitW+HGG0Pb586N/NrgEP20NOua2K5d9sfecovd2Lz22vyV1zkXN1FVZ1V1MjA5w7YHwpYVGBJ4FLqyxzWCufD3Dys5OJEC+t9/Q9u29vx2hq79P0fo1TNpkgVzsFp9TsEc7JfNzTfnvazOubgr1iNFg6q1awRA6tc/xbkk+aQK995rU6jdf7/15V62zH55vPFGdOf45BO72Xn22QVaVOdc0VMsZyzKaNFCpU6b2uw5sTP15o6PyTnjYts2qFo1+uPLl4fTT7cuhcGbnN6F0LmElnAzFmV0TCPhfS6k3lcTrDtecaNqN3Q3box87NSpFsS7drWa+yefwAkn2L5Eam5yzuVaQgT0SpXgv3VvspXRxWji6F27bJq2e+6xdu5gr5VwdepAz7CBuV27wrRpFtiDs/iUKmU9X6K5UeqcS1gJ08evbKtmrE5pyFGjR8NJJ6UfIVlUde9ufcBz8uOP9o21ZInlS8lOly4xLZpzrvhJiBo6QMeO8A8CeUvuuadotiXv32/dD4cOtcxikYI5WDAHOO640LJzzmUhYQL67bfDLLrw2fG32lD1//433kUKSU21gTsDB9pEyo8/Ht3rtm0r2HI55xJKwjS5lC4N9erB+Yv/yV88C716we+/F42JhgcNytyPPNyDD8L118PBB1vPldRUWL0aKlcuvDI654q9hKmhAzRqBDupyJbegfbzmjXhyy/jV6CVKyElxQJ0VhYtsvS2995rNzirVLHRmnXqWBuSc87lQkIF9EcftefpvV8MbTz5ZIhRf/dca9vWfjYsXZp534oVlhBrwADr4eKcc/mUUAG9ZUurlL//39JWOw4aNy4+BQq2gYdPFBHk07M552IsoQJ6uXJw2mkwZw7oUUeHgvqYMZapsKCNHm1ZEH/91drws1KrlrWpO+dcjCVUQAfo1s0qxK+/js2d2aOHtWGHZyosCKrWfNKvn7WBf/RRaN/AgbBlC3z2Gfz2m83r6ZxzMZZwAf2SS+z5zjsDXdGffTa0U8QG6BSEUaOy3n733fDSS5aj5YwzCubazjlHAgb0ChVsmszNm+H777HJHB5+OHRAQTW9TJ2afv3nn23bvfcWzPWccy6DhAvoABdeaM+tWgU23HYbnHqqLY8caeux9MMP8OGHtrxjh/00qFfP8q5UrBjbaznnXDYSMqA3bRpabtwY1mwsZ8PsX3rJNj79NOzZY8s7d4ZmBcqtzZvhlFNsCjeAa67xAO6ci5uoArqIdBORFSKyUkSGZrG/v4hsFpFFgUdcM2OJhDq4/PQTPPFEYMc//gHnn2/LSUkwYYIF4BtuyP1F9u+3iSjmBCanPu00G97vnHNxEjGgi0gpYATQHWgG9BGRZlkcOl5VWwUer8S4nLl29NFw/PG2XKVKYGOpUvDuu3DZZdZMEryDOmpU6Gbppk2h2ntWtmyxan+pUrBmjW077zyYMiXsQs45V/iiqaG3B1aq6mpV3QOMA3pGeE2REExmGGzeBizpy9ixMHhw+oOPPx4eeABq1848t+bGjXDFFTZUf9Qoq/YHNWhg/dx9tKdzLs4iTkEnIr2Bbqp6dWD9CqCDqt4Udkx/4FFgM/AjMFhVMw2PFJGBwECAI488su26deti9Day17MnTJyYRZ4uVZg50zqsZzVfZ/XqVmuvXRuOPDLr0Z7B8zjnXCEpjCnoPgYaqGoL4DPg9awOUtVRqpqkqkm1atWK0aVzFuzQEmzqPkDE2r1HjIBhw2wwULg//rBte/ZkDubz5sF999ksQc45V0REE9A3APXC1usGth2gqqmqujuw+grQNjbFy7/27e2+5/Dh2RxQqZKlr9240Wrbzz+ffn+5cqHlGjVspGdSknV291mCnHNFSDQBfR7QSEQaikhZ4FJgYvgBIhJeve0BLItdEfOnfHkb27NgAbz1VhQvuPnm0GTNhx9uz0ccAWlp1m5TSL8snHMutyIGdFXdC9wETMUC9QRVXSIiw0WkR+CwQSKyRES+AwYB/QuqwHlxxx1Wub7iCqtgR1SnjtXWN2yAjz+G776zm6nOOVeERbwpWlCSkpI0uRDzlJ9zDkyeDBdcAO+/X2iXdc65mCqMm6JF3quB+aM/+ADeeSe+ZXHOuYJQYgJ67dqWgRFsXNHy5fEtj3POxVqJCehgHVOCOneOWzGcc65AlKiAXrYsjB9vy5UqxbcszjkXayUqoANcfDFcfz2sWgXTpsW7NM45FzslLqAD3BRIWnDmmTZgdMWK+JbHOedioUQG9GbNrHt50Ctxzw3pnHP5VyIDOsC551oNHWyeCuecK+5KbEAHm/KzShVLuLhhQ+TjnXOuKCvRAV0EBgyw5bp1LU26c84VVyU6oAM88wzcdZctX355fMvinHP5UeIDOlhq86DgtHXOOVfceEDHBhkF29CXLIH33rPZ5pxzrjjxgB5w+OHwxRe2fNFF0Lo1/PJLfMvknHO54QE9zCmnpL8x2qxZ/MrinHO55QE9g8sug8ces+UtW2Dv3viWxznnouUBPQu33gqdOtny1Vfb7HPOOVfURRXQRaSbiKwQkZUiMjSH4y4UERWRLGfTKC7KlYPp06FXLxt0VLYsdOhgs9I551xRFTGgi0gpYATQHWgG9BGRTK3LIlIZuAX4JtaFjIfSpW2qun//29a//Rb++9/4lsk553ISTQ29PbBSVVer6h5gHNAzi+MeAh4HdsWwfHElYpkZv/7a1nv1giefhK1b41su55zLSjQB/Qhgfdh6SmDbASLSBqinqpNiWLYio0MH+M9/bPnOO6FJExth6pxzRUm+b4qKyEHA08BtURw7UESSRSR5czFLcXjttTbBNMCmTTBkCDz+eHzL5Jxz4aIJ6BuAemHrdQPbgioDxwOzRGQtcAIwMasbo6o6SlWTVDWpVq1aeS91nPTqBT//DGecYetDh0Lz5jYgKeMN010J0/DknCsuogno84BGItJQRMoClwITgztVdauq1lTVBqraAPga6KGqyQVS4jirVw8++wx+/dXWFy+GU0+1x4cf2rb334eDD4Zly+JXTudcyRMxoKvqXuAmYCqwDJigqktEZLiI9CjoAhZVhx0Ga9bAMcfY+uzZcMEFMGdOaLRpckJ+pTnniirROHWuTkpK0uQEiXhr11pzTMaEXnXqWD6YPXugTJm4FM05l2BEZL6qZjnWx0eKxkCDBjB/vgX1cMHkXg89ZN0ff/gh82sXL4azz4adOwu8mM65BOc19BhStaaXefOsa+N556Xf37y5NcOkpdmN1O7doU0bWLgQvvwSTjoJtm+HChWgVKn4vAfnXNGWUw29dGEXJpGJWA6YYB6Yf/0LPv4YZs2y9R9+sLQCQWvWWK8ZsGaZtDSb4/SWW+DZZwu16M65BOBNLgVoyBCYORP++APOOivz/rPOgtRUW/7jj1Bwf+45Sz0wd27o2B9/LPjyOueKNw/oheCQQ2DKFPjzT/jqK+u/DumD9KBBti9o3z4bjTpjht1QbdIEXn65cMvtnCtevA09Tn78Ee6/HyZMyP6Ys8+2m62bNoW2rV0L9esXePGcc0WU93Ipgho3hjFjrCfMsmXw9NOWM+axx2xQEsDkyemDOdj0eFnZt8/a4Z1zJZcH9Dg6+GCoXRuaNoXBgy2r4113we+/h26kZrR1qw1eCvaWARg1ytrcw2+45sXff1v+95Ej83ce51x8eJNLEaUKV14JBx0E11wDl19uzS3hzjnHHnfcAX/9Zdt++cW+JIJ69ID9++H8860b5WGHZX29OXNsTtXw6zvnip6cmlw8oBcjd90FTzwR3bETJ0K3bjbbUtCpp2Zf87/tNmv2CVK1L4Ibb4TrroOWLfNcbOdcDHlATzDz5lm+mBo14IEHsj+ufn1Yty60Xrs2rFplmSCrV09/rEj6dVVYvRqOPtoeK1fGrvzOubzzgUUJpl07ewD072+17iZNrDbeunXouPBgDpYhsmZNayvfs8dGo37+OXTunPV1ghkl9+6NXdlfe83uA/z735b2oEKF2J3buZLOA3oxV68eXHFFaF3VAnmDBqFtTz5p7exgwRws+DdvbqNXsxr0pAobAlnvI6UhSE6Gtm0z1/KzOuc//hFaX7Ik9MXknMs/7+WSgOrXt+C5e7cF5dtvh6lTMx8XTBaW1b6//4aUFFtevRqym2BqwgQLyuPHRy7Xjh3p13/7LfJrnHPR84CewMqWhcMPt+WuXa2pY+XK6Lo3nnyy9XwJOvRQ63Wzfr3dLP33v+Hee+GSS2x/sHkGrFfOhx/azdS1a0O9c4JpDoI2bozufdSqBX37RnescyWZ3xQt4fbvt5QC48ZZLXvrVhv0lJObboIXXki/7amnLKnYr79aM1BGr7wCkyaFZnUCm5P1zjtzvta+fdbHHrwrpXPgvVxcLk2YAI88Yn3WDzkkuuaUvLjrLqhY0drf27bNuo/82rXQsKEtB/+pLlhgN38jtdk7l4i8l4vLlYsvtkfQ2LE2ivWVV2xWpkMOsQFPBx1kNfKsJu6Ixief2I3RoClTbBq/NWusiQfSpz7Yv9/yyHfpYk0+N92Ut+s6l6iiCugi0g14DigFvKKqj2XYfx1wI7AP2AEMVNWlMS6ri5NSpaBjR3tk5a+/rG/8o49a2/v339uN1u3bcz5veDAHGwgFVlO/6ipISrJmmaBnn7V88QDffhtd2WfPtu6R118f3fHOFWuqmuMDC+KrgKOAssB3QLMMx1QJW+4BTIl03rZt26pLXCtWqE6cqPrJJ6qjR6v+/rvqc8+pfvqp6p49qgMHqlojSvSPM89UfeYZW+7b167zv/+pLlqkum+f6uOPq1apojp2bKgclSvb8fPmhbatXau6enWh/jmcixkgWbOL19ntOHAAnAhMDVu/G7g7h+P7AJ9GOq8H9JJt+3bV2bNVt21Tff11+5d4/PHRB/dDDlF95ZXs9+/YoTp1qmrz5rZ+ww2hawePya29e+3hXDzlFNCj6bZ4BLA+bD0lsC0dEblRRFYBTwCDsjqRiAwUkWQRSd6cXcdmVyJUqmTNM5UrQ79+1u994ULLE798uSUZ+/ZbG9n6zDMwenT61//5J1x9dfbnf+ABGzAVbN8fNQpeesn65geFTyiSUd++dtP1k09C25o391z0rojLLtIHH0BvrN08uH4F8EIOx18GvB7pvF5Dd7m1bZtqaqrVkvv2tVr2oEGRa/PBZhdQHTIk/T5V1eRk1VtvVd2/P3St8GP++1/Vp57KW81+16681+pnzbJmK+fCUchNLgcBWyOd1wO6i5VJk1RXrlT94w/V117LHNA//DD7YB8eqMeOVR05UrVs2Zy/IKZMseued56t9+ihmpaWddlA9bLLonsfy5erfvmlLScl5b1pKDf27lXdsKFgr+FiK78BvTSwGmhI6KbocRmOaRS2fF5OFww+PKC7grR4sermzaopKba+dKlq166Ra/PRPFq0sHOGb7vnntC1p01Tfftt1b/+yl1QDh67cGHmXxEF5eGH7Rpr1xbsdVzs5BRfI7ahq+pe4CZgKrAMmKCqS0RkuIj0CBx2k4gsEZFFwBDgyrw2ATkXC8cdZ+3vRwTu9hx7rHWlXLPG+tVv2ACnnQbHHBPqChl0ZYR/vd9/DyeckH7bI49YWuJ9++CMM+Cyy9KPig1atQrmzrXl/fvted8+2LYtdEx4xkzIPo9OLMycac8LFhTcNVzhiaofuqpOBiZn2PZA2PItMS6XcwWiQYNQJsrp09PvW78e6ta1m6HXXWdfCEuWWB/7Qw+1G6xJSbbvm28ynzs4F2zQ5ZeHlvfssaB5zTXWLz7orrvsOby/fUaHHhpd2oP16+2La84caNUq8vEQyov/88/RHe+KNh8p6lxAeA6aYA38mGOgZ8/Q9p07LfvkWWdZbpoHH7SeOuefb7NEZeeww2DLlszbcwrkuTV5sg3y+ve/4dVXo3tNcF7a8eOtp9HQobErjyt8nsvFuRjZudNGpq5ZY0G1TRvrirl7t+0LZpd87LHsA+dBB4WaYsKdfba9TtWaiKZPt5G4hx0GH39szUivvmq/AMBq6RlH9qam2oQi69fbr5SyZaFTJytzUFpaKBna7Nk2BeE332T+9eHiJ6dcLhFvihbUw2+KupJmyRIbLbtnj+rff9uo2auvVr3wQtWnn7YRtbNm2U3KwYNVly1TveiivN+8HT8+/fVB9dhj7bllS+tV06RJ+tcsXhw6vkUL27ZgQeb3snu36ldf5f9vMmKEXePPP/N/rpKCHG6Keg3duSJm61arhYvYpCC9esG0aXk7V4UKcO21lhI5q3w2hxxig7TCBUPCccfB0qV2DyEpUB9MS4Pnn7f7Ca+/bsna9u+3AVcZ56mNZNYsOO88e49LlkCzZrl+eyWSZ1t0rhipWjW0XKkSfPaZLe/bZ803//wntGhhUw/efTdUq2Zpho86ym7kbtpkeeb377emnmeeyf5af/4JderYyNygF1+EMWMsmIPdMK1e3c5/yy22P2j6dLjtNivPV1/ZfYVevULNNjnp0iW0vGuXNQXt3Gnz4xaU1FS7QV2nTsFdI568hu5cglq3zgLzF19YOoVLL7VgtmiRpVgITgH42mswYEDernHZZfD227Z8++020cnbb1t30dKl4aSTbJ+qBeuKFW35nXfSz0I1Y4Z1Iw0eW1CCOfRze429e+0LrkWL2Jcpt3yCC+dcOn/9ZU0xl19uaYu//RaOPNJq/Xlt3gkqX95q3ADvvWe14muvtfX16+2L5uST079m9GhLmQxFM6A/9JDlB1q0CFq2jH25ciOngO5zijpXAlWsCG+9FcpB37491K5tg6/277emlB9/tPbyM8+Eo4+2QHbccTY/bU6CwRygd+9QMAfrGjpuXObX3H9/aPnrr619/a+/Mvf4efRRK3c0/u//7EsqK9nl09+yJTTYKlyw+WnRouiuHTfZ3S0t6If3cnGueFq2TLVVK0tvsHChrQd7yZQurXr++aHeNJEeL7yQ8/5Bg+yaH32UfntWvvvO9n3+ua0Hj921K3RM+Dm2b898jtNPt33btqXffttttr1VK9Vx49Incits5NDLxW+KOudypWlT618fLi3N+tYPGhSqFe/YYe3qFSrAl1/ajdUpU2zf0KFw+OHWbz6nqQSff94eGW3caL8o7rjDattXXw0jRti+V19NP0p30iSoVcv6+IfbsCH9DdgdO0K18z//tAFjQcHXLlpk9yIaNIAOHbIvd7x4QHfO5Vvp0nZDNFylSvCf/6TftmWLdckMD65Tp9rApZYtLZCefXaoiSM7R2SYkWHOnNDyG2+k33fhhVmfY9q0UEBXteakYBPPuHH2ZRFscw/PtQN2kzk8oP/8s/WcKVMm53IXNA/ozrlCU61a5m3hbfJVqlif9AkT4PjjrXb9wQewYoUF+7Fjrevk77/nvyw33WTnbNYsc9C/6y5LpXD55faLJGNAT0kJLaemWj/8+vXtC+LddzMnfCss3svFOVes7N5tTSO33261+UcftYRnN9xg/fDPPNNq1/372w3aMWPyf80WLSzLZrh33rEcPlWrWnfQoDFjbHBY5crWFPXEE5CcHPoyS0vLX03euy0650qkLVust8tRR1k/+Pr1Lbj+61+hY0qXtl42H39s+7LTqpUN4ApPslaqlA34iuRf/7JfA336wIkn2mCvvPb994DunHNhnnnG0iG0a2fpiYOWLYN7702fy/7ii60J6I47rLZ9ySW2nh+ff26J0fLCA7pzzuVCSgo8/LAF/vLlLWVy7drWY+e332DIEEs3XLu2Zda89VZrUmndGkaOhOHDbZRs587Wpz5cjx7w/vvRpUfIigd055wrZMHQesUV1u7/xhuxSUOc75GiItJNRFaIyEoRyZTJWUSGiMhSEfleRKaLSP38Fto554ozEXu89Zb1fCmMnPIRA7qIlAJGAN2BZkAfEcmY6HIhkKSqLYD3gCdiXVDnnHM5i6aG3h5YqaqrVXUPMA7oGX6Aqs5U1Z2B1a+BurEtpnPOuUiiCehHAOvD1lMC27LzD+DTrHaIyEARSRaR5M0FOZW5c86VQDHNtigilwNJwJNZ7VfVUaqapKpJtWrViuWlnXOuxIum48wGIGw+dOoGtqUjImcA9wKnquru2BTPOedctKKpoc8DGolIQxEpC1wKTAw/QERaAy8BPVT1t9gX0znnXCQRA7qq7gVuAqYCy4AJqrpERIaLSI/AYU8ClYB3RWSRiEzM5nTOOecKSFRjlVR1MjA5w7YHwpbPiHG5nHPO5VLcRoqKyGZgXR5fXhOIQQLNYsXfc8ng77lkyM97rq+qWfYqiVtAzw8RSc5u6Gui8vdcMvh7LhkK6j37JNHOOZcgPKA751yCKK4BfVS8CxAH/p5LBn/PJUOBvOdi2YbunHMus+JaQ3fOOZeBB3TnnEsQxS6gR5pso7gSkXoiMjMwUcgSEbklsL26iHwmIj8Fng8JbBcReT7wd/heRNrE9x3kjYiUEpGFIvJJYL2hiHwTeF/jA+kmEJFygfWVgf0N4lnuvBKRaiLynogsF5FlInJiCfiMBwf+TS8WkXdEpHwifs4i8pqI/CYii8O25fqzFZErA8f/JCJX5qYMxSqgRznZRnG1F7hNVZsBJwA3Bt7bUGC6qjYCpgfWwf4GjQKPgcCLhV/kmLgFSykR9DjwjKoeA/yJpWMm8PxnYPszgeOKo+eAKaraFGiJvfeE/YxF5AhgEDYBzvFAKSwfVCJ+zmOAbhm25eqzFZHqwINAB2wuigeDXwJRUdVi8wBOBKaGrd8N3B3vchXQe/0vcCawAqgT2FYHWBFYfgnoE3b8geOKywPL3DkdOA34BBBs9FzpjJ83lkvoxMBy6cBxEu/3kMv3WxVYk7HcCf4ZB+dTqB743D4BzkrUzxloACzO62cL9AFeCtue7rhIj2JVQyf3k20US4Gfma2Bb4DDVPWXwK5fgcMCy4nwt3gWuBPYH1ivAWxRSwgH6d/Tgfcb2L81cHxx0hDYDIwONDO9IiIVSeDPWFU3AE8BPwO/YJ/bfBL7cw6X2882X595cQvoCU9EKgHvA7eq6rbwfWpf2QnRz1REVufTAQAAAdRJREFUzgV+U9X58S5LISoNtAFeVNXWwF+EfoIDifUZAwSaC3piX2aHAxXJ3CxRIhTGZ1vcAnpUk20UVyJSBgvmY1X1g8DmTSJSJ7C/DhDMN1/c/xYdgR4ishabp/Y0rH25mogEs4CGv6cD7zewvyqQWpgFjoEUIEVVvwmsv4cF+ET9jAHOANao6mZVTQM+wD77RP6cw+X2s83XZ17cAnrEyTaKKxER4FVgmao+HbZrIhC8030l1rYe3N4vcLf8BGBr2E+7Ik9V71bVuqraAPscZ6hqX2Am0DtwWMb3G/w79A4cX6xqsqr6K7BeRJoENp0OLCVBP+OAn4ETRKRC4N948D0n7OecQW4/26lAVxE5JPDrpmtgW3TifRMhDzcdzgZ+BFYB98a7PDF8XydjP8e+BxYFHmdj7YfTgZ+AaUD1wPGC9fhZBfyA9SKI+/vI43vvDHwSWD4K+BZYCbwLlAtsLx9YXxnYf1S8y53H99oKSA58zh8BhyT6Zwz8H7AcWAy8CZRLxM8ZeAe7T5CG/Rr7R14+W2BA4P2vBK7KTRl86L9zziWI4tbk4pxzLhse0J1zLkF4QHfOuQThAd055xKEB3TnnEsQHtCdcy5BeEB3zrkE8f93rlp2EGLzywAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8fUXoqeZvwf"
      },
      "source": [
        "**12. Evaluate the performance**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wawHhkURYMLE",
        "outputId": "2ecf6570-85b0-449b-e512-698ef5cc11a6"
      },
      "source": [
        "res =model.evaluate(X_testing, Y_testing)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/10 [==============================] - 0s 2ms/step - loss: 0.8198 - accuracy: 0.7727\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0WCSw36oZyG_"
      },
      "source": [
        "**13. Predict on new datatset**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CcE27mGFYo3G",
        "outputId": "2c887daa-a4ad-4fba-896f-f0a2dfc0e539"
      },
      "source": [
        "test=X_testing[0]\n",
        "y_act=Y_testing[0]\n",
        "result=model.predict(test.reshape(1,8))\n",
        "result"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.5069922 , 0.49300775]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T4RDC-ZHYqv_",
        "outputId": "b9bf58aa-57c6-48c5-96c1-c983c880ff64"
      },
      "source": [
        "import numpy as np\n",
        "y_pred = np.round(result)\n",
        "print(\"Actual:\"+ str(y_act))\n",
        "print(\"Predicted:\"+str(y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Actual:[1. 0.]\n",
            "Predicted:[[1. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E9mMqJtXYz2Q"
      },
      "source": [
        "**Reference:** - https://keras.io/"
      ]
    }
  ]
}